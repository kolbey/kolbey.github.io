<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>EMP-SSL</title>
      <link href="/2023/08/27/emp-ssl/"/>
      <url>/2023/08/27/emp-ssl/</url>
      
        <content type="html"><![CDATA[<h3 id="EMP-SSL-Towards-Self-Supervised-Learning-in-One-Training-Epoch"><a href="#EMP-SSL-Towards-Self-Supervised-Learning-in-One-Training-Epoch" class="headerlink" title="EMP-SSL: Towards Self-Supervised Learning in One Training Epoch"></a>EMP-SSL: Towards Self-Supervised Learning in One Training Epoch</h3><h3 id="0-写在前面"><a href="#0-写在前面" class="headerlink" title="0. 写在前面"></a>0. 写在前面</h3><h3 id="1-论文基本信息"><a href="#1-论文基本信息" class="headerlink" title="1. 论文基本信息"></a>1. 论文基本信息</h3><blockquote><ul><li><a href="https://arxiv.org/pdf/2304.03977.pdf">论文链接</a></li><li><a href="https://github.com/kolbey/EMP-SSL">代码链接</a></li></ul></blockquote><h3 id="2-论文主要内容"><a href="#2-论文主要内容" class="headerlink" title="2. 论文主要内容"></a>2. 论文主要内容</h3><p>过去几年，无监督和自监督学习（SSL）取得了巨大进步，通过SSL学习得到的表征在分类性能上甚至赶上了有监督学习，在某些情况下甚至还能超过有监督学习，这一趋势也为视觉任务的大规模数据驱动无监督学习提供了可能。</p><p>虽然自监督学习的实验性能惊人，但大多数自监督学习方法都是相当「低效」的，通常需要数百个训练epoch才能完全收敛。</p><p>最近，马毅教授、图灵奖得主Yann LeCun团队发布了一种新的自监督学习方法Extreme-Multi-Patch Self-Supervised-Learning（EMP-SSL），证明了高效自监督学习的关键是增加每个图像实例中的图像块数量。</p><p>与其他 SSL 方法类似，EMP-SSL也是从图像的增强视图（augmented views）中获得联合嵌入，其中增强视图是固定大小的图像块（image patch）</p><p>这类方法有两个目标：同一图像的两个不同增强图像的表征应该更接近；表征空间不应该 collapsed trivial space，即必须保留数据的重要几何或随机结构。</p><p>之前的研究主要探索了各种策略和不同的启发式方法来实现这两个特性，并取得了越来越好的性能，其成功主要源于对图像块共现的学习。</p><p>为了让图像块共现的学习更有效率，研究人员在EMP-SSL中将自监督学习中的图像块数量增加到了极限（extreme）。</p><p>首先，对于输入的图像，先通过随机裁剪（可重叠）切分成n个固定大小的图像块，然后使用标准的数据增强技术对图像块进行增强。</p><p>对每个增强的图像块，通过两个网络分别获得获取嵌入（embedding）和投影（projection），其中嵌入网络是一个比较深的网络（如ResNet-18），投影网络更小，只有两个全连接层，二者共同组成编码器。</p><p><img src="/./images/Self_Supervised_Learning/0.png"></p><p>在训练期间，模型采用Total Coding Rate(TCR)正则化技术来避免表征崩溃。</p><p><img src="/./images/Self_Supervised_Learning/1.png"></p><p>研究人员也希望来自同一图像的不同图像块的表征是不变的，即在表示空间中应该尽可能接近，所以要尽量缩小增强图像的表征与同一图像中所有增强图像块的平均表征之间的距离，所以训练目标为：</p><p><img src="/./images/Self_Supervised_Learning/2.png" alt="2"></p><p>其中Z代表不同增强图像块的表征平均值，D为距离函数（余弦相似度），即D的值越大，二者越相似。</p><p>这个目标函数可以看作是最大速率下降（maximal rate reduction）的一个变体，也可以看作是基于协方差的 SSL 方法的广义版本，将n设置为2就是常见的2-view自监督学习方法，也可以将n设的更大，以提高图像块贡献的学习速度。</p><p><img src="/./images/Self_Supervised_Learning/3.png"></p><p><strong>实验结果</strong> </p><p>对比其他最先进的自监督学习方法，可以看到，即便EMP-SSL只看过一次数据集，也能收敛到接近完全收敛的SOTA性能。结果表明，该方法不仅在提高当前 SSL 方法的收敛性方面具有巨大潜力，而且在计算机视觉的其他领域，如在线学习、增量学习和机器人学习中，也具有巨大潜力。</p><p><img src="/./images/Self_Supervised_Learning/4.png"></p><p>在标准数据集中，包括CIFAR-10、CIFAR-100、Tiny ImageNet 和 ImageNet-100，研究人员验证了所提目标函数在收敛速度方面的效率。</p><p><img src="/./images/Self_Supervised_Learning/5.png"></p><p>可以看到，EMP-SSL仅在一个epoch的训练之后，就在 20 个图像块的设置下实现了 80.6% 的准确率，在 200 个图像块设置下可以实现82.6%的准确率。</p><p><img src="/./images/Self_Supervised_Learning/6.png"></p><p>在10个epoch后，EMP-SSL就已经收敛到超过90%，也是CIFAR-10数据集上最先进的自监督学习方法；而30个 epochs 时，EMP-SSL 的准确率更是超过了当前所有方法，达到了 93% 以上。</p><p>研究人员使用 t-SNE maps的结果来证明，尽管只训练几个epoch，EMP-SSL 已经学到了有意义的表征。在CIFAR-10训练集上学到的表征图中，EMP-SSL 使用 200 个图像块训练了 10 个 epochs，其他 SOTA 方法则训练了 1000 个 epochs，其中每个颜色代表一个不同的类别。可以看到，EMP-SSL 为不同类别学习到的表征分离得更好，并且更结构化；与其他 SOTA 方法相比，EMP-SSL学习到的特征显示出更精细的低维结构。最令人惊叹的是，所有这些结构都是在短短 10 个epoch的训练中学到的！</p><p><img src="/./images/Self_Supervised_Learning/7.png"></p>]]></content>
      
      
      <categories>
          
          <category> Computer Vision </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Image Classification </tag>
            
            <tag> Self-Supervised Learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>RL-PID Servo Control</title>
      <link href="/2023/07/06/rl-pid-control/"/>
      <url>/2023/07/06/rl-pid-control/</url>
      
        <content type="html"><![CDATA[<h3 id="Control-Strategy-of-Speed-Servo-Systems-Based-on-Deep-Reinforcement-Learning"><a href="#Control-Strategy-of-Speed-Servo-Systems-Based-on-Deep-Reinforcement-Learning" class="headerlink" title="Control Strategy of Speed Servo Systems Based on Deep Reinforcement Learning"></a>Control Strategy of Speed Servo Systems Based on Deep Reinforcement Learning</h3><h3 id="0-写在前面"><a href="#0-写在前面" class="headerlink" title="0.写在前面"></a>0.写在前面</h3><p>在这篇文章中，作者基于深度强化学习提出了一种新型的速度伺服系统控制策略，可以一定程度上解决速度伺服系统的控制参数在实际应用中难以调节且运行中易出现力矩扰动和惯量突变的问题。具体而言，作者探索了两种速度伺服系统控制策略，一种采用RL方法对PID控制参数进行整定，另一种采用RL方法自适应的对PID控制的电流进行补偿。实验结果表明，将传统的PID控制方法与RL方法进行结合能够有效的解决实际应用过程中面对力矩扰动和惯量突变等情况传统PID方法无法自适应的问题。</p><h3 id="1-论文基本信息"><a href="#1-论文基本信息" class="headerlink" title="1. 论文基本信息"></a>1. 论文基本信息</h3><blockquote><ul><li><a href="https://www.mdpi.com/1999-4893/11/5/65#:~:text=In%20this%20study%2C%20an%20adaptive%20compensation%20PID%20control,a%20servo%20system%20controlled%20by%20a%20PID%20controller.">论文链接</a></li><li><a href="https://github.com/kolbey/RL-PID-Servo-Control">源码链接</a></li></ul></blockquote><h3 id="2-论文主要内容"><a href="#2-论文主要内容" class="headerlink" title="2. 论文主要内容"></a>2. 论文主要内容</h3><h4 id="速度伺服系统模型分析"><a href="#速度伺服系统模型分析" class="headerlink" title="速度伺服系统模型分析"></a>速度伺服系统模型分析</h4><p>速度伺服系统由电流控制环、伺服电机、负载和反馈系统组成。根据速度环组成部分的分析，可将电流闭环、电机和速度检测假设为一阶系统，并采用PI控制算法作为速度调节器，可得到如图所示的速度伺服系统结构。</p><p><img src="/./images/Reinforcement_Learning/0.PNG"></p><p>其中，Ks 是电流回路的比例增益，Ts 是积分时间常数，Kt 是伺服系统转矩电流系数。Ksf &#x3D; 60 m &#x2F; fp T 是速度反馈系数，m 是检测到的脉冲数，pf 代表编码器的分辨率，T 是速度检测周期。2TΣ 是电流回路近似系统的时间常数。Tsf 是速度反馈近似系统的时间常数，K 是机械传动的刚度系数，B 是负载摩擦力的换算系数。</p><p>关于伺服系统的建模推到过程可以具体参看论文原文，这里值得指出的是，负载转矩变化引起的速度波动与系统惯量和负载转矩都有关系。惯量越小，说明相同负载转矩波动对速度控制过程的影响越大。伺服系统运行时应仔细考虑系统惯量和负载扭矩，以获得稳定的速度响应。例如，机器人手臂在运动过程中，其惯性不断变化。因此在数控加工过程中，加工零件的质量会降低，从而导致进给轴的换算惯量发生变化。当负载对象的特性发生变化时，整个伺服系统的特性也会发生变化。如果系统惯量增大，系统的响应就会变慢，这很可能会导致系统不稳定并导致爬升。相反，如果系统惯性减小，动态响应就会加快，出现速度超调和扰动。</p><p>在这篇文章中，伺服系统的数学模型如下图所示，伺服系统在运行过程中的转动惯量和外部力矩扰动可视为是图中的系统1、2、3在不同时刻之间的跳变切换。</p><p><img src="/./images/Reinforcement_Learning/1.PNG"></p><h4 id="基于强化学习的PID伺服系统控制策略"><a href="#基于强化学习的PID伺服系统控制策略" class="headerlink" title="基于强化学习的PID伺服系统控制策略"></a>基于强化学习的PID伺服系统控制策略</h4><p><strong>基于强化学习的PID参数整定策略</strong> </p><p>这篇文章首先使用actor-critic构建强化学习智能体1的框架，以PID伺服系统作为其环境对象。获得激励函数的跟踪误差曲线。采用确定性策略梯度算法设计动作网络，采用DQN算法设计评估网络。最终实现PID参数自整定。由于，前面将伺服系统的模型建立为PI控制，因此这里强化学习智能体的动作变量只有两个，分别是比例系数和积分系数。奖励函数由伺服系统输出角度的跟踪误差的绝对值构成。</p><p><img src="/./images/Reinforcement_Learning/2.PNG"></p><p><strong>基于强化学习的自适应PID电流补偿策略</strong> </p><p>自适应PID电流补偿智能体2采用与智能体1相同的控制结构和算法，实现PID输出电流的自适应补偿。</p><p><img src="/./images/Reinforcement_Learning/3.PNG"></p><h4 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h4><p>详细的实验配置和整体的实验结果可以参看论文原文，这里主要对几个重要的性能结果曲线图进行展示，可以看出利用强化学习不仅可以使伺服系统的控制参数进行快速、准确的整定，而且可以根据伺服系统的状态进行电流在线补偿，从而使得该系统能够有效克服外界因素的影响。</p><p><img src="/./images/Reinforcement_Learning/4.PNG"></p><p><img src="/./images/Reinforcement_Learning/5.PNG"></p><p><img src="/./images/Reinforcement_Learning/6.PNG"></p><p><img src="/./images/Reinforcement_Learning/7.PNG"></p><p><img src="/./images/Reinforcement_Learning/8.PNG"></p>]]></content>
      
      
      <categories>
          
          <category> 深度强化学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DRL </tag>
            
            <tag> Control </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>KAD (nature 子刊)</title>
      <link href="/2023/07/05/kad-nature-zi-kan/"/>
      <url>/2023/07/05/kad-nature-zi-kan/</url>
      
        <content type="html"><![CDATA[<h3 id="Knowledge-enhanced-Visual-Language-Pre-training-on-Chest-Radiology-Images"><a href="#Knowledge-enhanced-Visual-Language-Pre-training-on-Chest-Radiology-Images" class="headerlink" title="Knowledge-enhanced Visual-Language Pre-training on Chest Radiology Images"></a>Knowledge-enhanced Visual-Language Pre-training on Chest Radiology Images</h3><h3 id="0-写在前面"><a href="#0-写在前面" class="headerlink" title="0. 写在前面"></a>0. 写在前面</h3><p>该模型通过在大规模医学影像与放射报告数据进行预训练，通过文本编码器对高质量医疗知识图谱进行隐空间嵌入，利用视觉 - 语言模型联合训练实现了知识增强的表征学习。在不需要任何额外标注情况下，KAD 模型即可直接应用于任意胸片相关疾病的诊断，为开发人工智能辅助诊断的基础模型提供了一条切实可行的技术路线。</p><h3 id="1-论文基本信息"><a href="#1-论文基本信息" class="headerlink" title="1. 论文基本信息"></a>1. 论文基本信息</h3><blockquote><ul><li><a href="https://arxiv.org/pdf/2302.14042.pdf">论文链接</a></li><li><a href="https://github.com/xiaoman-zhang/KAD">代码链接</a></li></ul></blockquote><h3 id="2-论文主要内容"><a href="#2-论文主要内容" class="headerlink" title="2. 论文主要内容"></a>2. 论文主要内容</h3><p>KAD 模型的核心是利用医学先验知识引导基础模型预训练，第一阶段，该研究利用医学知识图谱训练一个文本知识编码器，对医学知识库在隐空间进行建模；第二阶段，该研究提出放射报告中提取医学实体和实体间关系，借助已训练的知识编码器来指导图像与文本对的视觉表征学习，最终实现了知识增强的模型预训练。具体流程如图 1 所示。</p><p><img src="/./images/Medical_AI/0.PNG"></p><p><strong>知识编码器</strong> </p><p>知识编码器的核心是在特征空间隐式地建立医学实体之间的关系。具体来说，该研究将统一医学语言系统 (Unified Medical Language System，UMLS) 作为医学知识库，如图 1a 所示；通过对比学习训练文本编码器，将医学知识注入模型，如图 1b 所示。</p><p><strong>知识引导的视觉表征学习</strong> </p><p>知识编码器训练完成后，模型在文本特征空间已经建立了医学实体之间的关系，即可用于引导视觉表征学习。具体来说，如图 1c 所示，基于胸片 - 报告对的数据，首先进行实体提取，得到常见疾病的集合及其标签，该研究尝试了三种方法：基于 UMLS 启发式规则的实体提取、基于报告结构化工具 RadGraph 的实体提取以及基于 ChatGPT 的实体提取；在模型层面，该研究提出了基于 Transformer 架构的疾病查询网络（Disease Query Networks），以疾病名称作为查询 (query) 输入，关注 (attend) 视觉特征以获得模型预测结果；在模型训练过程中，该研究联合优化图像 - 文本对比学习和疾病查询网络预测的多标签分类损失。</p><p>经过上述两阶段的训练，在模型使用阶段，如图 1d 所示，给定一张图像以及查询的疾病名称，分别输入图像编码器和知识编码器，经过疾病查询网络，即可得到查询疾病的预测。同时可以通过疾病查询网络得到注意力图对病灶进行定位，增强模型的可解释性。</p><h3 id="3-论文性能结果"><a href="#3-论文性能结果" class="headerlink" title="3. 论文性能结果"></a>3. 论文性能结果</h3><p>研究团队将仅在 MIMIC-CXR [1] 上使用图像和报告预训练的 KAD 模型，在多个具有不同数据分布的公开数据集上进行了系统性评测，包括 CheXpert [2], PadChest [3], NIH ChestX-ray [4] 和 CheXDet10 [5]。MIMIC-CXR 数据收集于贝斯以色列女执事医疗中心（Beth Israel Deaconess Medical Center,BIDMC）是，CheXpert 数据收集于美国斯坦福医院（Stanford Hospital），PadChest 数据收集于西班牙圣胡医院（San Juan Hospital），NIH ChestX-ray 和 CheXDet10 数据来自于美国国立卫生研究院（National Institutes of Health）临床 PACS 数据库。</p><p><strong>KAD 零样本诊断能力与专业放射科医生精度相当</strong> </p><p>如图 2 所示，该研究将预训练的 KAD 模型在 CheXpert 数据上进行评测，在其中的五类疾病诊断任务与放射科医生进行了比较，图中 Radiologists 表示三名放射科医生的平均结果。KAD 在五类疾病诊断任务上的平均 MCC 超过了 Radiologists，且在其中三类疾病的诊断结果显著优于放射科医生，肺不张 atelectasis (KAD 0.613 (95% CI 0.567, 0.659) vs. Radiologists 0.548)；肺水肿 edema (KAD 0.666 (95% CI 0.608, 0.724) vs. Radiologists 0.507)；胸腔积液 pleural effusion (KAD 0.702 (95% CI 0.653, 0.751) vs. Radiologists 0.548)。该结果证实了基于知识增强的模型预训练的有效性。</p><p><img src="/./images/Medical_AI/3.PNG"></p><p><strong>KAD 零样本诊断能力与全监督模型相当，支持开放集疾病诊断</strong> </p><p>如图 3a 所示，在 PadChest 上的零样本诊断性能大幅度超越此前所有多模态预训练模型（例如 Microsoft 发布的 BioVIL [6]，Stanford 发布的 CheXzero [7]），与全监督模型 (CheXNet [8]) 相当。此外，全监督的模型的应用范围受限于封闭的训练类别集合，而 KAD 可以支持任意的疾病输入，在 PadChest 的 177 个未见类别的测试中，有 31 类 AUC 达到 0.900 以上，111 类 AUC 达到 0.700 以上，如图 3b 所示。</p><p><img src="/./images/Medical_AI/1.PNG"></p><p><strong>KAD 具有疾病定位能力，为模型预测提供可解释性</strong> </p><p>除了自动诊断能力，可解释性在人工智能辅助医疗的作用同样关键，能够有效帮助临床医生理解人工智能算法的判断依据。在 ChestXDet10 数据集上对 KAD 的定位能力进行了定量分析与定性分析。如图 4 所示，KAD 的定位能力显著优于基线模型。图 5 中，红色方框为放射科医生提供的标注，高亮区域为模型的热力图，从中可以看出模型所关注的区域往往能与医生标注区域对应上，随着输入图像的分辨率增加，模型的定位能力也显著增强。需要强调 这是模型设计的优势，是在无需人工病灶区域标注情况下获得的副产品。</p><p><img src="/./images/Medical_AI/4.PNG"></p><p><img src="/./images/Medical_AI/5.PNG"></p>]]></content>
      
      
      <categories>
          
          <category> 预训练大模型 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Medical AI </tag>
            
            <tag> GPT </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Socket两台主机通信</title>
      <link href="/2023/06/12/socket-liang-tai-zhu-ji-tong-xin/"/>
      <url>/2023/06/12/socket-liang-tai-zhu-ji-tong-xin/</url>
      
        <content type="html"><![CDATA[<h1 id="Socket两台主机通信"><a href="#Socket两台主机通信" class="headerlink" title="Socket两台主机通信"></a>Socket两台主机通信</h1><h3 id="Socket"><a href="#Socket" class="headerlink" title="Socket"></a>Socket</h3><p>socket(简称 套接字) 是进程间通信的一种方式，它与其他进程间通信的一个主要不同是：它能实现不同主机间的进程间通信。我们网络上各种各样的服务大多都是基于 Socket 来完成通信的，例如浏览网页、QQ 聊天、收发 email 等等。</p><p><strong>socket通信的条件：IP和端口</strong> </p><p>每一台主机都有一个IP，不同主机之间通信的首要前提就是IP可以互访，此外还有一个条件就是端口，比如我们经常听到的80端口，3306端口，8080端口等。主机中的数据是通过端口发送和接收，需要将对应端口打开才能进行通信。</p><h3 id="创建客户端"><a href="#创建客户端" class="headerlink" title="创建客户端"></a>创建客户端</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> socket <span class="token keyword">import</span> <span class="token operator">*</span><span class="token comment"># 1.创建套接字</span>tcp_socket <span class="token operator">=</span> socket<span class="token punctuation">(</span>AF_INET<span class="token punctuation">,</span>SOCK_STREAM<span class="token punctuation">)</span><span class="token comment"># 2.准备连接服务器，建立连接</span>serve_ip <span class="token operator">=</span> <span class="token string">"服务器端（主机B）的IP"</span>serve_port <span class="token operator">=</span> <span class="token number">8000</span>  <span class="token comment">#端口，比如8000</span>tcp_socket<span class="token punctuation">.</span>connect<span class="token punctuation">(</span><span class="token punctuation">(</span>serve_ip<span class="token punctuation">,</span>serve_port<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># 连接服务器，建立连接,参数是元组形式</span><span class="token comment">#准备需要传送的数据</span>send_data <span class="token operator">=</span> <span class="token string">"今天是2021年08月29日，Kolbey给服务器端发送数据了"</span>tcp_socket<span class="token punctuation">.</span>send<span class="token punctuation">(</span>send_data<span class="token punctuation">.</span>encode<span class="token punctuation">(</span><span class="token string">"gbk"</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment">#从服务器接收数据</span><span class="token comment">#注意这个1024byte，大小根据需求自己设置</span>from_server_msg <span class="token operator">=</span> tcp_socket<span class="token punctuation">.</span>recv<span class="token punctuation">(</span><span class="token number">1024</span><span class="token punctuation">)</span><span class="token comment">#加上.decode("gbk")可以解决乱码</span><span class="token keyword">print</span><span class="token punctuation">(</span>from_server_msg<span class="token punctuation">.</span>decode<span class="token punctuation">(</span><span class="token string">"gbk"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment">#关闭连接</span>tcp_socket<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="创建服务器"><a href="#创建服务器" class="headerlink" title="创建服务器"></a>创建服务器</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> socket <span class="token keyword">import</span>  <span class="token operator">*</span><span class="token comment">#创建套接字</span>tcp_server <span class="token operator">=</span> socket<span class="token punctuation">(</span>AF_INET<span class="token punctuation">,</span>SOCK_STREAM<span class="token punctuation">)</span><span class="token comment">#绑定ip，port</span><span class="token comment">#这里ip默认本机</span>address <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token string">''</span><span class="token punctuation">,</span><span class="token number">8000</span><span class="token punctuation">)</span>tcp_server<span class="token punctuation">.</span>bind<span class="token punctuation">(</span>address<span class="token punctuation">)</span><span class="token comment"># 启动被动连接</span><span class="token comment">#多少个客户端可以连接</span>tcp_server<span class="token punctuation">.</span>listen<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">)</span>  <span class="token comment">#使用socket创建的套接字默认的属性是主动的</span><span class="token comment">#使用listen将其变为被动的，这样就可以接收别人的链接了</span><span class="token comment"># 创建接收</span><span class="token comment"># 如果有新的客户端来链接服务器，那么就产生一个新的套接字专门为这个客户端服务</span>client_socket<span class="token punctuation">,</span> clientAddr <span class="token operator">=</span> tcp_server<span class="token punctuation">.</span>accept<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># client_socket用来为这个客户端服务，相当于的tcp_server套接字的代理</span><span class="token comment"># tcp_server_socket就可以省下来专门等待其他新客户端的链接</span><span class="token comment"># 这里clientAddr存放的就是连接服务器的客户端地址</span><span class="token comment">#接收对方发送过来的数据</span>from_client_msg <span class="token operator">=</span> client_socket<span class="token punctuation">.</span>recv<span class="token punctuation">(</span><span class="token number">1024</span><span class="token punctuation">)</span><span class="token comment">#接收1024给字节,这里recv接收的不再是元组，区别UDP</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"接收的数据："</span><span class="token punctuation">,</span>from_client_msg<span class="token punctuation">.</span>encode<span class="token punctuation">(</span><span class="token string">"gbk"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment">#发送数据给客户端</span>send_data <span class="token operator">=</span> client_socket<span class="token punctuation">.</span>send<span class="token punctuation">(</span><span class="token string">"客户端你好，服务器端收到！"</span><span class="token punctuation">.</span>encode<span class="token punctuation">(</span><span class="token string">"gbk"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment">#关闭套接字</span><span class="token comment">#关闭为这个客户端服务的套接字，就意味着为不能再为这个客户端服务了</span><span class="token comment">#如果还需要服务，只能再次重新连</span>client_socket<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="创建客户端，实现持续通信"><a href="#创建客户端，实现持续通信" class="headerlink" title="创建客户端，实现持续通信"></a>创建客户端，实现持续通信</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> socket <span class="token keyword">import</span> <span class="token operator">*</span><span class="token comment"># 1.创建套接字</span>tcp_socket <span class="token operator">=</span> socket<span class="token punctuation">(</span>AF_INET<span class="token punctuation">,</span>SOCK_STREAM<span class="token punctuation">)</span><span class="token comment"># 2.准备连接服务器，建立连接</span>serve_ip <span class="token operator">=</span> <span class="token string">"服务器端（主机B）的IP"</span>serve_port <span class="token operator">=</span> <span class="token number">8000</span>  <span class="token comment">#端口，比如8000</span>tcp_socket<span class="token punctuation">.</span>connect<span class="token punctuation">(</span><span class="token punctuation">(</span>serve_ip<span class="token punctuation">,</span>serve_port<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># 连接服务器，建立连接,参数是元组形式</span><span class="token keyword">while</span> <span class="token boolean">True</span><span class="token punctuation">:</span>    send_data <span class="token operator">=</span> <span class="token builtin">input</span><span class="token punctuation">(</span><span class="token string">"请输入内容："</span><span class="token punctuation">)</span>    <span class="token comment">#send_data = "今天是2021年08月29日，Kolbey给服务器端发送数据了"</span>    tcp_socket<span class="token punctuation">.</span>send<span class="token punctuation">(</span>send_data<span class="token punctuation">.</span>encode<span class="token punctuation">(</span><span class="token string">"gbk"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">if</span> send_data <span class="token operator">==</span> <span class="token string">"exit"</span><span class="token punctuation">:</span>         <span class="token keyword">break</span>    <span class="token comment">#从服务器接收数据</span>    <span class="token comment">#注意这个1024byte，大小根据需求自己设置</span>    from_server_msg <span class="token operator">=</span> tcp_socket<span class="token punctuation">.</span>recv<span class="token punctuation">(</span><span class="token number">1024</span><span class="token punctuation">)</span>    <span class="token comment">#加上.decode("gbk")可以解决乱码</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>from_server_msg<span class="token punctuation">.</span>decode<span class="token punctuation">(</span><span class="token string">"gbk"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment">#关闭连接</span>tcp_socket<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="创建服务器，实现持续通信"><a href="#创建服务器，实现持续通信" class="headerlink" title="创建服务器，实现持续通信"></a>创建服务器，实现持续通信</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> socket <span class="token keyword">import</span>  <span class="token operator">*</span><span class="token keyword">import</span> time<span class="token comment">#创建套接字</span>tcp_server <span class="token operator">=</span> socket<span class="token punctuation">(</span>AF_INET<span class="token punctuation">,</span>SOCK_STREAM<span class="token punctuation">)</span><span class="token comment">#绑定ip，port</span><span class="token comment">#这里ip默认本机</span>address <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token string">''</span><span class="token punctuation">,</span><span class="token number">8000</span><span class="token punctuation">)</span>tcp_server<span class="token punctuation">.</span>bind<span class="token punctuation">(</span>address<span class="token punctuation">)</span><span class="token comment"># 启动被动连接</span><span class="token comment">#多少个客户端可以连接</span>tcp_server<span class="token punctuation">.</span>listen<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">)</span>  <span class="token comment">#使用socket创建的套接字默认的属性是主动的</span><span class="token comment">#使用listen将其变为被动的，这样就可以接收别人的链接了</span><span class="token comment"># 创建接收</span><span class="token comment"># 如果有新的客户端来链接服务器，那么就产生一个新的套接字专门为这个客户端服务</span>client_socket<span class="token punctuation">,</span> clientAddr <span class="token operator">=</span> tcp_server<span class="token punctuation">.</span>accept<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># client_socket用来为这个客户端服务，相当于的tcp_server套接字的代理</span><span class="token comment"># tcp_server_socket就可以省下来专门等待其他新客户端的链接</span><span class="token comment"># 这里clientAddr存放的就是连接服务器的客户端地址</span><span class="token keyword">while</span> <span class="token boolean">True</span><span class="token punctuation">:</span>    <span class="token comment">#接收对方发送过来的数据</span>    from_client_msg <span class="token operator">=</span> client_socket<span class="token punctuation">.</span>recv<span class="token punctuation">(</span><span class="token number">1024</span><span class="token punctuation">)</span><span class="token comment">#接收1024给字节,这里recv接收的不再是元组，区别UDP</span>    <span class="token keyword">if</span><span class="token punctuation">(</span>from_client_msg<span class="token operator">==</span><span class="token string">"exit"</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">break</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"接收的数据："</span><span class="token punctuation">,</span>from_client_msg<span class="token punctuation">.</span>decode<span class="token punctuation">(</span><span class="token string">"gbk"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    now_time <span class="token operator">=</span> time<span class="token punctuation">.</span>strftime<span class="token punctuation">(</span><span class="token string">'%Y-%m-%d %H:%M:%S'</span><span class="token punctuation">,</span> time<span class="token punctuation">.</span>localtime<span class="token punctuation">(</span>time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token comment">#发送数据给客户端</span>    send_data <span class="token operator">=</span> client_socket<span class="token punctuation">.</span>send<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token builtin">str</span><span class="token punctuation">(</span>now_time<span class="token punctuation">)</span><span class="token operator">+</span><span class="token string">" 服务端：客户端你好，服务器端收到！"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>encode<span class="token punctuation">(</span><span class="token string">"gbk"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token comment">#关闭套接字</span>    <span class="token comment">#关闭为这个客户端服务的套接字，就意味着为不能再为这个客户端服务了</span>    <span class="token comment">#如果还需要服务，只能再次重新连</span>client_socket<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> 数据通信 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Socket </tag>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Pytorch-Lightning教程</title>
      <link href="/2023/05/19/pytorch-lightning-jiao-cheng/"/>
      <url>/2023/05/19/pytorch-lightning-jiao-cheng/</url>
      
        <content type="html"><![CDATA[<h2 id="Pytorch学习-Pytorch-Lightning"><a href="#Pytorch学习-Pytorch-Lightning" class="headerlink" title="Pytorch学习: Pytorch Lightning"></a>Pytorch学习: Pytorch Lightning</h2><p>Pytorch Lightning是在Pytorch基础上封装的框架, 号称”Pytorch里的Keras”, 如官网所述, 它具有灵活, 解耦, 易于复现, 自动化, 扩展性好等优点(实际上大多也是Keras的优点哈哈哈). 知乎上对Pytorch Lightning的议论比较多, 有些人认为Pytorch Lightning纯属过度封装, 但它事实上确实能解决一些Pytorch自身不好解决的问题. 最主要的其实是保证了<strong>代码复用</strong>, 节省时间.<br>和Huggingface出品的Trainer相比, 我感觉在大多数任务上, Pytorch Lightning要更加灵活一些.</p><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>下面是一个官方给出的VAE在MNIST上的例子, 大概建立一下Pytorch Lightning的初印象:</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn<span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">import</span> functional <span class="token keyword">as</span> F<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> random_split<span class="token keyword">from</span> torchvision<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> MNIST<span class="token keyword">from</span> torchvision <span class="token keyword">import</span> transforms<span class="token keyword">import</span> pytorch_lightning <span class="token keyword">as</span> pl<span class="token keyword">class</span> <span class="token class-name">LitAutoEncoder</span><span class="token punctuation">(</span>pl<span class="token punctuation">.</span>LightningModule<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>encoder <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>          nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">28</span> <span class="token operator">*</span> <span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">,</span>          nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>          nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>decoder <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>          nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">,</span>          nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>          nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">28</span> <span class="token operator">*</span> <span class="token number">28</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        embedding <span class="token operator">=</span> self<span class="token punctuation">.</span>encoder<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">return</span> embedding    <span class="token keyword">def</span> <span class="token function">configure_optimizers</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>self<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">1e-3</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> optimizer    <span class="token keyword">def</span> <span class="token function">training_step</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> train_batch<span class="token punctuation">,</span> batch_idx<span class="token punctuation">)</span><span class="token punctuation">:</span>        x<span class="token punctuation">,</span> y <span class="token operator">=</span> train_batch        x <span class="token operator">=</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span>x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>        z <span class="token operator">=</span> self<span class="token punctuation">.</span>encoder<span class="token punctuation">(</span>x<span class="token punctuation">)</span>            x_hat <span class="token operator">=</span> self<span class="token punctuation">.</span>decoder<span class="token punctuation">(</span>z<span class="token punctuation">)</span>        loss <span class="token operator">=</span> F<span class="token punctuation">.</span>mse_loss<span class="token punctuation">(</span>x_hat<span class="token punctuation">,</span> x<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>log<span class="token punctuation">(</span><span class="token string">'train_loss'</span><span class="token punctuation">,</span> loss<span class="token punctuation">)</span>        <span class="token keyword">return</span> loss    <span class="token keyword">def</span> <span class="token function">validation_step</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> val_batch<span class="token punctuation">,</span> batch_idx<span class="token punctuation">)</span><span class="token punctuation">:</span>        x<span class="token punctuation">,</span> y <span class="token operator">=</span> val_batch        x <span class="token operator">=</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span>x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>        z <span class="token operator">=</span> self<span class="token punctuation">.</span>encoder<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x_hat <span class="token operator">=</span> self<span class="token punctuation">.</span>decoder<span class="token punctuation">(</span>z<span class="token punctuation">)</span>        loss <span class="token operator">=</span> F<span class="token punctuation">.</span>mse_loss<span class="token punctuation">(</span>x_hat<span class="token punctuation">,</span> x<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>log<span class="token punctuation">(</span><span class="token string">'val_loss'</span><span class="token punctuation">,</span> loss<span class="token punctuation">)</span><span class="token comment"># data</span>dataset <span class="token operator">=</span> MNIST<span class="token punctuation">(</span><span class="token string">''</span><span class="token punctuation">,</span> train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> transform<span class="token operator">=</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>mnist_train<span class="token punctuation">,</span> mnist_val <span class="token operator">=</span> random_split<span class="token punctuation">(</span>dataset<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">55000</span><span class="token punctuation">,</span> <span class="token number">5000</span><span class="token punctuation">]</span><span class="token punctuation">)</span>train_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>mnist_train<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">)</span>val_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>mnist_val<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token comment"># model</span>model <span class="token operator">=</span> LitAutoEncoder<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># training</span>trainer <span class="token operator">=</span> pl<span class="token punctuation">.</span>Trainer<span class="token punctuation">(</span>gpus<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">,</span> num_nodes<span class="token operator">=</span><span class="token number">8</span><span class="token punctuation">,</span> precision<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">,</span> limit_train_batches<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">)</span>trainer<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>model<span class="token punctuation">,</span> train_loader<span class="token punctuation">,</span> val_loader<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>Pytorch Lightning最重要的两个API便是<code>LightningModule</code>和<code>Trainer</code>. <code>pl.LightningModule</code>和<code>nn.Module</code>有点像对吧? 都有<code>forward()</code>. 没错, “A <code>LightningModule</code> is still just a <code>torch.nn.Module</code>“.<br>从代码里可以看出, 在<code>pl.LightningModule</code>下重写了<code>training_step</code>, <code>validation_step</code>, 完成模型训练和验证的<strong>内部流程</strong>即可, 整个训练的逻辑已经被它封装好了, 无需重写.<br>同时, DataLoader使用的是Pytorch自己的DataLoader, 二者兼容. Pytorch Lightning有对DataLoader在逻辑上的进一步封装, 方便组织数据的加载逻辑. 但是我自己用的不是很习惯, 本文中就不提及了, 感兴趣的去<a href="https://pytorch-lightning.readthedocs.io/en/latest/data/datamodule.html">这里</a>查阅.<br>通过<code>trainer.fit</code>就开始了模型的训练, 和Keras很像.<br>事实上, 整个<code>pl.LightningModule</code>只是组织了下列6种行为的逻辑:</p><ul><li><strong>Computations</strong> (init).</li><li><strong>Train Loop</strong> (training_step)</li><li><strong>Validation Loop</strong> (validation_step)</li><li><strong>Test Loop</strong> (test_step)</li><li><strong>Prediction Loop</strong> (predict_step)</li><li><strong>Optimizers and LR Schedulers</strong> (configure_optimizers)<br>记住, <strong>它并没有做进一步抽象</strong>, 只是简单的<strong>把逻辑组织在一起</strong>.</li></ul><h2 id="Initialization-amp-Forward"><a href="#Initialization-amp-Forward" class="headerlink" title="Initialization &amp; Forward"></a>Initialization &amp; Forward</h2><p><code>pl.LightningModule</code><strong>继承</strong>于<code>nn.Module</code>, 也就是说你call它的时候会默认调用它的<code>forward()</code>.</p><p>但是, <code>forward</code>的具体行为在Training和Validation甚至是Prediction的时候可能是不同的, 所以只能写模型自身的逻辑, 不要把Loss的计算也写进去, 也不要把<code>logits.argmax</code>写进去.<br>一般来说, <code>pl.LightningModule</code>的初始化和<code>forward</code>是这样写的:</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">TaskModel</span><span class="token punctuation">(</span>pl<span class="token punctuation">.</span>LightningModule<span class="token punctuation">)</span><span class="token punctuation">:</span>      <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> model<span class="token punctuation">)</span><span class="token punctuation">:</span>          <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>          self<span class="token punctuation">.</span>model <span class="token operator">=</span> model      <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token operator">**</span>inputs<span class="token punctuation">)</span><span class="token punctuation">:</span>          <span class="token keyword">return</span> self<span class="token punctuation">.</span>model<span class="token punctuation">(</span><span class="token operator">**</span>inputs<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>没错, 仅仅是将模型在<code>pl.LightningModule</code>初始化时作为参数传进来, 然后添加一个Hook… 就像<a href="https://pytorch-lightning.readthedocs.io/en/latest/common/lightning_module.html#child-modules">这样</a>. 强烈建议把模型本身和训练逻辑解耦, 将来改起来方便很多.</p><h2 id="Training-amp-Validation"><a href="#Training-amp-Validation" class="headerlink" title="Training &amp; Validation"></a>Training &amp; Validation</h2><h3 id="Training"><a href="#Training" class="headerlink" title="Training"></a>Training</h3><p><code>pl.LightningModule</code>组织的训练逻辑伪代码如下:</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">fit_loop</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    on_train_epoch_start<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">for</span> batch <span class="token keyword">in</span> train_dataloader<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        on_train_batch_start<span class="token punctuation">(</span><span class="token punctuation">)</span>        on_before_batch_transfer<span class="token punctuation">(</span><span class="token punctuation">)</span>        transfer_batch_to_device<span class="token punctuation">(</span><span class="token punctuation">)</span>        on_after_batch_transfer<span class="token punctuation">(</span><span class="token punctuation">)</span>        training_step<span class="token punctuation">(</span><span class="token punctuation">)</span>        on_before_zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>        optimizer_zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>        on_before_backward<span class="token punctuation">(</span><span class="token punctuation">)</span>        backward<span class="token punctuation">(</span><span class="token punctuation">)</span>        on_after_backward<span class="token punctuation">(</span><span class="token punctuation">)</span>        on_before_optimizer_step<span class="token punctuation">(</span><span class="token punctuation">)</span>        configure_gradient_clipping<span class="token punctuation">(</span><span class="token punctuation">)</span>        optimizer_step<span class="token punctuation">(</span><span class="token punctuation">)</span>        on_train_batch_end<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">if</span> should_check_val<span class="token punctuation">:</span>            val_loop<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment"># end training epoch</span>    training_epoch_end<span class="token punctuation">(</span><span class="token punctuation">)</span>    on_train_epoch_end<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>似乎很多对吧, 事实上我们只需要关注下面两个函数:</p><ol><li><code>training_step(self, batch, batch_idx)</code>.</li><li><code>training_epoch_end(self, training_step_outputs)</code>.</li></ol><p>其他的函数在项目规模不大的时候不会用到, 例如<code>on_train_epoch_end</code>, <code>on_train_batch_end</code>, 看起来比较美好, 但是实际上有些鸡肋, 因为合适的逻辑已经在<code>training_step</code>和<code>training_epoch_end</code>里搞定了, 而且它们不存在耦合问题.<br>我们使用Pytorch Lightning的目的就是为了快速搭建一套能跑的流程, 如果真的用到了再去查文档就好.</p><h4 id="training-step"><a href="#training-step" class="headerlink" title="training_step"></a>training_step</h4><p>batch就是<code>DataLoader</code>里返回的batch, 一般来说<code>training_step</code>里就是把batch解包, 然后计算loss. 例如:</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">training_step</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> batch<span class="token punctuation">,</span> batch_idx<span class="token punctuation">)</span><span class="token punctuation">:</span>    x<span class="token punctuation">,</span> y <span class="token operator">=</span> batch    y_hat <span class="token operator">=</span> self<span class="token punctuation">.</span>model<span class="token punctuation">(</span>x<span class="token punctuation">)</span>    loss <span class="token operator">=</span> F<span class="token punctuation">.</span>cross_entropy<span class="token punctuation">(</span>y_hat<span class="token punctuation">,</span> y<span class="token punctuation">)</span>    <span class="token keyword">return</span> loss<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>返回值可以是loss, 也可以是一个<strong>字典</strong>, 如果你想在每个训练epoch结束的时候再计算点别的什么东西, 可以这样写:</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">training_step</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> batch<span class="token punctuation">,</span> batch_idx<span class="token punctuation">)</span><span class="token punctuation">:</span>    x<span class="token punctuation">,</span> y <span class="token operator">=</span> batch    y_hat <span class="token operator">=</span> self<span class="token punctuation">.</span>model<span class="token punctuation">(</span>x<span class="token punctuation">)</span>    loss <span class="token operator">=</span> F<span class="token punctuation">.</span>cross_entropy<span class="token punctuation">(</span>y_hat<span class="token punctuation">,</span> y<span class="token punctuation">)</span>    preds <span class="token operator">=</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>    <span class="token keyword">return</span> <span class="token punctuation">&#123;</span>        <span class="token string">"loss"</span><span class="token punctuation">:</span> loss<span class="token punctuation">,</span>         <span class="token string">"other_stuff"</span><span class="token punctuation">:</span> preds<span class="token punctuation">,</span>    <span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>这样在<code>training_epoch_end</code>中可以取到<code>other_stuff</code>. 但是一定要保证里面有个<code>loss</code>, 这样才能保证整个batch正常工作.</p><h4 id="training-epoch-end"><a href="#training-epoch-end" class="headerlink" title="training_epoch_end"></a>training_epoch_end</h4><p>在每个epoch训练结束时调用<code>training_epoch_end</code>, 其参数<code>training_step_outputs</code>实际上是<strong>每个step返回的字典的一个列表</strong>.<br>例如:</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">training_step</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> batch<span class="token punctuation">,</span> batch_idx<span class="token punctuation">)</span><span class="token punctuation">:</span>    x<span class="token punctuation">,</span> y <span class="token operator">=</span> batch    y_hat <span class="token operator">=</span> self<span class="token punctuation">.</span>model<span class="token punctuation">(</span>x<span class="token punctuation">)</span>    loss <span class="token operator">=</span> F<span class="token punctuation">.</span>cross_entropy<span class="token punctuation">(</span>y_hat<span class="token punctuation">,</span> y<span class="token punctuation">)</span>    preds <span class="token operator">=</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>    <span class="token keyword">return</span> <span class="token punctuation">&#123;</span><span class="token string">"loss"</span><span class="token punctuation">:</span> loss<span class="token punctuation">,</span> <span class="token string">"other_stuff"</span><span class="token punctuation">:</span> preds<span class="token punctuation">&#125;</span><span class="token keyword">def</span> <span class="token function">training_epoch_end</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> training_step_outputs<span class="token punctuation">)</span><span class="token punctuation">:</span>    all_preds <span class="token operator">=</span> torch<span class="token punctuation">.</span>stack<span class="token punctuation">(</span>training_step_outputs<span class="token punctuation">)</span>    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><code>training_epoch_end</code>无返回值限制.<br>例子中的<code>preds</code>应该也是一个Tensor, 我们也可以在每个step结束时返回其他类型的值.</p><h4 id="log"><a href="#log" class="headerlink" title="log"></a>log</h4><p>在训练时一般都要把loss记录下来, 使用<code>self.log()</code>就可以把标量记录下来, 在其他地方也都可以随时使用. 例如:</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">training_step</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> batch<span class="token punctuation">,</span> batch_idx<span class="token punctuation">)</span><span class="token punctuation">:</span>    x<span class="token punctuation">,</span> y <span class="token operator">=</span> batch    y_hat <span class="token operator">=</span> self<span class="token punctuation">.</span>model<span class="token punctuation">(</span>x<span class="token punctuation">)</span>    loss <span class="token operator">=</span> F<span class="token punctuation">.</span>cross_entropy<span class="token punctuation">(</span>y_hat<span class="token punctuation">,</span> y<span class="token punctuation">)</span>    <span class="token comment"># logs metrics for each training_step,</span>    <span class="token comment"># and the average across the epoch, to the progress bar and logger</span>    self<span class="token punctuation">.</span>log<span class="token punctuation">(</span><span class="token string">"train_loss"</span><span class="token punctuation">,</span> loss<span class="token punctuation">,</span> on_step<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> on_epoch<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> prog_bar<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> logger<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> loss<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><code>on_step</code>即一个step记录一次, 如果也同时<code>on_epoch</code>, 它会将整个epoch的loss加起来求个平均, 在上述代码里同时记录了<code>train_loss_step</code>和<code>train_loss_epoch</code>.<br>记录的值可以在<strong>Tensorboard</strong>里看到, 非常方便.</p><ul><li>如果有多个要记录的值, 可以把它们都放进一个字典里, 然后使用<code>self.log_dict(dict)</code>一并记录下来.</li><li>如果要记录的内容是图像, 语音等其他类型, 则需要调用<code>logger</code>来存储, 从<a href="https://pytorch-lightning.readthedocs.io/en/latest/visualize/experiment_managers.html">这里</a>获取更多信息.</li></ul><h3 id="Validataion"><a href="#Validataion" class="headerlink" title="Validataion"></a>Validataion</h3><p>验证和被包含在训练逻辑中, 但流程几乎是一样的, 只是少了梯度优化的参与.<br><code>pl.LightningModule</code>组织的验证逻辑伪代码如下:</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">val_loop</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    on_validation_model_eval<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># calls `model.eval()`</span>    torch<span class="token punctuation">.</span>set_grad_enabled<span class="token punctuation">(</span><span class="token boolean">False</span><span class="token punctuation">)</span>    on_validation_start<span class="token punctuation">(</span><span class="token punctuation">)</span>    on_validation_epoch_start<span class="token punctuation">(</span><span class="token punctuation">)</span>    val_outs <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    <span class="token keyword">for</span> batch_idx<span class="token punctuation">,</span> batch <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>val_dataloader<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        on_validation_batch_start<span class="token punctuation">(</span>batch<span class="token punctuation">,</span> batch_idx<span class="token punctuation">)</span>        batch <span class="token operator">=</span> on_before_batch_transfer<span class="token punctuation">(</span>batch<span class="token punctuation">)</span>        batch <span class="token operator">=</span> transfer_batch_to_device<span class="token punctuation">(</span>batch<span class="token punctuation">)</span>        batch <span class="token operator">=</span> on_after_batch_transfer<span class="token punctuation">(</span>batch<span class="token punctuation">)</span>        out <span class="token operator">=</span> validation_step<span class="token punctuation">(</span>batch<span class="token punctuation">,</span> batch_idx<span class="token punctuation">)</span>        on_validation_batch_end<span class="token punctuation">(</span>batch<span class="token punctuation">,</span> batch_idx<span class="token punctuation">)</span>        val_outs<span class="token punctuation">.</span>append<span class="token punctuation">(</span>out<span class="token punctuation">)</span>    validation_epoch_end<span class="token punctuation">(</span>val_outs<span class="token punctuation">)</span>    on_validation_epoch_end<span class="token punctuation">(</span><span class="token punctuation">)</span>    on_validation_end<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment"># set up for train</span>    on_validation_model_train<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># calls `model.train()`</span>    torch<span class="token punctuation">.</span>set_grad_enabled<span class="token punctuation">(</span><span class="token boolean">True</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>与训练不同的是, 在验证开始前, <code>pl.LightningModule</code>会自动为我们启用<code>model.eval()</code>, 还会禁用梯度. 可以不必重复声明<code>torch.no_grad</code>, 如果不放心的话可以再包上一层.<br>我们同样只需要关注与训练过程相似的两个函数:</p><ol><li><code>validation_step(self, batch, batch_idx)</code>.</li><li><code>validation_epoch_end(self, validation_step_outputs)</code>.</li></ol><h4 id="validation-step"><a href="#validation-step" class="headerlink" title="validation_step"></a>validation_step</h4><p>与训练中的<code>training_step</code>相同. 直接贴出一个例子:</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">LitModel</span><span class="token punctuation">(</span>pl<span class="token punctuation">.</span>LightningModule<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">validation_step</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> batch<span class="token punctuation">,</span> batch_idx<span class="token punctuation">)</span><span class="token punctuation">:</span>        x<span class="token punctuation">,</span> y <span class="token operator">=</span> batch        y_hat <span class="token operator">=</span> self<span class="token punctuation">.</span>model<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        loss <span class="token operator">=</span> F<span class="token punctuation">.</span>cross_entropy<span class="token punctuation">(</span>y_hat<span class="token punctuation">,</span> y<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>log<span class="token punctuation">(</span><span class="token string">"val_loss"</span><span class="token punctuation">,</span> loss<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="validation-epoch-end"><a href="#validation-epoch-end" class="headerlink" title="validation_epoch_end"></a>validation_epoch_end</h4><p>与训练中的<code>training_epoch_end</code>相同, 这里拿到的<code>validation_step_outputs</code>也是每个<code>validation_step</code>的返回值的一个字典的列表. 例如:</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">validation_step</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> batch<span class="token punctuation">,</span> batch_idx<span class="token punctuation">)</span><span class="token punctuation">:</span>    x<span class="token punctuation">,</span> y <span class="token operator">=</span> batch    y_hat <span class="token operator">=</span> self<span class="token punctuation">.</span>model<span class="token punctuation">(</span>x<span class="token punctuation">)</span>    loss <span class="token operator">=</span> F<span class="token punctuation">.</span>cross_entropy<span class="token punctuation">(</span>y_hat<span class="token punctuation">,</span> y<span class="token punctuation">)</span>    pred <span class="token operator">=</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>    <span class="token keyword">return</span> pred<span class="token keyword">def</span> <span class="token function">validation_epoch_end</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> validation_step_outputs<span class="token punctuation">)</span><span class="token punctuation">:</span>    all_preds <span class="token operator">=</span> torch<span class="token punctuation">.</span>stack<span class="token punctuation">(</span>validation_step_outputs<span class="token punctuation">)</span>    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><code>validation_epoch_end</code>无返回值限制.</p><h2 id="Optimizer-amp-LR-Scheduler"><a href="#Optimizer-amp-LR-Scheduler" class="headerlink" title="Optimizer &amp; LR Scheduler"></a>Optimizer &amp; LR Scheduler</h2><p>在文章最开始的例子中, 我们重写了<code>configure_optimizers()</code>来为模型准备优化器. 大多数时候我们只需要一个optimizer和scheduler:</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">configure_optimizers</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">return</span> Adam<span class="token punctuation">(</span>self<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">1e-3</span><span class="token punctuation">)</span><span class="token comment"># or</span><span class="token keyword">def</span> <span class="token function">configure_optimizers</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>    optimizer <span class="token operator">=</span> Adam<span class="token punctuation">(</span>self<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">1e-3</span><span class="token punctuation">)</span>    scheduler <span class="token operator">=</span> get_linear_schedule_with_warmup<span class="token punctuation">(</span>optimizer<span class="token punctuation">,</span> self<span class="token punctuation">.</span>total_step<span class="token punctuation">)</span>    <span class="token keyword">return</span> <span class="token punctuation">[</span>optimizer<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span>scheduler<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>如果只有optimizer, 直接返回即可, 如果还有scheduler, 则需要把optimizer和scheduler分别套上一个list返回.<br>同时, 在<code>pl.LightningModule</code>内部使用<code>self.parameters()</code>可以获得所有的模型参数, 因为它继承了<code>nn.Module</code>.<br>再复杂一点, 也可以通过返回字典来控制optimizer和scheduler执行的间隔(<code>interval / frequency</code>):</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># example with step-based learning rate schedulers</span><span class="token keyword">def</span> <span class="token function">configure_optimizers</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>    gen_opt <span class="token operator">=</span> Adam<span class="token punctuation">(</span>self<span class="token punctuation">.</span>model_gen<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">)</span>    dis_opt <span class="token operator">=</span> Adam<span class="token punctuation">(</span>self<span class="token punctuation">.</span>model_disc<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.02</span><span class="token punctuation">)</span>    gen_sched <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token string">'scheduler'</span><span class="token punctuation">:</span> ExponentialLR<span class="token punctuation">(</span>gen_opt<span class="token punctuation">,</span> <span class="token number">0.99</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                 <span class="token string">'interval'</span><span class="token punctuation">:</span> <span class="token string">'step'</span><span class="token punctuation">&#125;</span>  <span class="token comment"># called after each training step</span>    dis_sched <span class="token operator">=</span> CosineAnnealing<span class="token punctuation">(</span>discriminator_opt<span class="token punctuation">,</span> T_max<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span> <span class="token comment"># called every epoch</span>    <span class="token keyword">return</span> <span class="token punctuation">[</span>gen_opt<span class="token punctuation">,</span> dis_opt<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span>gen_sched<span class="token punctuation">,</span> dis_sched<span class="token punctuation">]</span><span class="token comment"># example with optimizer frequencies</span><span class="token comment"># see training procedure in `Improved Training of Wasserstein GANs`, Algorithm 1</span><span class="token comment"># https://arxiv.org/abs/1704.00028</span><span class="token keyword">def</span> <span class="token function">configure_optimizers</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>    gen_opt <span class="token operator">=</span> Adam<span class="token punctuation">(</span>self<span class="token punctuation">.</span>model_gen<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">)</span>    dis_opt <span class="token operator">=</span> Adam<span class="token punctuation">(</span>self<span class="token punctuation">.</span>model_disc<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.02</span><span class="token punctuation">)</span>    n_critic <span class="token operator">=</span> <span class="token number">5</span>    <span class="token keyword">return</span> <span class="token punctuation">(</span>        <span class="token punctuation">&#123;</span><span class="token string">'optimizer'</span><span class="token punctuation">:</span> dis_opt<span class="token punctuation">,</span> <span class="token string">'frequency'</span><span class="token punctuation">:</span> n_critic<span class="token punctuation">&#125;</span><span class="token punctuation">,</span>        <span class="token punctuation">&#123;</span><span class="token string">'optimizer'</span><span class="token punctuation">:</span> gen_opt<span class="token punctuation">,</span> <span class="token string">'frequency'</span><span class="token punctuation">:</span> <span class="token number">1</span><span class="token punctuation">&#125;</span>    <span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>注意, <code>transformers</code> 里面的Warm up LRScheduler往往是根据Step完成学习率调节的!!!</strong> 这点非常重要!!!</p><p>所以在使用<code>transformers</code> 的调度器时, 必须把Scheduler的执行间隔<code>interval</code> 设置为<code>step</code>, 放入字典中返回:</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> AdamW<span class="token punctuation">,</span> get_linear_schedule_with_warmup<span class="token keyword">def</span> <span class="token function">configure_optimizers</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>    optimizer <span class="token operator">=</span> Adam<span class="token punctuation">(</span>self<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">1e-3</span><span class="token punctuation">)</span>    total_steps <span class="token operator">=</span> self<span class="token punctuation">.</span>trainer<span class="token punctuation">.</span>estimated_stepping_batches    warmup_steps <span class="token operator">=</span> warmup_ratio <span class="token operator">*</span> total_steps    scheduler <span class="token operator">=</span> get_linear_schedule_with_warmup<span class="token punctuation">(</span>        optimizer<span class="token punctuation">,</span>         num_warmup_steps<span class="token operator">=</span>warmup_steps<span class="token punctuation">,</span>          num_training_steps<span class="token operator">=</span>total_steps<span class="token punctuation">,</span>    <span class="token punctuation">)</span>    scheduler <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token string">"scheduler"</span><span class="token punctuation">:</span> scheduler<span class="token punctuation">,</span> <span class="token string">"interval"</span><span class="token punctuation">:</span> <span class="token string">"step"</span><span class="token punctuation">&#125;</span>    <span class="token keyword">return</span> <span class="token punctuation">[</span>optimizer<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span>scheduler<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>示例中的<code>total_steps</code>, 可以直接通过Trainer的<code>estimated_stepping_batches</code> 属性拿到, 不用手动计算.</p><blockquote><p>此外, 一些特殊情况会用到多个优化器或者多个Scheduler, 首先参考<a href="https://pytorch-lightning.readthedocs.io/en/latest/common/lightning_module.html#configure-optimizers">这里</a> , 并在<code>training_step</code>中使用<code>optimizer_idx</code>来控制loss和optimizer的关联, 参考<a href="https://pytorch-lightning.readthedocs.io/en/latest/common/lightning_module.html#training-step">这里</a>.</p></blockquote><h2 id="Test-amp-Predict"><a href="#Test-amp-Predict" class="headerlink" title="Test &amp; Predict"></a>Test &amp; Predict</h2><p>PL应该是为了满足客制化而将Test和Predict区分开. 在我们跑实验而没有部署时, Test和Predict行为并没有什么区别, 但测试和真正Inference的时候的Predict还是不一样的, Predict没有标签.<br>和验证时相同, model.eval()和<code>torch.no_grad()</code>会自动在测试和预测时自动配上.<br>当Trainer调用<code>trainer.test()</code>时, 会调用<code>test_step()</code>, 它与<code>training_step</code>, <code>validation_step</code>类似, 一般重写<code>test_step</code>时只是一层对<code>validation_step</code>的封装.<br>在测试结束时, 我比较推荐在<code>test_step</code>返回batch级的预测结果, <code>test_epoch_end</code>一并<strong>保存实验结果</strong>, 这样封装一层比较有意义.<br>Predict仅有<code>predict_step</code>, 而没有<code>predict_epoch_end</code>.</p><h2 id="Trainer"><a href="#Trainer" class="headerlink" title="Trainer"></a>Trainer</h2><p><code>pl.LightningModule</code><strong>组织</strong>了逻辑, 而<code>pl.Trainer</code><strong>驱动</strong>了流程.<br>其拟合阶段伪代码如下:</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">fit</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">if</span> global_rank <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>        <span class="token comment"># prepare data is called on GLOBAL_ZERO only</span>        prepare_data<span class="token punctuation">(</span><span class="token punctuation">)</span>    configure_callbacks<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">with</span> parallel<span class="token punctuation">(</span>devices<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment"># devices can be GPUs, TPUs, ...</span>        train_on_device<span class="token punctuation">(</span>model<span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">train_on_device</span><span class="token punctuation">(</span>model<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment"># called PER DEVICE</span>    on_fit_start<span class="token punctuation">(</span><span class="token punctuation">)</span>    setup<span class="token punctuation">(</span><span class="token string">"fit"</span><span class="token punctuation">)</span>    configure_optimizers<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment"># the sanity check runs here</span>    on_train_start<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">for</span> epoch <span class="token keyword">in</span> epochs<span class="token punctuation">:</span>        fit_loop<span class="token punctuation">(</span><span class="token punctuation">)</span>    on_train_end<span class="token punctuation">(</span><span class="token punctuation">)</span>    on_fit_end<span class="token punctuation">(</span><span class="token punctuation">)</span>    teardown<span class="token punctuation">(</span><span class="token string">"fit"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>一般我们这样使用Trainer来完成包含测试在内的整个流程:</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">model <span class="token operator">=</span> MyLightningModule<span class="token punctuation">(</span><span class="token punctuation">)</span>trainer <span class="token operator">=</span> Trainer<span class="token punctuation">(</span><span class="token punctuation">)</span>trainer<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>model<span class="token punctuation">,</span> train_dataloader<span class="token punctuation">,</span> val_dataloader<span class="token punctuation">)</span>trainer<span class="token punctuation">.</span>test<span class="token punctuation">(</span>model<span class="token punctuation">,</span> test_dataloader<span class="token punctuation">,</span> ckpt<span class="token operator">=</span><span class="token string">"best"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>对Trainer的简单用法说明如下:</p><ul><li>使用<code>trainer.stage_name()</code>可以让模型执行相应的阶段(fit, validate, test, predict).<br>如果不主动调用<code>trainer.test()</code>, 则不会执行测试阶段.</li><li><code>trainer.validate()</code>, <code>trainer.predict()</code>, 可以分别让模型执行验证和预测阶段, 前者被包含在模型的训练过程中, 无需重复调用.</li><li>虽然官网有写<code>trainer.test()</code>, <code>trainer.predict()</code>会自动加载最好的模型检查点后再测试和预测, 但我实测的时候没有加载, 默认是使用最后一个epoch测试和预测. 而在设置<code>ckpt_path=&quot;best&quot;</code>才会加载最好的模型, 否则是以最后一个epoch的模型进行测试的. 该参数在<code>trainer.fit()</code>中附加也可以让模型从该检查点开始训练.</li></ul><h3 id="Parameters"><a href="#Parameters" class="headerlink" title="Parameters"></a>Parameters</h3><p>定义Trainer时有很多参数很好用, 在这里推荐一些.</p><ul><li><code>max_epochs</code>: <strong>最大Epoch</strong>, 肯定要设置.</li><li><code>default_root_dir</code>: 默认存储模型, 日志<strong>地址</strong>. 如果不设置, 每次跑实验时候都会多一个<code>version_x</code>文件夹, 看个人喜好和需求.</li><li><code>val_check_interval</code>: <strong>验证间隔</strong>, 计量单位是epoch, 如果有更高的验证频次需求, 也可以设置为小数, 即不到1个epoch验证一次.</li><li><code>gpus</code>: 使用的GPU数量. 在即将出现的2.0版本中会被<code>accelerator=gpu</code>, <code>device=x</code>取代.</li><li><code>precision</code>: 全精度 &#x2F; 半精度训练.</li><li><code>accumulate_grad_batches</code>: <strong>梯度累加</strong>, 可以多个batch更新一次梯度, 以间接的近似大batch的效果. PS: 听说对比学习不能用.</li><li><code>gradient_clip_val</code>: <strong>梯度裁剪</strong>, 将梯度大小限制在该值内, 防止梯度过大崩掉.</li><li><code>num_sanity_val_steps</code>: 在执行训练前会先用几个batch的验证数据跑一下, 检查代码是否有问题, 设置为-1为全部, 0为不检测. 我一般设置为0.</li><li><code>callbacks</code>: <strong>回调函数</strong>, 接受值为回调函数的列表, 下小节会讲.</li></ul><h3 id="Callback"><a href="#Callback" class="headerlink" title="Callback"></a>Callback</h3><p>一般来说, <strong>早停</strong>和<strong>检查点</strong>是两个比较常用的Callback, 需要在Trainer定义时作为参数传入. 例如:</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> pytorch_lightning <span class="token keyword">import</span> Trainer  <span class="token keyword">from</span> pytorch_lightning<span class="token punctuation">.</span>callbacks <span class="token keyword">import</span> EarlyStopping<span class="token punctuation">,</span> ModelCheckpoint  early_stopping <span class="token operator">=</span> EarlyStopping<span class="token punctuation">(</span><span class="token string">'val_loss'</span><span class="token punctuation">)</span>  checkpoint <span class="token operator">=</span> ModelCheckpoint<span class="token punctuation">(</span>      save_weights_only<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>      save_on_train_epoch_end<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>      monitor<span class="token operator">=</span><span class="token string">"valid_f1"</span><span class="token punctuation">,</span>      mode<span class="token operator">=</span><span class="token string">"max"</span><span class="token punctuation">,</span>      save_top_k<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>  <span class="token punctuation">)</span>trainer <span class="token operator">=</span> Trainer<span class="token punctuation">(</span>callbacks<span class="token operator">=</span><span class="token punctuation">[</span>early_stopping<span class="token punctuation">,</span> checkpoint<span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><blockquote><p>仅当<code>ModelCheckpoint</code>的<code>save_on_train_epoch_end</code>设置为False时才会在验证时保存, 否则设置为True时是在训练时保存, 默认为None.</p></blockquote><p>还有一个<code>PrintTableMetricsCallback</code>, 不用带参数, 会在每个epoch结束时打印表格, 不过我基本不用.</p><h3 id="Trainer-in-Python-scripts"><a href="#Trainer-in-Python-scripts" class="headerlink" title="Trainer in Python scripts"></a>Trainer in Python scripts</h3><p>通常情况下, 使用<code>ArgumentParser</code>能更灵活的跑实验. 可以对Trainer手动添加参数:</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> argparse <span class="token keyword">import</span> ArgumentParser<span class="token keyword">def</span> <span class="token function">main</span><span class="token punctuation">(</span>hparams<span class="token punctuation">)</span><span class="token punctuation">:</span>    model <span class="token operator">=</span> LightningModule<span class="token punctuation">(</span><span class="token punctuation">)</span>    trainer <span class="token operator">=</span> Trainer<span class="token punctuation">(</span>accelerator<span class="token operator">=</span>hparams<span class="token punctuation">.</span>accelerator<span class="token punctuation">,</span> devices<span class="token operator">=</span>hparams<span class="token punctuation">.</span>devices<span class="token punctuation">)</span>    trainer<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>model<span class="token punctuation">)</span><span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">"__main__"</span><span class="token punctuation">:</span>    parser <span class="token operator">=</span> ArgumentParser<span class="token punctuation">(</span><span class="token punctuation">)</span>    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">"--accelerator"</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span>    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">"--devices"</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span>    args <span class="token operator">=</span> parser<span class="token punctuation">.</span>parse_args<span class="token punctuation">(</span><span class="token punctuation">)</span>    main<span class="token punctuation">(</span>args<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>如果需要修改某些参数可以在命令行附带上:</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">python main.py <span class="token parameter variable">--accelerator</span> <span class="token string">'gpu'</span> <span class="token parameter variable">--devices</span> <span class="token number">2</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>但上面手动很麻烦, Trainer支持自动添加参数到里面:</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> argparse <span class="token keyword">import</span> ArgumentParser<span class="token keyword">def</span> <span class="token function">main</span><span class="token punctuation">(</span>args<span class="token punctuation">)</span><span class="token punctuation">:</span>    model <span class="token operator">=</span> LightningModule<span class="token punctuation">(</span><span class="token punctuation">)</span>    trainer <span class="token operator">=</span> Trainer<span class="token punctuation">.</span>from_argparse_args<span class="token punctuation">(</span>args<span class="token punctuation">)</span>    trainer<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>model<span class="token punctuation">)</span><span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">"__main__"</span><span class="token punctuation">:</span>    parser <span class="token operator">=</span> ArgumentParser<span class="token punctuation">(</span><span class="token punctuation">)</span>    parser <span class="token operator">=</span> Trainer<span class="token punctuation">.</span>add_argparse_args<span class="token punctuation">(</span>parser<span class="token punctuation">)</span>    args <span class="token operator">=</span> parser<span class="token punctuation">.</span>parse_args<span class="token punctuation">(</span><span class="token punctuation">)</span>    main<span class="token punctuation">(</span>args<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>也可以走混合路线, 同时定义别的超参和Trainer的参数到parser里.</p><blockquote><p>其实都不如<strong>Hydra</strong>来的优雅, 见文末Recommended推荐的模板.</p></blockquote><h2 id="Tips"><a href="#Tips" class="headerlink" title="Tips"></a>Tips</h2><p>这一节写一些我自己使用过程中用到的一些很有用的小技巧.</p><ol><li>在<code>pl.LightningModule</code>的构造函数里面, 使用<code>self.save_hyperparameters()</code>可以将<code>pl.LightningModule</code>中所有的传入参数记录到yaml文件里, 非常方便于实验记录.</li><li><code>pl.seedeverything()</code>, 彻底告别自己写随机种子设置函数.</li><li>有的时候想把模型的预测结果和模型本身的权重保存到同一个目录下, 但是我不想自己按照规则去写路径, 而是和Trainer的设置同步, 该怎么办呢? 在<code>pl.LightningModule</code>里会添加<code>Trainer</code>的Hook, 调用<code>self.trainer</code>就能够获得它身上的属性. 例如我想把模型预测结果保存到日志目录下, 应该这么写:</li></ol><pre class="line-numbers language-python" data-language="python"><code class="language-python">pred_save_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>self<span class="token punctuation">.</span>trainer<span class="token punctuation">.</span>log_dir<span class="token punctuation">,</span> <span class="token string">"prediction.json"</span><span class="token punctuation">)</span>  your_save_function<span class="token punctuation">(</span>pred_save_path<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><ol><li>其他需要的属性也是同理, 通过Hook可以轻松拿到Trainer身上的属性.</li><li>使用<code>pl.LightningModule.load_from_checkpoint(ckpt_path)</code>可以一条命令直接为TaskModel加载超参和模型权重.</li></ol><h2 id="Reference-amp-Recommended"><a href="#Reference-amp-Recommended" class="headerlink" title="Reference &amp; Recommended"></a>Reference &amp; Recommended</h2><ul><li>Pytorch Lightning官方文档: <a href="https://www.pytorchlightning.ai/tutorials">PyTorch Lightning Tutorials</a>.</li><li>Pytorch Lightning API: <a href="https://pytorch-lightning.readthedocs.io/en/stable/common/lightning_module.html">LightningModule — PyTorch Lightning 1.7.1 documentation</a>, <a href="https://pytorch-lightning.readthedocs.io/en/stable/common/trainer.html">Trainer — PyTorch Lightning 1.7.1 documentation</a>.</li><li>Example of Transformer: <a href="https://pytorch-lightning.readthedocs.io/en/latest/notebooks/lightning_examples/text-transformers.html">Finetune Transformers Models with PyTorch Lightning — PyTorch Lightning 1.8.0dev documentation</a>.</li><li>知乎的攻略帖: <a href="https://zhuanlan.zhihu.com/p/353985363">Pytorch Lightning 完全攻略 - 知乎</a>.</li><li>一套传闻不错的PL模板(需要学习hydra): <a href="https://github.com/ashleve/lightning-hydra-template">GitHub - ashleve&#x2F;lightning-hydra-template: PyTorch Lightning + Hydra. A very user-friendly template for rapid and reproducible ML experimentation with best practices. ⚡🔥⚡</a>.</li><li>另一套简单很多的PL模板: <a href="https://github.com/KinWaiCheuk/pytorch_template">GitHub - KinWaiCheuk&#x2F;pytorch_template: Template that combines PyTorch Lightning and Hydra</a>.</li></ul>]]></content>
      
      
      <categories>
          
          <category> Tutorial </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Pytorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Pytorch分布式训练教程</title>
      <link href="/2023/05/12/pytorch-fen-bu-shi-xun-lian-jiao-cheng/"/>
      <url>/2023/05/12/pytorch-fen-bu-shi-xun-lian-jiao-cheng/</url>
      
        <content type="html"><![CDATA[<h3 id="0-概述"><a href="#0-概述" class="headerlink" title="0. 概述"></a>0. 概述</h3><p>神经网络训练加速的最简单方法是使用GPU，对弈神经网络中常规操作（矩阵乘法和加法）GPU运算速度要倍超于CPU。随着模型或数据集越来越大，一个GPU很快就会变得不足。例如，BERT和GPT-2等大型语言模型是在数百个GPU上训练的。对于多GPU训练，需要一种在不同GPU之间对模型和数据进行切分和调度的方法。</p><p>PyTorch是非常流行的深度学习框架，它在主流框架中对于灵活性和易用性的平衡最好。Pytorch有两种方法可以在多个GPU上切分模型和数据：<code>nn.DataParallel</code>和<code>nn.distributedataparallel</code>。<code>DataParallel</code>更易于使用（只需简单包装单GPU模型）。然而，由于它使用一个进程来计算模型权重，然后在每个批处理期间将分发到每个GPU，因此通信很快成为一个瓶颈，GPU利用率通常很低。而且，<code>nn.DataParallel</code>要求所有的GPU都在同一个节点上（不支持分布式），而且不能使用<a href="https://link.zhihu.com/?target=https://nvidia.github.io/apex/amp.html">Apex</a>进行<a href="https://link.zhihu.com/?target=https://devblogs.nvidia.com/mixed-precision-training-deep-neural-networks/">混合精度训练</a>。<code>nn.DataParallel</code>和<code>nn.distributedataparallel</code>的主要差异可以总结为以下几点（译者注）：</p><ol><li><code>DistributedDataParallel</code>支持模型并行，而<code>DataParallel</code>并不支持，这意味如果模型太大单卡显存不足时只能使用前者；</li><li><code>DataParallel</code>是单进程多线程的，只用于单机情况，而<code>DistributedDataParallel</code>是多进程的，适用于单机和多机情况，真正实现分布式训练；</li><li><code>DistributedDataParallel</code>的训练更高效，因为每个进程都是独立的Python解释器，避免GIL问题，而且通信成本低其训练速度更快，基本上<code>DataParallel</code>已经被弃用；</li><li>必须要说明的是<code>DistributedDataParallel</code>中每个进程都有独立的优化器，执行自己的更新过程，但是梯度通过通信传递到每个进程，所有执行的内容是相同的；</li></ol><p>总的来说，Pytorch文档是相当完备和清晰的，尤其是在1.0x版本后。但是关于<code>DistributedDataParallel</code>的介绍却较少，主要的文档有以下三个：</p><ol><li><a href="https://link.zhihu.com/?target=https://pytorch.org/tutorials/intermediate/dist_tuto.html">Writing Distributed Applications with PyTorch</a>：主要介绍分布式API，分布式配置，不同通信机制以及内部机制，但是说实话大部分人不太同意看懂，而且很少会直接用这些;</li><li><a href="https://link.zhihu.com/?target=https://pytorch.org/tutorials/intermediate/ddp_tutorial.html">Getting Started with Distributed Data Parallel</a>：简单介绍了如何使用<code>DistributedDataParallel</code>，但是用例并不清晰完整；</li><li><a href="https://link.zhihu.com/?target=https://github.com/pytorch/examples/tree/master/imagenet">ImageNet training in PyTorch</a>：比较完整的使用实例，但是仅有代码，缺少详细说明；（<code>apex</code>也提供了一个类似的训练用例<a href="https://link.zhihu.com/?target=https://github.com/NVIDIA/apex/tree/master/examples/imagenet">Mixed Precision ImageNet Training in PyTorch</a>）</li><li><a href="https://link.zhihu.com/?target=https://pytorch.org/tutorials/beginner/aws_distributed_training_tutorial.html">(advanced) PyTorch 1.0 Distributed Trainer with Amazon AWS</a>：如何在亚马逊云上进行分布式训练，但是估计很多人用不到。</li></ol><p>这篇教程将通过一个MNISI例子讲述如何使用PyTorch的分布式训练，这里将一段段代码进行解释，而且也包括任何使用<code>apex</code>进行混合精度训练。</p><h3 id="1-DistributedDataParallel内部机制"><a href="#1-DistributedDataParallel内部机制" class="headerlink" title="1. DistributedDataParallel内部机制"></a>1. <strong>DistributedDataParallel内部机制</strong></h3><p><code>DistributedDataParallel</code>通过多进程在多个GPUs间复制模型，每个GPU都由一个进程控制（当然可以让每个进程控制多个GPU，但这显然比每个进程有一个GPU要慢；也可以多个进程在一个GPU上运行）。GPU可以都在同一个节点上，也可以分布在多个节点上。每个进程都执行相同的任务，并且每个进程都与所有其他进程通信。进程或者说GPU之间只传递梯度，这样网络通信就不再是瓶颈。</p><p><img src="/./images/Pytorch/0.png"></p><p>在训练过程中，每个进程从磁盘加载batch数据，并将它们传递到其GPU。每一个GPU都有自己的前向过程，然后梯度在各个GPUs间进行All-Reduce。每一层的梯度不依赖于前一层，所以梯度的All-Reduce和后向过程同时计算，以进一步缓解网络瓶颈。在后向过程的最后，每个节点都得到了平均梯度，这样模型参数保持同步。</p><p>这都要求多个进程（可能在多个节点上）同步并通信。Pytorch通过<code>distributed.init_process_group</code>函数来实现这一点。他需要知道进程0位置以便所有进程都可以同步，以及预期的进程总数。每个进程都需要知道进程总数及其在进程中的顺序，以及使用哪个GPU。通常将进程总数称为<code>world_size</code>.Pytorch提供了<code>nn.utils.data.DistributedSampler</code>来为各个进程切分数据，以保证训练数据不重叠。</p><p>更详细的DDP的内部机理见官方的文档介绍：<a href="https://link.zhihu.com/?target=https://pytorch.org/docs/stable/notes/ddp.html">官方文档</a></p><p><img src="/./images/Pytorch/1.png"></p><h3 id="2-实例讲解"><a href="#2-实例讲解" class="headerlink" title="2. 实例讲解"></a>2. 实例讲解</h3><p>这里通过一个<a href="https://link.zhihu.com/?target=https://github.com/yangkky/distributed_tutorial/blob/master/src/mnist.py">MNIST实例</a>来讲解，我们先将其改成<a href="https://link.zhihu.com/?target=https://github.com/yangkky/distributed_tutorial/blob/master/src/mnist-distributed.py">分布式训练</a>，然后增加<a href="https://link.zhihu.com/?target=https://github.com/yangkky/distributed_tutorial/blob/master/src/mnist-mixed.py">混合精度训练</a>。</p><h4 id="普通单卡训练"><a href="#普通单卡训练" class="headerlink" title="普通单卡训练"></a><strong>普通单卡训练</strong></h4><p>首先，导入所需要的库（这里需要安装nvidia的混合精度训练库apex）：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> os<span class="token keyword">from</span> datetime <span class="token keyword">import</span> datetime<span class="token keyword">import</span> argparse<span class="token keyword">import</span> torch<span class="token punctuation">.</span>multiprocessing <span class="token keyword">as</span> mp<span class="token keyword">import</span> torchvision<span class="token keyword">import</span> torchvision<span class="token punctuation">.</span>transforms <span class="token keyword">as</span> transforms<span class="token keyword">import</span> torch<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn<span class="token keyword">import</span> torch<span class="token punctuation">.</span>distributed <span class="token keyword">as</span> dist<span class="token keyword">from</span> apex<span class="token punctuation">.</span>parallel <span class="token keyword">import</span> DistributedDataParallel <span class="token keyword">as</span> DDP<span class="token keyword">from</span> apex <span class="token keyword">import</span> amp<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>然后我们定义一个简单的CNN模型处理MNIST数据：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">ConvNet</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> num_classes<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>ConvNet<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>layer1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>layer2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>fc <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">7</span><span class="token operator">*</span><span class="token number">7</span><span class="token operator">*</span><span class="token number">32</span><span class="token punctuation">,</span> num_classes<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        out <span class="token operator">=</span> self<span class="token punctuation">.</span>layer1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        out <span class="token operator">=</span> self<span class="token punctuation">.</span>layer2<span class="token punctuation">(</span>out<span class="token punctuation">)</span>        out <span class="token operator">=</span> out<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>out<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>        out <span class="token operator">=</span> self<span class="token punctuation">.</span>fc<span class="token punctuation">(</span>out<span class="token punctuation">)</span>        <span class="token keyword">return</span> out<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>主函数<code>main()</code>接受参数，执行训练：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    parser <span class="token operator">=</span> argparse<span class="token punctuation">.</span>ArgumentParser<span class="token punctuation">(</span><span class="token punctuation">)</span>    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'-n'</span><span class="token punctuation">,</span> <span class="token string">'--nodes'</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">,</span> metavar<span class="token operator">=</span><span class="token string">'N'</span><span class="token punctuation">)</span>    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'-g'</span><span class="token punctuation">,</span> <span class="token string">'--gpus'</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">,</span>                        <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'number of gpus per node'</span><span class="token punctuation">)</span>    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'-nr'</span><span class="token punctuation">,</span> <span class="token string">'--nr'</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">,</span>                        <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'ranking within the nodes'</span><span class="token punctuation">)</span>    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--epochs'</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">,</span> metavar<span class="token operator">=</span><span class="token string">'N'</span><span class="token punctuation">,</span>                        <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'number of total epochs to run'</span><span class="token punctuation">)</span>    args <span class="token operator">=</span> parser<span class="token punctuation">.</span>parse_args<span class="token punctuation">(</span><span class="token punctuation">)</span>    train<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> args<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>其中训练部分主函数为：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span>gpu<span class="token punctuation">,</span> args<span class="token punctuation">)</span><span class="token punctuation">:</span>torch<span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>    model <span class="token operator">=</span> ConvNet<span class="token punctuation">(</span><span class="token punctuation">)</span>    torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>set_device<span class="token punctuation">(</span>gpu<span class="token punctuation">)</span>    model<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span>gpu<span class="token punctuation">)</span>    batch_size <span class="token operator">=</span> <span class="token number">100</span>    <span class="token comment"># define loss function (criterion) and optimizer</span>    criterion <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cuda<span class="token punctuation">(</span>gpu<span class="token punctuation">)</span>    optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">1e-4</span><span class="token punctuation">)</span>    <span class="token comment"># Data loading code</span>    train_dataset <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>MNIST<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">'./data'</span><span class="token punctuation">,</span>                                               train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>                                               transform<span class="token operator">=</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                                               download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>    train_loader <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>dataset<span class="token operator">=</span>train_dataset<span class="token punctuation">,</span>                                               batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span>                                               shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>                                               num_workers<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span>                                               pin_memory<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>    start <span class="token operator">=</span> datetime<span class="token punctuation">.</span>now<span class="token punctuation">(</span><span class="token punctuation">)</span>    total_step <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>train_loader<span class="token punctuation">)</span>    <span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>args<span class="token punctuation">.</span>epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">for</span> i<span class="token punctuation">,</span> <span class="token punctuation">(</span>images<span class="token punctuation">,</span> labels<span class="token punctuation">)</span> <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>train_loader<span class="token punctuation">)</span><span class="token punctuation">:</span>            images <span class="token operator">=</span> images<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span>non_blocking<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>            labels <span class="token operator">=</span> labels<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span>non_blocking<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>            <span class="token comment"># Forward pass</span>            outputs <span class="token operator">=</span> model<span class="token punctuation">(</span>images<span class="token punctuation">)</span>            loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> labels<span class="token punctuation">)</span>            <span class="token comment"># Backward and optimize</span>            optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>            loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>            optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>            <span class="token keyword">if</span> <span class="token punctuation">(</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">%</span> <span class="token number">100</span> <span class="token operator">==</span> <span class="token number">0</span> <span class="token keyword">and</span> gpu <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>                <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Epoch [&#123;&#125;/&#123;&#125;], Step [&#123;&#125;/&#123;&#125;], Loss: &#123;:.4f&#125;'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>                    epoch <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span>                     args<span class="token punctuation">.</span>epochs<span class="token punctuation">,</span>                     i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span>                     total_step<span class="token punctuation">,</span>                    loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>                   <span class="token punctuation">)</span>    <span class="token keyword">if</span> gpu <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Training complete in: "</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>datetime<span class="token punctuation">.</span>now<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-</span> start<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>通过启动主函数来开始训练：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>    main<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>你可能注意到有些参数是多余的，但是对后面的分布式训练是有用的。我们通过执行以下语句就可以在单机单卡上训练：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">python src<span class="token operator">/</span>mnist<span class="token punctuation">.</span>py <span class="token operator">-</span>n <span class="token number">1</span> <span class="token operator">-</span>g <span class="token number">1</span> <span class="token operator">-</span>nr <span class="token number">0</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="分布式训练"><a href="#分布式训练" class="headerlink" title="分布式训练"></a>分布式训练</h4><p>使用多进程进行分布式训练，我们需要为每个GPU启动一个进程。每个进程需要知道自己运行在哪个GPU上，以及自身在所有进程中的序号。对于多节点，我们需要在每个节点启动脚本。</p><p>首先，我们要配置基本的参数：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    parser <span class="token operator">=</span> argparse<span class="token punctuation">.</span>ArgumentParser<span class="token punctuation">(</span><span class="token punctuation">)</span>    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'-n'</span><span class="token punctuation">,</span> <span class="token string">'--nodes'</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>                        <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">,</span> metavar<span class="token operator">=</span><span class="token string">'N'</span><span class="token punctuation">)</span>    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'-g'</span><span class="token punctuation">,</span> <span class="token string">'--gpus'</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">,</span>                        <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'number of gpus per node'</span><span class="token punctuation">)</span>    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'-nr'</span><span class="token punctuation">,</span> <span class="token string">'--nr'</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">,</span>                        <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'ranking within the nodes'</span><span class="token punctuation">)</span>    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--epochs'</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">,</span>                         metavar<span class="token operator">=</span><span class="token string">'N'</span><span class="token punctuation">,</span>                        <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'number of total epochs to run'</span><span class="token punctuation">)</span>    args <span class="token operator">=</span> parser<span class="token punctuation">.</span>parse_args<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment">#########################################################</span>    args<span class="token punctuation">.</span>world_size <span class="token operator">=</span> args<span class="token punctuation">.</span>gpus <span class="token operator">*</span> args<span class="token punctuation">.</span>nodes                <span class="token comment">#</span>    os<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">'MASTER_ADDR'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">'10.57.23.164'</span>              <span class="token comment">#</span>    os<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">'MASTER_PORT'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">'8888'</span>                      <span class="token comment">#</span>    mp<span class="token punctuation">.</span>spawn<span class="token punctuation">(</span>train<span class="token punctuation">,</span> nprocs<span class="token operator">=</span>args<span class="token punctuation">.</span>gpus<span class="token punctuation">,</span> args<span class="token operator">=</span><span class="token punctuation">(</span>args<span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span>         <span class="token comment">#</span>    <span class="token comment">#########################################################</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>其中<code>args.nodes</code>是节点总数，而<code>args.gpus</code>是每个节点的GPU总数（每个节点GPU数是一样的），而<code>args.nr</code> 是当前节点在所有节点的序号。节点总数乘以每个节点的GPU数可以得到<code>world_size</code>，也即进程总数。所有的进程需要知道进程0的IP地址以及端口，这样所有进程可以在开始时同步，一般情况下称进程0是master进程，比如我们会在进程0中打印信息或者保存模型。PyTorch提供了<code>mp.spawn</code>来在一个节点启动该节点所有进程，每个进程运行<code>train(i, args)</code>，其中<code>i</code>从0到<code>args.gpus - 1</code>。</p><p>同样，我们要修改训练函数：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span>gpu<span class="token punctuation">,</span> args<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment">############################################################</span>    rank <span class="token operator">=</span> args<span class="token punctuation">.</span>nr <span class="token operator">*</span> args<span class="token punctuation">.</span>gpus <span class="token operator">+</span> gpu                              dist<span class="token punctuation">.</span>init_process_group<span class="token punctuation">(</span>                                       backend<span class="token operator">=</span><span class="token string">'nccl'</span><span class="token punctuation">,</span>                                            init_method<span class="token operator">=</span><span class="token string">'env://'</span><span class="token punctuation">,</span>                                       world_size<span class="token operator">=</span>args<span class="token punctuation">.</span>world_size<span class="token punctuation">,</span>                                  rank<span class="token operator">=</span>rank                                                   <span class="token punctuation">)</span>                                                              <span class="token comment">############################################################</span>        torch<span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>    model <span class="token operator">=</span> ConvNet<span class="token punctuation">(</span><span class="token punctuation">)</span>    torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>set_device<span class="token punctuation">(</span>gpu<span class="token punctuation">)</span>    model<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span>gpu<span class="token punctuation">)</span>    batch_size <span class="token operator">=</span> <span class="token number">100</span>    <span class="token comment"># define loss function (criterion) and optimizer</span>    criterion <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cuda<span class="token punctuation">(</span>gpu<span class="token punctuation">)</span>    optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">1e-4</span><span class="token punctuation">)</span>        <span class="token comment">###############################################################</span>    <span class="token comment"># Wrap the model</span>    model <span class="token operator">=</span> nn<span class="token punctuation">.</span>parallel<span class="token punctuation">.</span>DistributedDataParallel<span class="token punctuation">(</span>model<span class="token punctuation">,</span>                                                device_ids<span class="token operator">=</span><span class="token punctuation">[</span>gpu<span class="token punctuation">]</span><span class="token punctuation">)</span>    <span class="token comment">###############################################################</span>    <span class="token comment"># Data loading code</span>    train_dataset <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>MNIST<span class="token punctuation">(</span>        root<span class="token operator">=</span><span class="token string">'./data'</span><span class="token punctuation">,</span>        train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>        transform<span class="token operator">=</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        download<span class="token operator">=</span><span class="token boolean">True</span>    <span class="token punctuation">)</span>                                                   <span class="token comment">################################################################</span>    train_sampler <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>distributed<span class="token punctuation">.</span>DistributedSampler<span class="token punctuation">(</span>    train_dataset<span class="token punctuation">,</span>    num_replicas<span class="token operator">=</span>args<span class="token punctuation">.</span>world_size<span class="token punctuation">,</span>    rank<span class="token operator">=</span>rank    <span class="token punctuation">)</span>    <span class="token comment">################################################################</span>    train_loader <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>    dataset<span class="token operator">=</span>train_dataset<span class="token punctuation">,</span>       batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span>    <span class="token comment">##############################</span>       shuffle<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>            <span class="token comment">#</span>    <span class="token comment">##############################</span>       num_workers<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span>       pin_memory<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>    <span class="token comment">#############################</span>      sampler<span class="token operator">=</span>train_sampler<span class="token punctuation">)</span>    <span class="token comment"># </span>    <span class="token comment">#############################</span>    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>这里我们首先计算出当前进程序号：<code>rank = args.nr * args.gpus + gpu</code>，然后就是通过<code>dist.init_process_group</code>初始化分布式环境，其中<code>backend</code>参数指定通信后端，包括<code>mpi, gloo, nccl</code>，这里选择<code>nccl</code>，这是Nvidia提供的官方多卡通信框架，相对比较高效。<code>mpi</code>也是高性能计算常用的通信协议，不过你需要自己安装MPI实现框架，比如OpenMPI。<code>gloo</code>倒是内置通信后端，但是不够高效。<code>init_method</code>指的是如何初始化，以完成刚开始的进程同步；这里我们设置的是<code>env://</code>，指的是环境变量初始化方式，需要在环境变量中配置4个参数：MASTER_PORT，MASTER_ADDR，WORLD_SIZE，RANK，前面两个参数我们已经配置，后面两个参数也可以通过<code>dist.init_process_group</code>函数中<code>world_size</code>和<code>rank</code>参数配置。其它的初始化方式还包括共享文件系统（<a href="https://link.zhihu.com/?target=https://pytorch.org/docs/stable/distributed.html%23shared-file-system-initialization">https://pytorch.org/docs/stable/distributed.html#shared-file-system-initialization</a>）以及TCP（<a href="https://link.zhihu.com/?target=https://pytorch.org/docs/stable/distributed.html%23tcp-initialization">https://pytorch.org/docs/stable/distributed.html#tcp-initialization</a>），比如采用TCP作为初始化方法<code>init_method=&#39;tcp://10.1.1.20:23456&#39;</code>，其实也是要提供master的IP地址和端口。注意这个调用是阻塞的，必须等待所有进程来同步，如果任何一个进程出错，就会失败。</p><p>对于模型侧，我们只需要用<code>DistributedDataParallel</code>包装一下原来的model即可，在背后它会支持梯度的All-Reduce操作。对于数据侧，我们<code>nn.utils.data.DistributedSampler</code>来给各个进程切分数据，只需要在dataloader中使用这个sampler就好，值得注意的一点是你要训练循环过程的每个epoch开始时调用<code>train_sampler.set_epoch(epoch)</code>，（主要是为了保证每个epoch的划分是不同的）其它的训练代码都保持不变。</p><p>最后就可以执行代码了，比如我们是4节点，每个节点是8卡，那么需要在4个节点分别执行：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">python src<span class="token operator">/</span>mnist<span class="token operator">-</span>distributed<span class="token punctuation">.</span>py <span class="token operator">-</span>n <span class="token number">4</span> <span class="token operator">-</span>g <span class="token number">8</span> <span class="token operator">-</span>nr i<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>要注意的是，此时的有效batch_size其实是<code>batch_size_per_gpu * world_size</code>，对于有BN的模型还可以采用同步BN获取更好的效果：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">model <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>SyncBatchNorm<span class="token punctuation">.</span>convert_sync_batchnorm<span class="token punctuation">(</span>model<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>上述讲述的是分布式训练过程，其实同样适用于评估或者测试过程，比如我们把数据划分到不同的进程中进行预测，这样可以加速预测过程。实现代码和上述过程完全一样，不过我们想计算某个指标，那就需要从各个进程的统计结果进行All-Reduce，因为每个进程仅是计算的部分数据的内容。比如我们要计算分类准确度，我们可以统计每个进程的数据总数total和分类正确的数量count，然后进行聚合。这里要提的一点，当用<code>dist.init_process_group</code>初始化分布式环境时，其实就是建立一个默认的分布式进程组（distributed process group），这个group同时会初始化Pytorch的<code>torch.distributed</code>包。这样我们可以直接用<code>torch.distributed</code>的API就可以进行分布式基本操作了，下面是具体实现：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># define tensor on GPU, count and total is the result at each GPU</span>t <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span>count<span class="token punctuation">,</span> total<span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float64<span class="token punctuation">,</span> device<span class="token operator">=</span><span class="token string">'cuda'</span><span class="token punctuation">)</span>dist<span class="token punctuation">.</span>barrier<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># synchronizes all processes</span>dist<span class="token punctuation">.</span>all_reduce<span class="token punctuation">(</span>t<span class="token punctuation">,</span> op<span class="token operator">=</span>torch<span class="token punctuation">.</span>distributed<span class="token punctuation">.</span>ReduceOp<span class="token punctuation">.</span>SUM<span class="token punctuation">,</span><span class="token punctuation">)</span>  <span class="token comment"># Reduces the tensor data across all machines in such a way that all get the final result.</span>t <span class="token operator">=</span> t<span class="token punctuation">.</span>tolist<span class="token punctuation">(</span><span class="token punctuation">)</span>all_count <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>t<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>all_total <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>t<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>acc <span class="token operator">=</span> all_count <span class="token operator">/</span> all_total<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="分布式训练启动方式"><a href="#分布式训练启动方式" class="headerlink" title="分布式训练启动方式"></a>分布式训练启动方式</h4><p>上述过程我们采用PyTorch的torch.multiprocessing包（<a href="https://link.zhihu.com/?target=https://pytorch.org/docs/stable/multiprocessing.html%23multiprocessing-doc">Multiprocessing package - torch.multiprocessing</a>）来启动分布式训练，目前官方给出的ImageNet训练例子是采用这种方式的，具体见<a href="https://link.zhihu.com/?target=https://github.com/pytorch/examples/tree/master/imagenet">examples&#x2F;imagenet at main · pytorch&#x2F;examples</a>，detectron2库也是采用这种方式启动：<a href="https://link.zhihu.com/?target=https://github.com/facebookresearch/detectron2/blob/main/detectron2/engine/launch.py">https://github.com/facebookresearch/detectron2/blob/main/detectron2/engine/launch.py</a>。如果使用<code>torch.multiprocessing.spawn</code>启动，要注意送进入的训练function必须是<code>fn(i,*args)</code> 这种格式，其中第一个参数<code>i</code>指代的是当前节点的进程编号，这个参数其实就充当了<code>local_rank</code>, 所谓的<code>local_rank</code>是指的训练进程在当前节点的序号，前面说的<code>rank</code>其实是全局的进程序号，这个参数很重要，因为我们要根据这个参数来设置每个进程所使用的device设备，一般情况下，我们就直接认为<code>local_rank</code>即为所采用的GPU编号，设置如下：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>set_device<span class="token punctuation">(</span>args<span class="token punctuation">.</span>local_rank<span class="token punctuation">)</span>  <span class="token comment"># before your code runs</span><span class="token comment"># set DDP</span>model <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>parallel<span class="token punctuation">.</span>DistributedDataParallel<span class="token punctuation">(</span>model<span class="token punctuation">,</span> device_ids<span class="token operator">=</span><span class="token punctuation">[</span>local_rank<span class="token punctuation">]</span><span class="token punctuation">,</span> output_device<span class="token operator">=</span>local_rank<span class="token punctuation">)</span><span class="token comment"># 或者</span><span class="token keyword">with</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>device<span class="token punctuation">(</span>args<span class="token punctuation">.</span>local_rank<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment"># your code to run</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>除了采用**<code>mp.spawn</code><strong>，我们还可以采用</strong><code>torch.distributed.launch</code>**来启动程序（<a href="https://link.zhihu.com/?target=https://pytorch.org/docs/stable/distributed.html%23launch-utility">Distributed communication package - torch.distributed</a>），这个是更常用的启动方式。比如对于单机多卡训练，其启动方式如下：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">python <span class="token operator">-</span>m torch<span class="token punctuation">.</span>distributed<span class="token punctuation">.</span>launch <span class="token operator">-</span><span class="token operator">-</span>nproc_per_node<span class="token operator">=</span>NUM_GPUS_YOU_HAVE           YOUR_TRAINING_SCRIPT<span class="token punctuation">.</span>py <span class="token punctuation">(</span><span class="token operator">-</span><span class="token operator">-</span>arg1 <span class="token operator">-</span><span class="token operator">-</span>arg2 <span class="token operator">-</span><span class="token operator">-</span>arg3 <span class="token keyword">and</span> <span class="token builtin">all</span> other           arguments of your training script<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>其中<code>NUM_GPUS_YOU_HAVE</code>是GPU的总量，而<code>YOUR_TRAINING_SCRIPT.py</code>是训练的脚本，其和上述基本一致，不过区别是采用<code>torch.distributed.launch</code>启动，会自动设置一些环境变量（<a href="https://link.zhihu.com/?target=https://github.com/pytorch/pytorch/blob/master/torch/distributed/run.py%23L211">https://github.com/pytorch/pytorch/blob/master/torch/distributed/run.py#L211</a>），比如我们需要的<code>RANK</code>和<code>WORLD_SIZE</code> 就直接可以从环境变量中获取：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">rank <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>os<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">"RANK"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>world_size <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>os<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">'WORLD_SIZE'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>对于<code>local_rank</code>的获取有两种方式，一种是在训练脚本添加一个命令行参数，程序启动时会对其自动赋值：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> argparseparser <span class="token operator">=</span> argparse<span class="token punctuation">.</span>ArgumentParser<span class="token punctuation">(</span><span class="token punctuation">)</span>parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">"--local_rank"</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">)</span>args <span class="token operator">=</span> parser<span class="token punctuation">.</span>parse_args<span class="token punctuation">(</span><span class="token punctuation">)</span>local_rank <span class="token operator">=</span> args<span class="token punctuation">.</span>local_rank<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>另外一种方式采用<code>torch.distributed.launch</code>启动加上<code>--use_env=True</code>，此时情况下会设置<code>LOCAL_RANK</code>这个环境变量，我们就可以从环境变量中获取<code>local_rank</code>：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token triple-quoted-string string">"""python -m torch.distributed.launch --nproc_per_node=NUM_GPUS_YOU_HAVE --use_env=True           YOUR_TRAINING_SCRIPT.py (--arg1 --arg2 --arg3 and all other           arguments of your training script)"""</span><span class="token keyword">import</span> oslocal_rank <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>os<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">"LOCAL_RANK"</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>对于多机多卡训练，比如2个node，其启动命令如下所示：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># Node 1: (IP: 192.168.1.1, and has a free port: 1234)</span>python <span class="token operator">-</span>m torch<span class="token punctuation">.</span>distributed<span class="token punctuation">.</span>launch <span class="token operator">-</span><span class="token operator">-</span>nproc_per_node<span class="token operator">=</span>NUM_GPUS_YOU_HAVE           <span class="token operator">-</span><span class="token operator">-</span>nnodes<span class="token operator">=</span><span class="token number">2</span> <span class="token operator">-</span><span class="token operator">-</span>node_rank<span class="token operator">=</span><span class="token number">0</span> <span class="token operator">-</span><span class="token operator">-</span>master_addr<span class="token operator">=</span><span class="token string">"192.168.1.1"</span>           <span class="token operator">-</span><span class="token operator">-</span>master_port<span class="token operator">=</span><span class="token number">1234</span> YOUR_TRAINING_SCRIPT<span class="token punctuation">.</span>py <span class="token punctuation">(</span><span class="token operator">-</span><span class="token operator">-</span>arg1 <span class="token operator">-</span><span class="token operator">-</span>arg2 <span class="token operator">-</span><span class="token operator">-</span>arg3           <span class="token keyword">and</span> <span class="token builtin">all</span> other arguments of your training script<span class="token punctuation">)</span><span class="token comment"># Node 2</span>python <span class="token operator">-</span>m torch<span class="token punctuation">.</span>distributed<span class="token punctuation">.</span>launch <span class="token operator">-</span><span class="token operator">-</span>nproc_per_node<span class="token operator">=</span>NUM_GPUS_YOU_HAVE           <span class="token operator">-</span><span class="token operator">-</span>nnodes<span class="token operator">=</span><span class="token number">2</span> <span class="token operator">-</span><span class="token operator">-</span>node_rank<span class="token operator">=</span><span class="token number">1</span> <span class="token operator">-</span><span class="token operator">-</span>master_addr<span class="token operator">=</span><span class="token string">"192.168.1.1"</span>           <span class="token operator">-</span><span class="token operator">-</span>master_port<span class="token operator">=</span><span class="token number">1234</span> YOUR_TRAINING_SCRIPT<span class="token punctuation">.</span>py <span class="token punctuation">(</span><span class="token operator">-</span><span class="token operator">-</span>arg1 <span class="token operator">-</span><span class="token operator">-</span>arg2 <span class="token operator">-</span><span class="token operator">-</span>arg3           <span class="token keyword">and</span> <span class="token builtin">all</span> other arguments of your training script<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>这里<code>--nnodes</code>传入node总量，而<code>--node_rank</code> 传入node的编号，world_size&#x3D;nnodes*nproc_per_node。</p><p>不过最新版本的PyTorch推出了**<code>torchrun</code>**（<a href="https://link.zhihu.com/?target=https://pytorch.org/docs/stable/elastic/run.html%23launcher-api">https://pytorch.org/docs/stable/elastic/run.html#launcher-api</a>）来替代 <code>torch.distributed.launch</code>。 torchrun和torch.distributed.launch的用法基本一致，不过弃用了<code>--use_env</code>命令，直接将local_rank设置在环境变量中，目前最新版本的torchvision是采用torchrun启动方式，具体见 <a href="https://link.zhihu.com/?target=https://github.com/pytorch/vision/tree/main/references/classification">vision&#x2F;references&#x2F;classification at main · pytorch&#x2F;vision</a>。</p><h4 id="混合精度训练（采用apex）"><a href="#混合精度训练（采用apex）" class="headerlink" title="混合精度训练（采用apex）"></a>混合精度训练（采用apex）</h4><p>混合精度训练（混合FP32和FP16训练）可以适用更大的batch_size，而且可以利用NVIDIA Tensor Cores加速计算。采用NVIDIA的apex进行混合精度训练非常简单，只需要修改部分代码：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">rank <span class="token operator">=</span> args<span class="token punctuation">.</span>nr <span class="token operator">*</span> args<span class="token punctuation">.</span>gpus <span class="token operator">+</span> gpu    dist<span class="token punctuation">.</span>init_process_group<span class="token punctuation">(</span>        backend<span class="token operator">=</span><span class="token string">'nccl'</span><span class="token punctuation">,</span>        init_method<span class="token operator">=</span><span class="token string">'env://'</span><span class="token punctuation">,</span>        world_size<span class="token operator">=</span>args<span class="token punctuation">.</span>world_size<span class="token punctuation">,</span>        rank<span class="token operator">=</span>rank<span class="token punctuation">)</span>        torch<span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>    model <span class="token operator">=</span> ConvNet<span class="token punctuation">(</span><span class="token punctuation">)</span>    torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>set_device<span class="token punctuation">(</span>gpu<span class="token punctuation">)</span>    model<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span>gpu<span class="token punctuation">)</span>    batch_size <span class="token operator">=</span> <span class="token number">100</span>    <span class="token comment"># define loss function (criterion) and optimizer</span>    criterion <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cuda<span class="token punctuation">(</span>gpu<span class="token punctuation">)</span>    optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">1e-4</span><span class="token punctuation">)</span>    <span class="token comment"># Wrap the model</span>    <span class="token comment">##############################################################</span>    model<span class="token punctuation">,</span> optimizer <span class="token operator">=</span> amp<span class="token punctuation">.</span>initialize<span class="token punctuation">(</span>model<span class="token punctuation">,</span> optimizer<span class="token punctuation">,</span>                                       opt_level<span class="token operator">=</span><span class="token string">'O2'</span><span class="token punctuation">)</span>    model <span class="token operator">=</span> DDP<span class="token punctuation">(</span>model<span class="token punctuation">)</span>    <span class="token comment">##############################################################</span>    <span class="token comment"># Data loading code</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>    start <span class="token operator">=</span> datetime<span class="token punctuation">.</span>now<span class="token punctuation">(</span><span class="token punctuation">)</span>    total_step <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>train_loader<span class="token punctuation">)</span>    <span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>args<span class="token punctuation">.</span>epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">for</span> i<span class="token punctuation">,</span> <span class="token punctuation">(</span>images<span class="token punctuation">,</span> labels<span class="token punctuation">)</span> <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>train_loader<span class="token punctuation">)</span><span class="token punctuation">:</span>            images <span class="token operator">=</span> images<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span>non_blocking<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>            labels <span class="token operator">=</span> labels<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span>non_blocking<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>            <span class="token comment"># Forward pass</span>            outputs <span class="token operator">=</span> model<span class="token punctuation">(</span>images<span class="token punctuation">)</span>            loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> labels<span class="token punctuation">)</span>            <span class="token comment"># Backward and optimize</span>            optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment">##############################################################</span>            <span class="token keyword">with</span> amp<span class="token punctuation">.</span>scale_loss<span class="token punctuation">(</span>loss<span class="token punctuation">,</span> optimizer<span class="token punctuation">)</span> <span class="token keyword">as</span> scaled_loss<span class="token punctuation">:</span>                scaled_loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment">##############################################################</span>            optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>     <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>其实就两处变化，首先是采用<code>amp.initialize</code>来包装model和optimizer以支持混合精度训练，其中<code>opt_level</code>指的是优化级别，如果为<code>O0</code>或者<code>O3</code>不是真正的混合精度，但是可以用来确定模型效果和速度的baseline，而<code>O1</code>和<code>O2</code>是混合精度的两种设置，可以选择某个进行混合精度训练。另外一处是在进行根据梯度更新参数前，要先通过<code>amp.scale_loss</code>对梯度进行scale以防止梯度下溢（underflowing）。此外，你还可以用<code>apex.parallel.DistributedDataParallel</code>替换<code>nn.DistributedDataParallel</code>。</p><p>新版本的PyTorch已经内置混合精度训练，具体见<a href="https://link.zhihu.com/?target=https://pytorch.org/docs/stable/amp.html">https://pytorch.org/docs/stable/amp.html</a>。</p><h3 id="3-参考"><a href="#3-参考" class="headerlink" title="3. 参考"></a>3. 参考</h3><ol><li><a href="https://link.zhihu.com/?target=https://yangkky.github.io/2019/07/08/distributed-pytorch-tutorial.html">Distributed data parallel training in Pytorch</a></li><li><a href="https://link.zhihu.com/?target=https://pytorch.org/docs/stable/distributed.html">torch.distributed</a></li><li><a href="https://zhuanlan.zhihu.com/p/113694038">知乎贴</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> Tutorial </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Pytorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>TCTrack (CVPR 2022)</title>
      <link href="/2023/05/08/tctrack-cvpr-2022/"/>
      <url>/2023/05/08/tctrack-cvpr-2022/</url>
      
        <content type="html"><![CDATA[<h1 id="TCTrack-Temporal-Contexts-for-Aerial-Tracking"><a href="#TCTrack-Temporal-Contexts-for-Aerial-Tracking" class="headerlink" title="TCTrack: Temporal Contexts for Aerial Tracking"></a>TCTrack: Temporal Contexts for Aerial Tracking</h1><h3 id="0-写在前面"><a href="#0-写在前面" class="headerlink" title="0. 写在前面"></a>0. 写在前面</h3><p>过去的Tracking-by-Detection框架和基于Siamese的跟踪器缺乏利用时间上下文的能力，难以处理快速运动和严重的外观变化，这篇文章提出的方法从两个方面引入时间上下文：特征提取阶段和相似度图细化阶段，在航空跟踪任务上具有鲁棒性、稳定性和高效性，适用于AGX上的实际部署。</p><h3 id="1-基本信息"><a href="#1-基本信息" class="headerlink" title="1. 基本信息"></a>1. 基本信息</h3><blockquote><ul><li><a href="https://arxiv.org/pdf/2203.01885.pdf">论文链接</a></li><li><a href="https://github.com/vision4robotics/TCTrack">代码链接</a></li></ul></blockquote><h3 id="2-主要内容"><a href="#2-主要内容" class="headerlink" title="2. 主要内容"></a>2. 主要内容</h3><p><img src="/./images/Object_Tracking/TCTrack/1.png"></p><p><img src="/./images/Object_Tracking/TCTrack/0.png"></p><p>该框架通过引入时间上下文，极大地提高了跟踪性能。AT-Trans和在线TAdaCNN模块被证明在处理运动场景和连续时间上下文中的遮挡条件上具有显著的效果。该框架可以在比其他最先进的跟踪器更少的计算资源下提供具有竞争力的性能。该框架的实用性和部署能力在UAV上得到验证。</p><p><img src="/./images/Object_Tracking/TCTrack/2.png"></p><p><img src="/./images/Object_Tracking/TCTrack/3.png"></p><h3 id="3-实验结果"><a href="#3-实验结果" class="headerlink" title="3. 实验结果"></a>3. 实验结果</h3><p>TCTrack 有效且高效：对四个空中跟踪基准的评估显示了其令人印象深刻的性能；真实世界的无人机测试显示其在 NVIDIA Jetson AGX Xavier 上的速度超过 27 FPS。</p><p><img src="/./images/Object_Tracking/TCTrack/4.png"></p><p><img src="/./images/Object_Tracking/TCTrack/5.png"></p><p><img src="/./images/Object_Tracking/TCTrack/6.png"></p>]]></content>
      
      
      <categories>
          
          <category> Computer Vision </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Object Tracking </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>UnetFormer (ISPRS)</title>
      <link href="/2023/04/28/unetformer-isprs/"/>
      <url>/2023/04/28/unetformer-isprs/</url>
      
        <content type="html"><![CDATA[<h1 id="UNetFormer-A-UNet-like-Transformer-for-Efficient-Semantic-Segmentation-of-Remote-Sensing-Urban-Scene-Imagery"><a href="#UNetFormer-A-UNet-like-Transformer-for-Efficient-Semantic-Segmentation-of-Remote-Sensing-Urban-Scene-Imagery" class="headerlink" title="UNetFormer: A UNet-like Transformer for Efficient Semantic Segmentation of Remote Sensing Urban Scene Imagery"></a>UNetFormer: A UNet-like Transformer for Efficient Semantic Segmentation of Remote Sensing Urban Scene Imagery</h1><h3 id="0-写在前面"><a href="#0-写在前面" class="headerlink" title="0. 写在前面"></a>0. 写在前面</h3><p>这篇文章提出了基于UNet的Transformer（UNetFormer）算法，通过使用一个由CNN构成的编码器和一个由Transformer构成的解码器的混合架构，实现了高效的遥感城市场景图像语义分割，相较于CNN范式性能具有显著提升。</p><h3 id="1-基本信息"><a href="#1-基本信息" class="headerlink" title="1. 基本信息"></a>1. 基本信息</h3><blockquote><ul><li><a href="https://arxiv.org/ftp/arxiv/papers/2109/2109.08937.pdf">论文链接</a></li><li><a href="https://github.com/WangLibo1995/GeoSeg">代码链接</a></li></ul></blockquote><h3 id="2-主要内容"><a href="#2-主要内容" class="headerlink" title="2. 主要内容"></a>2. 主要内容</h3><p><img src="/./images/semantic_segmentation/UnetFormer/0.png"></p><p>ResNet18由四个阶段的Resblocks组成，每阶段以2的比例因子对feature map进行下采样。每一阶段生成的特征图都与解码器对应的特征图进行1×1卷积（通道数为64），即跳接。具体来说，通过加权求和将残差块产生的特征与解码器的GLTB（全局-局部transfomer块）产生的特征进行聚合。加权和操作根据两个特征对分割精度的贡献有选择地对它们加权，从而学习更一般性的融合特征。加权和操作的公式为：</p><p><img src="/./images/semantic_segmentation/UnetFormer/2.png"></p><p>为了捕捉全局上下文，在网络末端附加单个注意力块 (Wang et al., 2018)，但无法捕捉多尺度的全局特征；引入transformer作为编码器(Chen et al.， 2021b)，但显著增加了复杂度，并丢失了空间细节。相比之下，在提出的UNetFormer中，利用三个GLTB和一个特征细化头来构建一个轻量级的基于transformer的解码器，如上图所示。通过这种分层和轻量级的设计，解码器能够在多个尺度上捕捉全局和局部上下文，同时保持高效率。</p><p><img src="/./images/semantic_segmentation/UnetFormer/1.png"></p><p>GLTB由全局-局部注意、MLP、两个batchnorm层和两个加和操作组成，全局分支中的WMHSA来自Swin提出的窗口多头自注意。</p><p><strong>Efficient Global-local attention</strong>：局部分支是一个较浅层的结构，如下图右边蓝色框，它使用两个并行的卷积层来提取局部上下文，内核大小分别为3和1。然后在最终的求和操作之前附加两个batchnorm。</p><p><img src="/./images/semantic_segmentation/UnetFormer/3.png"></p><p>全局分支如上图左侧绿色框，首先使用一个标准1×1卷积层将输入的2D特征图的通道数扩展到三倍。然后，应用窗口划分操作将1D序列划分为Q, K, V。通道数C设为64，窗口大小w和头的数量h都设为8。</p><p><strong>cross-shaped window context interaction module</strong>：Swin Transformer引入了一个额外的可移动Transformer块来挖掘局部窗口之间的关系。尽管捕捉跨窗口关系的能力增加了，但计算量也大幅增加。在本文中，提出了一个十字形窗口上下文交互模块来捕获跨窗口关系，具有较高的计算效率。</p><p><img src="/./images/semantic_segmentation/UnetFormer/4.png"></p><p>将水平平均池化层和垂直平均池化层产生的两种特征图融合，从而获取全局上下文。具体来说，水平平均池层建立了窗口之间的水平关系。对于窗口1中的任何一点 P1 ，它对窗口2中P2 的依赖可以建模为：</p><p><img src="/./images/semantic_segmentation/UnetFormer/5.png"></p><p>D表示自注意计算，它可以在一个局部窗口中对像素对的依赖性建模。对于M×M输入(M表示窗口的数量)，通过连接更多的中间窗口，如窗口2和窗口3，任意两个窗口之间的长期依赖可以建模。因此，十字形窗口上下文交互模块可以对窗口的远程依赖关系建模，从而捕获全局上下文。</p><p><strong>Feature refinement head (特征细化头)</strong> ：第一个Resblock产生的浅层特征保留了丰富的城市场景空间细节，但缺乏语义内容；而深层的全局-局部特征提供了精确的语义信息，但空间分辨率较粗。对这两个特征直接求和，虽然速度快，但会降低分割精度。在本文中，开发了一个特征细化头FRH，以缩小两个特征之间的语义差距，进一步提高准确性。</p><p>首先对两个特征进行加权和运算，以充分利用精确的语义信息和空间细节。然后选择融合特征作为FRH的输入。其次，构建了两条路径来加强信道和空间特征表示。</p><p><img src="/./images/semantic_segmentation/UnetFormer/6.png"></p><p><strong>损失函数：</strong></p><p>主损失</p><p><img src="/./images/semantic_segmentation/UnetFormer/7.png"></p><p>辅助损失</p><p><img src="/./images/semantic_segmentation/UnetFormer/8.png"></p><h3 id="3-源码解析"><a href="#3-源码解析" class="headerlink" title="3. 源码解析"></a>3. 源码解析</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F<span class="token keyword">from</span> einops <span class="token keyword">import</span> rearrange<span class="token punctuation">,</span> repeat<span class="token keyword">from</span> timm<span class="token punctuation">.</span>models<span class="token punctuation">.</span>layers <span class="token keyword">import</span> DropPath<span class="token punctuation">,</span> to_2tuple<span class="token punctuation">,</span> trunc_normal_<span class="token keyword">import</span> timm<span class="token keyword">class</span> <span class="token class-name">ConvBNReLU</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> dilation<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> norm_layer<span class="token operator">=</span>nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>ConvBNReLU<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span>kernel_size<span class="token punctuation">,</span> bias<span class="token operator">=</span>bias<span class="token punctuation">,</span>                      dilation<span class="token operator">=</span>dilation<span class="token punctuation">,</span> stride<span class="token operator">=</span>stride<span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token punctuation">(</span><span class="token punctuation">(</span>stride <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">+</span> dilation <span class="token operator">*</span> <span class="token punctuation">(</span>kernel_size <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">//</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            norm_layer<span class="token punctuation">(</span>out_channels<span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU6<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token punctuation">)</span><span class="token keyword">class</span> <span class="token class-name">ConvBN</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> dilation<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> norm_layer<span class="token operator">=</span>nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>ConvBN<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span>kernel_size<span class="token punctuation">,</span> bias<span class="token operator">=</span>bias<span class="token punctuation">,</span>                      dilation<span class="token operator">=</span>dilation<span class="token punctuation">,</span> stride<span class="token operator">=</span>stride<span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token punctuation">(</span><span class="token punctuation">(</span>stride <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">+</span> dilation <span class="token operator">*</span> <span class="token punctuation">(</span>kernel_size <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">//</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            norm_layer<span class="token punctuation">(</span>out_channels<span class="token punctuation">)</span>        <span class="token punctuation">)</span><span class="token keyword">class</span> <span class="token class-name">Conv</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> dilation<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>Conv<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span>kernel_size<span class="token punctuation">,</span> bias<span class="token operator">=</span>bias<span class="token punctuation">,</span>                      dilation<span class="token operator">=</span>dilation<span class="token punctuation">,</span> stride<span class="token operator">=</span>stride<span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token punctuation">(</span><span class="token punctuation">(</span>stride <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">+</span> dilation <span class="token operator">*</span> <span class="token punctuation">(</span>kernel_size <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">//</span> <span class="token number">2</span><span class="token punctuation">)</span>        <span class="token punctuation">)</span><span class="token keyword">class</span> <span class="token class-name">SeparableConvBNReLU</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> dilation<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>                 norm_layer<span class="token operator">=</span>nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>SeparableConvBNReLU<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> in_channels<span class="token punctuation">,</span> kernel_size<span class="token punctuation">,</span> stride<span class="token operator">=</span>stride<span class="token punctuation">,</span> dilation<span class="token operator">=</span>dilation<span class="token punctuation">,</span>                      padding<span class="token operator">=</span><span class="token punctuation">(</span><span class="token punctuation">(</span>stride <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">+</span> dilation <span class="token operator">*</span> <span class="token punctuation">(</span>kernel_size <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">//</span> <span class="token number">2</span><span class="token punctuation">,</span>                      groups<span class="token operator">=</span>in_channels<span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            norm_layer<span class="token punctuation">(</span>out_channels<span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU6<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token punctuation">)</span><span class="token keyword">class</span> <span class="token class-name">SeparableConvBN</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> dilation<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>                 norm_layer<span class="token operator">=</span>nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>SeparableConvBN<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> in_channels<span class="token punctuation">,</span> kernel_size<span class="token punctuation">,</span> stride<span class="token operator">=</span>stride<span class="token punctuation">,</span> dilation<span class="token operator">=</span>dilation<span class="token punctuation">,</span>                      padding<span class="token operator">=</span><span class="token punctuation">(</span><span class="token punctuation">(</span>stride <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">+</span> dilation <span class="token operator">*</span> <span class="token punctuation">(</span>kernel_size <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">//</span> <span class="token number">2</span><span class="token punctuation">,</span>                      groups<span class="token operator">=</span>in_channels<span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            norm_layer<span class="token punctuation">(</span>out_channels<span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>        <span class="token punctuation">)</span><span class="token keyword">class</span> <span class="token class-name">SeparableConv</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> dilation<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>SeparableConv<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> in_channels<span class="token punctuation">,</span> kernel_size<span class="token punctuation">,</span> stride<span class="token operator">=</span>stride<span class="token punctuation">,</span> dilation<span class="token operator">=</span>dilation<span class="token punctuation">,</span>                      padding<span class="token operator">=</span><span class="token punctuation">(</span><span class="token punctuation">(</span>stride <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">+</span> dilation <span class="token operator">*</span> <span class="token punctuation">(</span>kernel_size <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">//</span> <span class="token number">2</span><span class="token punctuation">,</span>                      groups<span class="token operator">=</span>in_channels<span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>        <span class="token punctuation">)</span><span class="token keyword">class</span> <span class="token class-name">Mlp</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_features<span class="token punctuation">,</span> hidden_features<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> act_layer<span class="token operator">=</span>nn<span class="token punctuation">.</span>ReLU6<span class="token punctuation">,</span> drop<span class="token operator">=</span><span class="token number">0.</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        out_features <span class="token operator">=</span> out_features <span class="token keyword">or</span> in_features        hidden_features <span class="token operator">=</span> hidden_features <span class="token keyword">or</span> in_features        self<span class="token punctuation">.</span>fc1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_features<span class="token punctuation">,</span> hidden_features<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>act <span class="token operator">=</span> act_layer<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>fc2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>hidden_features<span class="token punctuation">,</span> out_features<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>drop <span class="token operator">=</span> nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>drop<span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>fc1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>act<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>drop<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>fc2<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>drop<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">return</span> x<span class="token keyword">class</span> <span class="token class-name">GlobalLocalAttention</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>                 dim<span class="token operator">=</span><span class="token number">256</span><span class="token punctuation">,</span>                 num_heads<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">,</span>                 qkv_bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>                 window_size<span class="token operator">=</span><span class="token number">8</span><span class="token punctuation">,</span>                 relative_pos_embedding<span class="token operator">=</span><span class="token boolean">True</span>                 <span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>num_heads <span class="token operator">=</span> num_heads        head_dim <span class="token operator">=</span> dim <span class="token operator">//</span> self<span class="token punctuation">.</span>num_heads        self<span class="token punctuation">.</span>scale <span class="token operator">=</span> head_dim <span class="token operator">**</span> <span class="token operator">-</span><span class="token number">0.5</span>        self<span class="token punctuation">.</span>ws <span class="token operator">=</span> window_size        self<span class="token punctuation">.</span>qkv <span class="token operator">=</span> Conv<span class="token punctuation">(</span>dim<span class="token punctuation">,</span> <span class="token number">3</span><span class="token operator">*</span>dim<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> bias<span class="token operator">=</span>qkv_bias<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>local1 <span class="token operator">=</span> ConvBN<span class="token punctuation">(</span>dim<span class="token punctuation">,</span> dim<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>local2 <span class="token operator">=</span> ConvBN<span class="token punctuation">(</span>dim<span class="token punctuation">,</span> dim<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>proj <span class="token operator">=</span> SeparableConvBN<span class="token punctuation">(</span>dim<span class="token punctuation">,</span> dim<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span>window_size<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>attn_x <span class="token operator">=</span> nn<span class="token punctuation">.</span>AvgPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token punctuation">(</span>window_size<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>  padding<span class="token operator">=</span><span class="token punctuation">(</span>window_size<span class="token operator">//</span><span class="token number">2</span> <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>attn_y <span class="token operator">=</span> nn<span class="token punctuation">.</span>AvgPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> window_size<span class="token punctuation">)</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> window_size<span class="token operator">//</span><span class="token number">2</span> <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>relative_pos_embedding <span class="token operator">=</span> relative_pos_embedding        <span class="token keyword">if</span> self<span class="token punctuation">.</span>relative_pos_embedding<span class="token punctuation">:</span>            <span class="token comment"># define a parameter table of relative position bias</span>            self<span class="token punctuation">.</span>relative_position_bias_table <span class="token operator">=</span> nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>                torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">2</span> <span class="token operator">*</span> window_size <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token punctuation">(</span><span class="token number">2</span> <span class="token operator">*</span> window_size <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> num_heads<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># 2*Wh-1 * 2*Ww-1, nH</span>            <span class="token comment"># get pair-wise relative position index for each token inside the window</span>            coords_h <span class="token operator">=</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>self<span class="token punctuation">.</span>ws<span class="token punctuation">)</span>            coords_w <span class="token operator">=</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>self<span class="token punctuation">.</span>ws<span class="token punctuation">)</span>            coords <span class="token operator">=</span> torch<span class="token punctuation">.</span>stack<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>meshgrid<span class="token punctuation">(</span><span class="token punctuation">[</span>coords_h<span class="token punctuation">,</span> coords_w<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># 2, Wh, Ww</span>            coords_flatten <span class="token operator">=</span> torch<span class="token punctuation">.</span>flatten<span class="token punctuation">(</span>coords<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment"># 2, Wh*Ww</span>            relative_coords <span class="token operator">=</span> coords_flatten<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">]</span> <span class="token operator">-</span> coords_flatten<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span>  <span class="token comment"># 2, Wh*Ww, Wh*Ww</span>            relative_coords <span class="token operator">=</span> relative_coords<span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>contiguous<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># Wh*Ww, Wh*Ww, 2</span>            relative_coords<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">+=</span> self<span class="token punctuation">.</span>ws <span class="token operator">-</span> <span class="token number">1</span>  <span class="token comment"># shift to start from 0</span>            relative_coords<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">+=</span> self<span class="token punctuation">.</span>ws <span class="token operator">-</span> <span class="token number">1</span>            relative_coords<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">*=</span> <span class="token number">2</span> <span class="token operator">*</span> self<span class="token punctuation">.</span>ws <span class="token operator">-</span> <span class="token number">1</span>            relative_position_index <span class="token operator">=</span> relative_coords<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment"># Wh*Ww, Wh*Ww</span>            self<span class="token punctuation">.</span>register_buffer<span class="token punctuation">(</span><span class="token string">"relative_position_index"</span><span class="token punctuation">,</span> relative_position_index<span class="token punctuation">)</span>            trunc_normal_<span class="token punctuation">(</span>self<span class="token punctuation">.</span>relative_position_bias_table<span class="token punctuation">,</span> std<span class="token operator">=</span><span class="token number">.02</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">pad</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> ps<span class="token punctuation">)</span><span class="token punctuation">:</span>        _<span class="token punctuation">,</span> _<span class="token punctuation">,</span> H<span class="token punctuation">,</span> W <span class="token operator">=</span> x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">if</span> W <span class="token operator">%</span> ps <span class="token operator">!=</span> <span class="token number">0</span><span class="token punctuation">:</span>            x <span class="token operator">=</span> F<span class="token punctuation">.</span>pad<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> ps <span class="token operator">-</span> W <span class="token operator">%</span> ps<span class="token punctuation">)</span><span class="token punctuation">,</span> mode<span class="token operator">=</span><span class="token string">'reflect'</span><span class="token punctuation">)</span>        <span class="token keyword">if</span> H <span class="token operator">%</span> ps <span class="token operator">!=</span> <span class="token number">0</span><span class="token punctuation">:</span>            x <span class="token operator">=</span> F<span class="token punctuation">.</span>pad<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> ps <span class="token operator">-</span> H <span class="token operator">%</span> ps<span class="token punctuation">)</span><span class="token punctuation">,</span> mode<span class="token operator">=</span><span class="token string">'reflect'</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> x    <span class="token keyword">def</span> <span class="token function">pad_out</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        x <span class="token operator">=</span> F<span class="token punctuation">.</span>pad<span class="token punctuation">(</span>x<span class="token punctuation">,</span> pad<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> mode<span class="token operator">=</span><span class="token string">'reflect'</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> x    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        B<span class="token punctuation">,</span> C<span class="token punctuation">,</span> H<span class="token punctuation">,</span> W <span class="token operator">=</span> x<span class="token punctuation">.</span>shape        local <span class="token operator">=</span> self<span class="token punctuation">.</span>local2<span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token operator">+</span> self<span class="token punctuation">.</span>local1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>pad<span class="token punctuation">(</span>x<span class="token punctuation">,</span> self<span class="token punctuation">.</span>ws<span class="token punctuation">)</span>        B<span class="token punctuation">,</span> C<span class="token punctuation">,</span> Hp<span class="token punctuation">,</span> Wp <span class="token operator">=</span> x<span class="token punctuation">.</span>shape        qkv <span class="token operator">=</span> self<span class="token punctuation">.</span>qkv<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        q<span class="token punctuation">,</span> k<span class="token punctuation">,</span> v <span class="token operator">=</span> rearrange<span class="token punctuation">(</span>qkv<span class="token punctuation">,</span> <span class="token string">'b (qkv h d) (hh ws1) (ww ws2) -> qkv (b hh ww) h (ws1 ws2) d'</span><span class="token punctuation">,</span> h<span class="token operator">=</span>self<span class="token punctuation">.</span>num_heads<span class="token punctuation">,</span>                            d<span class="token operator">=</span>C<span class="token operator">//</span>self<span class="token punctuation">.</span>num_heads<span class="token punctuation">,</span> hh<span class="token operator">=</span>Hp<span class="token operator">//</span>self<span class="token punctuation">.</span>ws<span class="token punctuation">,</span> ww<span class="token operator">=</span>Wp<span class="token operator">//</span>self<span class="token punctuation">.</span>ws<span class="token punctuation">,</span> qkv<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> ws1<span class="token operator">=</span>self<span class="token punctuation">.</span>ws<span class="token punctuation">,</span> ws2<span class="token operator">=</span>self<span class="token punctuation">.</span>ws<span class="token punctuation">)</span>        dots <span class="token operator">=</span> <span class="token punctuation">(</span>q @ k<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">*</span> self<span class="token punctuation">.</span>scale        <span class="token keyword">if</span> self<span class="token punctuation">.</span>relative_pos_embedding<span class="token punctuation">:</span>            relative_position_bias <span class="token operator">=</span> self<span class="token punctuation">.</span>relative_position_bias_table<span class="token punctuation">[</span>self<span class="token punctuation">.</span>relative_position_index<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span>                self<span class="token punctuation">.</span>ws <span class="token operator">*</span> self<span class="token punctuation">.</span>ws<span class="token punctuation">,</span> self<span class="token punctuation">.</span>ws <span class="token operator">*</span> self<span class="token punctuation">.</span>ws<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment"># Wh*Ww,Wh*Ww,nH</span>            relative_position_bias <span class="token operator">=</span> relative_position_bias<span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>contiguous<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># nH, Wh*Ww, Wh*Ww</span>            dots <span class="token operator">+=</span> relative_position_bias<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>        attn <span class="token operator">=</span> dots<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>        attn <span class="token operator">=</span> attn @ v        attn <span class="token operator">=</span> rearrange<span class="token punctuation">(</span>attn<span class="token punctuation">,</span> <span class="token string">'(b hh ww) h (ws1 ws2) d -> b (h d) (hh ws1) (ww ws2)'</span><span class="token punctuation">,</span> h<span class="token operator">=</span>self<span class="token punctuation">.</span>num_heads<span class="token punctuation">,</span>                         d<span class="token operator">=</span>C<span class="token operator">//</span>self<span class="token punctuation">.</span>num_heads<span class="token punctuation">,</span> hh<span class="token operator">=</span>Hp<span class="token operator">//</span>self<span class="token punctuation">.</span>ws<span class="token punctuation">,</span> ww<span class="token operator">=</span>Wp<span class="token operator">//</span>self<span class="token punctuation">.</span>ws<span class="token punctuation">,</span> ws1<span class="token operator">=</span>self<span class="token punctuation">.</span>ws<span class="token punctuation">,</span> ws2<span class="token operator">=</span>self<span class="token punctuation">.</span>ws<span class="token punctuation">)</span>        attn <span class="token operator">=</span> attn<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span>H<span class="token punctuation">,</span> <span class="token punctuation">:</span>W<span class="token punctuation">]</span>        out <span class="token operator">=</span> self<span class="token punctuation">.</span>attn_x<span class="token punctuation">(</span>F<span class="token punctuation">.</span>pad<span class="token punctuation">(</span>attn<span class="token punctuation">,</span> pad<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> mode<span class="token operator">=</span><span class="token string">'reflect'</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">+</span> \              self<span class="token punctuation">.</span>attn_y<span class="token punctuation">(</span>F<span class="token punctuation">.</span>pad<span class="token punctuation">(</span>attn<span class="token punctuation">,</span> pad<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> mode<span class="token operator">=</span><span class="token string">'reflect'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        out <span class="token operator">=</span> out <span class="token operator">+</span> local        out <span class="token operator">=</span> self<span class="token punctuation">.</span>pad_out<span class="token punctuation">(</span>out<span class="token punctuation">)</span>        out <span class="token operator">=</span> self<span class="token punctuation">.</span>proj<span class="token punctuation">(</span>out<span class="token punctuation">)</span>        <span class="token comment"># print(out.size())</span>        out <span class="token operator">=</span> out<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span>H<span class="token punctuation">,</span> <span class="token punctuation">:</span>W<span class="token punctuation">]</span>        <span class="token keyword">return</span> out<span class="token keyword">class</span> <span class="token class-name">Block</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">256</span><span class="token punctuation">,</span> num_heads<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">,</span>  mlp_ratio<span class="token operator">=</span><span class="token number">4.</span><span class="token punctuation">,</span> qkv_bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> drop<span class="token operator">=</span><span class="token number">0.</span><span class="token punctuation">,</span> attn_drop<span class="token operator">=</span><span class="token number">0.</span><span class="token punctuation">,</span>                 drop_path<span class="token operator">=</span><span class="token number">0.</span><span class="token punctuation">,</span> act_layer<span class="token operator">=</span>nn<span class="token punctuation">.</span>ReLU6<span class="token punctuation">,</span> norm_layer<span class="token operator">=</span>nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">,</span> window_size<span class="token operator">=</span><span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>norm1 <span class="token operator">=</span> norm_layer<span class="token punctuation">(</span>dim<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>attn <span class="token operator">=</span> GlobalLocalAttention<span class="token punctuation">(</span>dim<span class="token punctuation">,</span> num_heads<span class="token operator">=</span>num_heads<span class="token punctuation">,</span> qkv_bias<span class="token operator">=</span>qkv_bias<span class="token punctuation">,</span> window_size<span class="token operator">=</span>window_size<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>drop_path <span class="token operator">=</span> DropPath<span class="token punctuation">(</span>drop_path<span class="token punctuation">)</span> <span class="token keyword">if</span> drop_path <span class="token operator">></span> <span class="token number">0.</span> <span class="token keyword">else</span> nn<span class="token punctuation">.</span>Identity<span class="token punctuation">(</span><span class="token punctuation">)</span>        mlp_hidden_dim <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>dim <span class="token operator">*</span> mlp_ratio<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>mlp <span class="token operator">=</span> Mlp<span class="token punctuation">(</span>in_features<span class="token operator">=</span>dim<span class="token punctuation">,</span> hidden_features<span class="token operator">=</span>mlp_hidden_dim<span class="token punctuation">,</span> out_features<span class="token operator">=</span>dim<span class="token punctuation">,</span> act_layer<span class="token operator">=</span>act_layer<span class="token punctuation">,</span> drop<span class="token operator">=</span>drop<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>norm2 <span class="token operator">=</span> norm_layer<span class="token punctuation">(</span>dim<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        x <span class="token operator">=</span> x <span class="token operator">+</span> self<span class="token punctuation">.</span>drop_path<span class="token punctuation">(</span>self<span class="token punctuation">.</span>attn<span class="token punctuation">(</span>self<span class="token punctuation">.</span>norm1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> x <span class="token operator">+</span> self<span class="token punctuation">.</span>drop_path<span class="token punctuation">(</span>self<span class="token punctuation">.</span>mlp<span class="token punctuation">(</span>self<span class="token punctuation">.</span>norm2<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> x<span class="token keyword">class</span> <span class="token class-name">WF</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_channels<span class="token operator">=</span><span class="token number">128</span><span class="token punctuation">,</span> decode_channels<span class="token operator">=</span><span class="token number">128</span><span class="token punctuation">,</span> eps<span class="token operator">=</span><span class="token number">1e-8</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>WF<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>pre_conv <span class="token operator">=</span> Conv<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> decode_channels<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>weights <span class="token operator">=</span> nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>eps <span class="token operator">=</span> eps        self<span class="token punctuation">.</span>post_conv <span class="token operator">=</span> ConvBNReLU<span class="token punctuation">(</span>decode_channels<span class="token punctuation">,</span> decode_channels<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> res<span class="token punctuation">)</span><span class="token punctuation">:</span>        x <span class="token operator">=</span> F<span class="token punctuation">.</span>interpolate<span class="token punctuation">(</span>x<span class="token punctuation">,</span> scale_factor<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> mode<span class="token operator">=</span><span class="token string">'bilinear'</span><span class="token punctuation">,</span> align_corners<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>        weights <span class="token operator">=</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>weights<span class="token punctuation">)</span>        fuse_weights <span class="token operator">=</span> weights <span class="token operator">/</span> <span class="token punctuation">(</span>torch<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>weights<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span> <span class="token operator">+</span> self<span class="token punctuation">.</span>eps<span class="token punctuation">)</span>        x <span class="token operator">=</span> fuse_weights<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">*</span> self<span class="token punctuation">.</span>pre_conv<span class="token punctuation">(</span>res<span class="token punctuation">)</span> <span class="token operator">+</span> fuse_weights<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">*</span> x        x <span class="token operator">=</span> self<span class="token punctuation">.</span>post_conv<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">return</span> x<span class="token keyword">class</span> <span class="token class-name">FeatureRefinementHead</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_channels<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span> decode_channels<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>pre_conv <span class="token operator">=</span> Conv<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> decode_channels<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>weights <span class="token operator">=</span> nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>eps <span class="token operator">=</span> <span class="token number">1e-8</span>        self<span class="token punctuation">.</span>post_conv <span class="token operator">=</span> ConvBNReLU<span class="token punctuation">(</span>decode_channels<span class="token punctuation">,</span> decode_channels<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>pa <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>decode_channels<span class="token punctuation">,</span> decode_channels<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> groups<span class="token operator">=</span>decode_channels<span class="token punctuation">)</span><span class="token punctuation">,</span>                                nn<span class="token punctuation">.</span>Sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>ca <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>AdaptiveAvgPool2d<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                                Conv<span class="token punctuation">(</span>decode_channels<span class="token punctuation">,</span> decode_channels<span class="token operator">//</span><span class="token number">16</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                                nn<span class="token punctuation">.</span>ReLU6<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                                Conv<span class="token punctuation">(</span>decode_channels<span class="token operator">//</span><span class="token number">16</span><span class="token punctuation">,</span> decode_channels<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                                nn<span class="token punctuation">.</span>Sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>shortcut <span class="token operator">=</span> ConvBN<span class="token punctuation">(</span>decode_channels<span class="token punctuation">,</span> decode_channels<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>proj <span class="token operator">=</span> SeparableConvBN<span class="token punctuation">(</span>decode_channels<span class="token punctuation">,</span> decode_channels<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>act <span class="token operator">=</span> nn<span class="token punctuation">.</span>ReLU6<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> res<span class="token punctuation">)</span><span class="token punctuation">:</span>        x <span class="token operator">=</span> F<span class="token punctuation">.</span>interpolate<span class="token punctuation">(</span>x<span class="token punctuation">,</span> scale_factor<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> mode<span class="token operator">=</span><span class="token string">'bilinear'</span><span class="token punctuation">,</span> align_corners<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>        weights <span class="token operator">=</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>weights<span class="token punctuation">)</span>        fuse_weights <span class="token operator">=</span> weights <span class="token operator">/</span> <span class="token punctuation">(</span>torch<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>weights<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span> <span class="token operator">+</span> self<span class="token punctuation">.</span>eps<span class="token punctuation">)</span>        x <span class="token operator">=</span> fuse_weights<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">*</span> self<span class="token punctuation">.</span>pre_conv<span class="token punctuation">(</span>res<span class="token punctuation">)</span> <span class="token operator">+</span> fuse_weights<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">*</span> x        x <span class="token operator">=</span> self<span class="token punctuation">.</span>post_conv<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        shortcut <span class="token operator">=</span> self<span class="token punctuation">.</span>shortcut<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        pa <span class="token operator">=</span> self<span class="token punctuation">.</span>pa<span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token operator">*</span> x        ca <span class="token operator">=</span> self<span class="token punctuation">.</span>ca<span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token operator">*</span> x        x <span class="token operator">=</span> pa <span class="token operator">+</span> ca        x <span class="token operator">=</span> self<span class="token punctuation">.</span>proj<span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token operator">+</span> shortcut        x <span class="token operator">=</span> self<span class="token punctuation">.</span>act<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">return</span> x<span class="token keyword">class</span> <span class="token class-name">AuxHead</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_channels<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span> num_classes<span class="token operator">=</span><span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>conv <span class="token operator">=</span> ConvBNReLU<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> in_channels<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>drop <span class="token operator">=</span> nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span><span class="token number">0.1</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>conv_out <span class="token operator">=</span> Conv<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> num_classes<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> h<span class="token punctuation">,</span> w<span class="token punctuation">)</span><span class="token punctuation">:</span>        feat <span class="token operator">=</span> self<span class="token punctuation">.</span>conv<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        feat <span class="token operator">=</span> self<span class="token punctuation">.</span>drop<span class="token punctuation">(</span>feat<span class="token punctuation">)</span>        feat <span class="token operator">=</span> self<span class="token punctuation">.</span>conv_out<span class="token punctuation">(</span>feat<span class="token punctuation">)</span>        feat <span class="token operator">=</span> F<span class="token punctuation">.</span>interpolate<span class="token punctuation">(</span>feat<span class="token punctuation">,</span> size<span class="token operator">=</span><span class="token punctuation">(</span>h<span class="token punctuation">,</span> w<span class="token punctuation">)</span><span class="token punctuation">,</span> mode<span class="token operator">=</span><span class="token string">'bilinear'</span><span class="token punctuation">,</span> align_corners<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> feat<span class="token keyword">class</span> <span class="token class-name">Decoder</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>                 encoder_channels<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                 decode_channels<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span>                 dropout<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">,</span>                 window_size<span class="token operator">=</span><span class="token number">8</span><span class="token punctuation">,</span>                 num_classes<span class="token operator">=</span><span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>Decoder<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>pre_conv <span class="token operator">=</span> ConvBN<span class="token punctuation">(</span>encoder_channels<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> decode_channels<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>b4 <span class="token operator">=</span> Block<span class="token punctuation">(</span>dim<span class="token operator">=</span>decode_channels<span class="token punctuation">,</span> num_heads<span class="token operator">=</span><span class="token number">8</span><span class="token punctuation">,</span> window_size<span class="token operator">=</span>window_size<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>b3 <span class="token operator">=</span> Block<span class="token punctuation">(</span>dim<span class="token operator">=</span>decode_channels<span class="token punctuation">,</span> num_heads<span class="token operator">=</span><span class="token number">8</span><span class="token punctuation">,</span> window_size<span class="token operator">=</span>window_size<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>p3 <span class="token operator">=</span> WF<span class="token punctuation">(</span>encoder_channels<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> decode_channels<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>b2 <span class="token operator">=</span> Block<span class="token punctuation">(</span>dim<span class="token operator">=</span>decode_channels<span class="token punctuation">,</span> num_heads<span class="token operator">=</span><span class="token number">8</span><span class="token punctuation">,</span> window_size<span class="token operator">=</span>window_size<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>p2 <span class="token operator">=</span> WF<span class="token punctuation">(</span>encoder_channels<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> decode_channels<span class="token punctuation">)</span>        <span class="token keyword">if</span> self<span class="token punctuation">.</span>training<span class="token punctuation">:</span>            self<span class="token punctuation">.</span>up4 <span class="token operator">=</span> nn<span class="token punctuation">.</span>UpsamplingBilinear2d<span class="token punctuation">(</span>scale_factor<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">)</span>            self<span class="token punctuation">.</span>up3 <span class="token operator">=</span> nn<span class="token punctuation">.</span>UpsamplingBilinear2d<span class="token punctuation">(</span>scale_factor<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>            self<span class="token punctuation">.</span>aux_head <span class="token operator">=</span> AuxHead<span class="token punctuation">(</span>decode_channels<span class="token punctuation">,</span> num_classes<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>p1 <span class="token operator">=</span> FeatureRefinementHead<span class="token punctuation">(</span>encoder_channels<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">,</span> decode_channels<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>segmentation_head <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>ConvBNReLU<span class="token punctuation">(</span>decode_channels<span class="token punctuation">,</span> decode_channels<span class="token punctuation">)</span><span class="token punctuation">,</span>                                               nn<span class="token punctuation">.</span>Dropout2d<span class="token punctuation">(</span>p<span class="token operator">=</span>dropout<span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                                               Conv<span class="token punctuation">(</span>decode_channels<span class="token punctuation">,</span> num_classes<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>init_weight<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> res1<span class="token punctuation">,</span> res2<span class="token punctuation">,</span> res3<span class="token punctuation">,</span> res4<span class="token punctuation">,</span> h<span class="token punctuation">,</span> w<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">if</span> self<span class="token punctuation">.</span>training<span class="token punctuation">:</span>            x <span class="token operator">=</span> self<span class="token punctuation">.</span>b4<span class="token punctuation">(</span>self<span class="token punctuation">.</span>pre_conv<span class="token punctuation">(</span>res4<span class="token punctuation">)</span><span class="token punctuation">)</span>            h4 <span class="token operator">=</span> self<span class="token punctuation">.</span>up4<span class="token punctuation">(</span>x<span class="token punctuation">)</span>            x <span class="token operator">=</span> self<span class="token punctuation">.</span>p3<span class="token punctuation">(</span>x<span class="token punctuation">,</span> res3<span class="token punctuation">)</span>            x <span class="token operator">=</span> self<span class="token punctuation">.</span>b3<span class="token punctuation">(</span>x<span class="token punctuation">)</span>            h3 <span class="token operator">=</span> self<span class="token punctuation">.</span>up3<span class="token punctuation">(</span>x<span class="token punctuation">)</span>            x <span class="token operator">=</span> self<span class="token punctuation">.</span>p2<span class="token punctuation">(</span>x<span class="token punctuation">,</span> res2<span class="token punctuation">)</span>            x <span class="token operator">=</span> self<span class="token punctuation">.</span>b2<span class="token punctuation">(</span>x<span class="token punctuation">)</span>            h2 <span class="token operator">=</span> x            x <span class="token operator">=</span> self<span class="token punctuation">.</span>p1<span class="token punctuation">(</span>x<span class="token punctuation">,</span> res1<span class="token punctuation">)</span>            x <span class="token operator">=</span> self<span class="token punctuation">.</span>segmentation_head<span class="token punctuation">(</span>x<span class="token punctuation">)</span>            x <span class="token operator">=</span> F<span class="token punctuation">.</span>interpolate<span class="token punctuation">(</span>x<span class="token punctuation">,</span> size<span class="token operator">=</span><span class="token punctuation">(</span>h<span class="token punctuation">,</span> w<span class="token punctuation">)</span><span class="token punctuation">,</span> mode<span class="token operator">=</span><span class="token string">'bilinear'</span><span class="token punctuation">,</span> align_corners<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>            ah <span class="token operator">=</span> h4 <span class="token operator">+</span> h3 <span class="token operator">+</span> h2            ah <span class="token operator">=</span> self<span class="token punctuation">.</span>aux_head<span class="token punctuation">(</span>ah<span class="token punctuation">,</span> h<span class="token punctuation">,</span> w<span class="token punctuation">)</span>            <span class="token keyword">return</span> x<span class="token punctuation">,</span> ah        <span class="token keyword">else</span><span class="token punctuation">:</span>            x <span class="token operator">=</span> self<span class="token punctuation">.</span>b4<span class="token punctuation">(</span>self<span class="token punctuation">.</span>pre_conv<span class="token punctuation">(</span>res4<span class="token punctuation">)</span><span class="token punctuation">)</span>            x <span class="token operator">=</span> self<span class="token punctuation">.</span>p3<span class="token punctuation">(</span>x<span class="token punctuation">,</span> res3<span class="token punctuation">)</span>            x <span class="token operator">=</span> self<span class="token punctuation">.</span>b3<span class="token punctuation">(</span>x<span class="token punctuation">)</span>            x <span class="token operator">=</span> self<span class="token punctuation">.</span>p2<span class="token punctuation">(</span>x<span class="token punctuation">,</span> res2<span class="token punctuation">)</span>            x <span class="token operator">=</span> self<span class="token punctuation">.</span>b2<span class="token punctuation">(</span>x<span class="token punctuation">)</span>            x <span class="token operator">=</span> self<span class="token punctuation">.</span>p1<span class="token punctuation">(</span>x<span class="token punctuation">,</span> res1<span class="token punctuation">)</span>            x <span class="token operator">=</span> self<span class="token punctuation">.</span>segmentation_head<span class="token punctuation">(</span>x<span class="token punctuation">)</span>            x <span class="token operator">=</span> F<span class="token punctuation">.</span>interpolate<span class="token punctuation">(</span>x<span class="token punctuation">,</span> size<span class="token operator">=</span><span class="token punctuation">(</span>h<span class="token punctuation">,</span> w<span class="token punctuation">)</span><span class="token punctuation">,</span> mode<span class="token operator">=</span><span class="token string">'bilinear'</span><span class="token punctuation">,</span> align_corners<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>            <span class="token keyword">return</span> x    <span class="token keyword">def</span> <span class="token function">init_weight</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">for</span> m <span class="token keyword">in</span> self<span class="token punctuation">.</span>children<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">if</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>m<span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">)</span><span class="token punctuation">:</span>                nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>kaiming_normal_<span class="token punctuation">(</span>m<span class="token punctuation">.</span>weight<span class="token punctuation">,</span> a<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>                <span class="token keyword">if</span> m<span class="token punctuation">.</span>bias <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>                    nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>constant_<span class="token punctuation">(</span>m<span class="token punctuation">.</span>bias<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token keyword">class</span> <span class="token class-name">UNetFormer</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>                 decode_channels<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span>                 dropout<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">,</span>                 backbone_name<span class="token operator">=</span><span class="token string">'swsl_resnet18'</span><span class="token punctuation">,</span>                 pretrained<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>                 window_size<span class="token operator">=</span><span class="token number">8</span><span class="token punctuation">,</span>                 num_classes<span class="token operator">=</span><span class="token number">6</span>                 <span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>backbone <span class="token operator">=</span> timm<span class="token punctuation">.</span>create_model<span class="token punctuation">(</span>backbone_name<span class="token punctuation">,</span> features_only<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> output_stride<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>                                          out_indices<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span> pretrained<span class="token operator">=</span>pretrained<span class="token punctuation">)</span>        encoder_channels <span class="token operator">=</span> self<span class="token punctuation">.</span>backbone<span class="token punctuation">.</span>feature_info<span class="token punctuation">.</span>channels<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>decoder <span class="token operator">=</span> Decoder<span class="token punctuation">(</span>encoder_channels<span class="token punctuation">,</span> decode_channels<span class="token punctuation">,</span> dropout<span class="token punctuation">,</span> window_size<span class="token punctuation">,</span> num_classes<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        h<span class="token punctuation">,</span> w <span class="token operator">=</span> x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">:</span><span class="token punctuation">]</span>        res1<span class="token punctuation">,</span> res2<span class="token punctuation">,</span> res3<span class="token punctuation">,</span> res4 <span class="token operator">=</span> self<span class="token punctuation">.</span>backbone<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">if</span> self<span class="token punctuation">.</span>training<span class="token punctuation">:</span>            x<span class="token punctuation">,</span> ah <span class="token operator">=</span> self<span class="token punctuation">.</span>decoder<span class="token punctuation">(</span>res1<span class="token punctuation">,</span> res2<span class="token punctuation">,</span> res3<span class="token punctuation">,</span> res4<span class="token punctuation">,</span> h<span class="token punctuation">,</span> w<span class="token punctuation">)</span>            <span class="token keyword">return</span> x<span class="token punctuation">,</span> ah        <span class="token keyword">else</span><span class="token punctuation">:</span>            x <span class="token operator">=</span> self<span class="token punctuation">.</span>decoder<span class="token punctuation">(</span>res1<span class="token punctuation">,</span> res2<span class="token punctuation">,</span> res3<span class="token punctuation">,</span> res4<span class="token punctuation">,</span> h<span class="token punctuation">,</span> w<span class="token punctuation">)</span>            <span class="token keyword">return</span> x<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> Computer Vision </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Semantic Segmentation </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Git 基本操作</title>
      <link href="/2023/04/15/git-ji-ben-cao-zuo/"/>
      <url>/2023/04/15/git-ji-ben-cao-zuo/</url>
      
        <content type="html"><![CDATA[<h3 id="Git-基本操作"><a href="#Git-基本操作" class="headerlink" title="Git 基本操作"></a>Git 基本操作</h3><p>Git 的工作就是创建和保存你项目的快照及与之后的快照进行对比。</p><p>Git 常用的是以下 6 个命令：<strong>git clone</strong>、<strong>git push</strong>、<strong>git add</strong> 、<strong>git commit</strong>、<strong>git checkout</strong>、<strong>git pull</strong>，后面我们会详细介绍。</p><p><img src="/./images/Git/0.png"></p><p><strong>说明：</strong></p><ul><li>workspace：工作区</li><li>staging area：暂存区&#x2F;缓存区</li><li>local repository：版本库或本地仓库</li><li>remote repository：远程仓库</li></ul><p>一个简单的操作步骤：</p><pre class="line-numbers language-none"><code class="language-none">git initgit add .git commit<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><ul><li>git init - 初始化仓库。</li><li>git add . - 添加文件到暂存区。</li><li>git commit - 将暂存区内容添加到仓库中。</li></ul><h4 id="创建仓库命令"><a href="#创建仓库命令" class="headerlink" title="创建仓库命令"></a>创建仓库命令</h4><p>下表列出了 git 创建仓库的命令：</p><table><thead><tr><th align="left">命令</th><th align="center">说明</th></tr></thead><tbody><tr><td align="left"><code>git init</code></td><td align="center">初始化仓库</td></tr><tr><td align="left"><code>git clone</code></td><td align="center">拷贝一份远程仓库，也就是下载一个项目。</td></tr></tbody></table><h4 id="提交与修改"><a href="#提交与修改" class="headerlink" title="提交与修改"></a>提交与修改</h4><p>Git 的工作就是创建和保存你的项目的快照及与之后的快照进行对比。</p><p>下表列出了有关创建与提交你的项目的快照的命令：</p><table><thead><tr><th align="left">命令</th><th align="left">说明</th></tr></thead><tbody><tr><td align="left"><code>git add</code></td><td align="left">添加文件到暂存区</td></tr><tr><td align="left"><code>git status</code></td><td align="left">查看仓库当前的状态，显示有变更的文件。</td></tr><tr><td align="left"><code>git diff</code></td><td align="left">比较文件的不同，即暂存区和工作区的差异。</td></tr><tr><td align="left"><code>git commit</code></td><td align="left">提交暂存区到本地仓库。</td></tr><tr><td align="left"><code>git reset</code></td><td align="left">回退版本。</td></tr><tr><td align="left"><code>git rm</code></td><td align="left">将文件从暂存区和工作区中删除。</td></tr><tr><td align="left"><code>git mv</code></td><td align="left">移动或重命名工作区文件。</td></tr></tbody></table><h4 id="提交日志"><a href="#提交日志" class="headerlink" title="提交日志"></a>提交日志</h4><table><thead><tr><th align="left">命令</th><th align="left">说明</th></tr></thead><tbody><tr><td align="left"><code>git log</code></td><td align="left">查看历史提交记录</td></tr><tr><td align="left"><code>git blame &lt;file&gt;</code></td><td align="left">以列表形式查看指定文件的历史修改记录</td></tr></tbody></table><h4 id="远程操作"><a href="#远程操作" class="headerlink" title="远程操作"></a>远程操作</h4><table><thead><tr><th align="left">命令</th><th align="left">说明</th></tr></thead><tbody><tr><td align="left"><code>git remote</code></td><td align="left">远程仓库操作</td></tr><tr><td align="left"><code>git fetch</code></td><td align="left">从远程获取代码库</td></tr><tr><td align="left"><code>git pull</code></td><td align="left">下载远程代码并合并</td></tr><tr><td align="left"><code>git push</code></td><td align="left">上传远程代码并合并</td></tr></tbody></table>]]></content>
      
      
      <categories>
          
          <category> Tutorial </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Git </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>NewCRFs (CVPR2022)</title>
      <link href="/2023/03/31/newcrfs-cvpr-2022/"/>
      <url>/2023/03/31/newcrfs-cvpr-2022/</url>
      
        <content type="html"><![CDATA[<h3 id="NeW-CRFs-Neural-Window-Fully-connected-CRFs-for-Monocular-Depth-Estimation"><a href="#NeW-CRFs-Neural-Window-Fully-connected-CRFs-for-Monocular-Depth-Estimation" class="headerlink" title="NeW CRFs: Neural Window Fully-connected CRFs for Monocular Depth Estimation"></a>NeW CRFs: Neural Window Fully-connected CRFs for Monocular Depth Estimation</h3><h3 id="0-写在前面"><a href="#0-写在前面" class="headerlink" title="0. 写在前面"></a>0. 写在前面</h3><p>这篇文章开创性地将深度学习方法与条件随机场（CRFs）相结合解决单目深度估计的问题，相较于传统简单粗暴的用复杂网络直接回归深度图而言，这篇文章提出了一个全新的思路，值得在此方面开展深入的研究工作。</p><h3 id="1-论文基本信息"><a href="#1-论文基本信息" class="headerlink" title="1. 论文基本信息"></a>1. 论文基本信息</h3><blockquote><ul><li><a href="https://arxiv.org/abs/2203.01502">论文链接</a></li><li><a href="https://github.com/aliyun/NeWCRFs">代码链接</a></li></ul></blockquote><h3 id="2-论文主要内容"><a href="#2-论文主要内容" class="headerlink" title="2. 论文主要内容"></a>2. 论文主要内容</h3><p>单目深度估计是从单张RGB图预测场景深度，是一个很具有挑战性的任务。现在做这个任务的方法大都是设计越来越复杂的网络来简单粗暴地回归深度图，但本文作者采取了一个更具可解释性的方案，就是使用优化方法中的条件随机场（CRFs）。由于CRFs的计算量很大，通常只会用于计算相邻节点的能量，而很难用于计算整个图模型中所有节点之间的能量。为了借助这种全连接CRFs的强大表征力，他们采取了一种折中的方法，即将整个图模型划分为一个个小窗口，在每个窗口里面进行全连接CRFs的计算，这样就可以大大减少计算量，使全连接CRFs在深度估计这一任务上成为了可能。同时，为了更好地在节点之间进行信息传递，他们利用多头注意力机制计算了多头能量函数，然后用网络将这个能量函数优化到一个精确的深度图。</p><p>基于此，作者用视觉transformer作为encoder，神经窗口全连接条件随机场作为decoder，构建了一个bottom-up-top-down的网络架构，这个网络在KITTI、NYUv2上都取得了SOTA的性能，同时可以应用于全景图深度估计任务，在MatterPort3D上也取得了SOTA的性能。</p><p><img src="/./images/Computer_Vision/23.png"></p><p>与普通的条件随机场相比，全连接条件随机场可以建立一个图模型中每个节点之间的关联，从而更好地进行特征提取和信息传递，强大的多。所以在本项工作中，作者希望能够使用全连接条件随机场，但是，全连接条件随机场的计算量大到惊人，在一个高分辨率的图中是很难做到的。另一方面，他们考虑到，其实在进行深度估计的时候，当前节点的深度值受很远的像素影响较小，也就是说，并不那么需要建立起当前节点跟距离很远的节点之间的信息传递。</p><p>于是，作者提出了一个基于窗口的全连接条件随机场。我们将一整个图模型划分为多个基于patch的窗口，每个窗口有 N×N 个图像patch，每个patch作为一个节点，由 你n×n 个像素构成。在每个窗口中，所有的节点都互相连接，也就是全连接，而不同窗口之间没有连接。</p><p><img src="/./images/Computer_Vision/24.png"></p><p>这样一来，计算量就可以大大减少。以一张含有 h×h 个patch的图片为例，全连接条件随机场的计算复杂度与窗口全连接条件随机场的计算复杂度分别为：</p><p><img src="/./images/Computer_Vision/25.png"></p><p>但是，这种窗口划分也会引入一个问题，就是本来应该有信息传递的相邻窗口之间失去了联系。为了解决这个问题，作者引入了swin-transformer里的shift window机制。也就是说，每次计算能量函数时，先基于正常窗口划分计算一个能量，然后将窗口平移半个窗口长度，再计算一个能量，这样就解决了窗口孤立的问题。</p><p><img src="/./images/Computer_Vision/26.png"></p><p>有了神经窗口全连接条件随机场，作者将它嵌入到一个bottom-up-top-down的网络中来端到端地训练。除了核心结构外，还有一个PPM Head用于聚合全局信息，Rearrange模块用于更好地上采用。详细解释可以查看论文。</p><p><img src="/./images/Computer_Vision/27.png"></p><p><img src="/./images/Computer_Vision/28.png"></p><p><img src="/./images/Computer_Vision/29.png"></p><p><img src="/./images/Computer_Vision/30.png"></p><h3 id="3-论文源码解析"><a href="#3-论文源码解析" class="headerlink" title="3. 论文源码解析"></a>3. 论文源码解析</h3><p>作者模型的实现相对比较清晰，感兴趣的可以前往官方仓库详细的看一下，基本思路是根据算法框图逐一实现<code>encoder</code>、<code>PPM Head</code>以及<code>Neural FC-CRF</code>。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F<span class="token keyword">from</span> <span class="token punctuation">.</span>swin_transformer <span class="token keyword">import</span> SwinTransformer<span class="token keyword">from</span> <span class="token punctuation">.</span>newcrf_layers <span class="token keyword">import</span> NewCRF<span class="token keyword">from</span> <span class="token punctuation">.</span>uper_crf_head <span class="token keyword">import</span> PSP<span class="token comment">########################################################################################################################</span><span class="token keyword">class</span> <span class="token class-name">NewCRFDepth</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""    Depth network based on neural window FC-CRFs architecture.    """</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> version<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> inv_depth<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> pretrained<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span>                     frozen_stages<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> min_depth<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">,</span> max_depth<span class="token operator">=</span><span class="token number">100.0</span><span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>inv_depth <span class="token operator">=</span> inv_depth        self<span class="token punctuation">.</span>with_auxiliary_head <span class="token operator">=</span> <span class="token boolean">False</span>        self<span class="token punctuation">.</span>with_neck <span class="token operator">=</span> <span class="token boolean">False</span>        norm_cfg <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'BN'</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>        <span class="token comment"># norm_cfg = dict(type='GN', requires_grad=True, num_groups=8)</span>        window_size <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>version<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        <span class="token keyword">if</span> version<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token string">'base'</span><span class="token punctuation">:</span>            embed_dim <span class="token operator">=</span> <span class="token number">128</span>            depths <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">18</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span>            num_heads <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">]</span>            in_channels <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">1024</span><span class="token punctuation">]</span>        <span class="token keyword">elif</span> version<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token string">'large'</span><span class="token punctuation">:</span>            embed_dim <span class="token operator">=</span> <span class="token number">192</span>            depths <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">18</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span>            num_heads <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">12</span><span class="token punctuation">,</span> <span class="token number">24</span><span class="token punctuation">,</span> <span class="token number">48</span><span class="token punctuation">]</span>            in_channels <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">192</span><span class="token punctuation">,</span> <span class="token number">384</span><span class="token punctuation">,</span> <span class="token number">768</span><span class="token punctuation">,</span> <span class="token number">1536</span><span class="token punctuation">]</span>        <span class="token keyword">elif</span> version<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token string">'tiny'</span><span class="token punctuation">:</span>            embed_dim <span class="token operator">=</span> <span class="token number">96</span>            depths <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span>            num_heads <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">12</span><span class="token punctuation">,</span> <span class="token number">24</span><span class="token punctuation">]</span>            in_channels <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">96</span><span class="token punctuation">,</span> <span class="token number">192</span><span class="token punctuation">,</span> <span class="token number">384</span><span class="token punctuation">,</span> <span class="token number">768</span><span class="token punctuation">]</span>        backbone_cfg <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span>            embed_dim<span class="token operator">=</span>embed_dim<span class="token punctuation">,</span>            depths<span class="token operator">=</span>depths<span class="token punctuation">,</span>            num_heads<span class="token operator">=</span>num_heads<span class="token punctuation">,</span>            window_size<span class="token operator">=</span>window_size<span class="token punctuation">,</span>            ape<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>            drop_path_rate<span class="token operator">=</span><span class="token number">0.3</span><span class="token punctuation">,</span>            patch_norm<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>            use_checkpoint<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>            frozen_stages<span class="token operator">=</span>frozen_stages        <span class="token punctuation">)</span>        embed_dim <span class="token operator">=</span> <span class="token number">512</span>        decoder_cfg <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span>            in_channels<span class="token operator">=</span>in_channels<span class="token punctuation">,</span>            in_index<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span>            pool_scales<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            channels<span class="token operator">=</span>embed_dim<span class="token punctuation">,</span>            dropout_ratio<span class="token operator">=</span><span class="token number">0.0</span><span class="token punctuation">,</span>            num_classes<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>            norm_cfg<span class="token operator">=</span>norm_cfg<span class="token punctuation">,</span>            align_corners<span class="token operator">=</span><span class="token boolean">False</span>        <span class="token punctuation">)</span>        self<span class="token punctuation">.</span>backbone <span class="token operator">=</span> SwinTransformer<span class="token punctuation">(</span><span class="token operator">**</span>backbone_cfg<span class="token punctuation">)</span>        v_dim <span class="token operator">=</span> decoder_cfg<span class="token punctuation">[</span><span class="token string">'num_classes'</span><span class="token punctuation">]</span><span class="token operator">*</span><span class="token number">4</span>        win <span class="token operator">=</span> <span class="token number">7</span>        crf_dims <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">1024</span><span class="token punctuation">]</span>        v_dims <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> embed_dim<span class="token punctuation">]</span>        self<span class="token punctuation">.</span>crf3 <span class="token operator">=</span> NewCRF<span class="token punctuation">(</span>input_dim<span class="token operator">=</span>in_channels<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> embed_dim<span class="token operator">=</span>crf_dims<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> window_size<span class="token operator">=</span>win<span class="token punctuation">,</span> v_dim<span class="token operator">=</span>v_dims<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> num_heads<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>crf2 <span class="token operator">=</span> NewCRF<span class="token punctuation">(</span>input_dim<span class="token operator">=</span>in_channels<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> embed_dim<span class="token operator">=</span>crf_dims<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> window_size<span class="token operator">=</span>win<span class="token punctuation">,</span> v_dim<span class="token operator">=</span>v_dims<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> num_heads<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>crf1 <span class="token operator">=</span> NewCRF<span class="token punctuation">(</span>input_dim<span class="token operator">=</span>in_channels<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> embed_dim<span class="token operator">=</span>crf_dims<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> window_size<span class="token operator">=</span>win<span class="token punctuation">,</span> v_dim<span class="token operator">=</span>v_dims<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> num_heads<span class="token operator">=</span><span class="token number">8</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>crf0 <span class="token operator">=</span> NewCRF<span class="token punctuation">(</span>input_dim<span class="token operator">=</span>in_channels<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> embed_dim<span class="token operator">=</span>crf_dims<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> window_size<span class="token operator">=</span>win<span class="token punctuation">,</span> v_dim<span class="token operator">=</span>v_dims<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> num_heads<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>decoder <span class="token operator">=</span> PSP<span class="token punctuation">(</span><span class="token operator">**</span>decoder_cfg<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>disp_head1 <span class="token operator">=</span> DispHead<span class="token punctuation">(</span>input_dim<span class="token operator">=</span>crf_dims<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>up_mode <span class="token operator">=</span> <span class="token string">'bilinear'</span>        <span class="token keyword">if</span> self<span class="token punctuation">.</span>up_mode <span class="token operator">==</span> <span class="token string">'mask'</span><span class="token punctuation">:</span>            self<span class="token punctuation">.</span>mask_head <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>                nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>crf_dims<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token operator">*</span><span class="token number">9</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>min_depth <span class="token operator">=</span> min_depth        self<span class="token punctuation">.</span>max_depth <span class="token operator">=</span> max_depth        self<span class="token punctuation">.</span>init_weights<span class="token punctuation">(</span>pretrained<span class="token operator">=</span>pretrained<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">init_weights</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> pretrained<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""Initialize the weights in backbone and heads.        Args:            pretrained (str, optional): Path to pre-trained weights.                Defaults to None.        """</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'== Load encoder backbone from: </span><span class="token interpolation"><span class="token punctuation">&#123;</span>pretrained<span class="token punctuation">&#125;</span></span><span class="token string">'</span></span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>backbone<span class="token punctuation">.</span>init_weights<span class="token punctuation">(</span>pretrained<span class="token operator">=</span>pretrained<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>decoder<span class="token punctuation">.</span>init_weights<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">if</span> self<span class="token punctuation">.</span>with_auxiliary_head<span class="token punctuation">:</span>            <span class="token keyword">if</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>auxiliary_head<span class="token punctuation">,</span> nn<span class="token punctuation">.</span>ModuleList<span class="token punctuation">)</span><span class="token punctuation">:</span>                <span class="token keyword">for</span> aux_head <span class="token keyword">in</span> self<span class="token punctuation">.</span>auxiliary_head<span class="token punctuation">:</span>                    aux_head<span class="token punctuation">.</span>init_weights<span class="token punctuation">(</span><span class="token punctuation">)</span>            <span class="token keyword">else</span><span class="token punctuation">:</span>                self<span class="token punctuation">.</span>auxiliary_head<span class="token punctuation">.</span>init_weights<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">upsample_mask</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> disp<span class="token punctuation">,</span> mask<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">""" Upsample disp [H/4, W/4, 1] -> [H, W, 1] using convex combination """</span>        N<span class="token punctuation">,</span> _<span class="token punctuation">,</span> H<span class="token punctuation">,</span> W <span class="token operator">=</span> disp<span class="token punctuation">.</span>shape        mask <span class="token operator">=</span> mask<span class="token punctuation">.</span>view<span class="token punctuation">(</span>N<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> H<span class="token punctuation">,</span> W<span class="token punctuation">)</span>        mask <span class="token operator">=</span> torch<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>mask<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>        up_disp <span class="token operator">=</span> F<span class="token punctuation">.</span>unfold<span class="token punctuation">(</span>disp<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>        up_disp <span class="token operator">=</span> up_disp<span class="token punctuation">.</span>view<span class="token punctuation">(</span>N<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> H<span class="token punctuation">,</span> W<span class="token punctuation">)</span>        up_disp <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>mask <span class="token operator">*</span> up_disp<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>        up_disp <span class="token operator">=</span> up_disp<span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> up_disp<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>N<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token operator">*</span>H<span class="token punctuation">,</span> <span class="token number">4</span><span class="token operator">*</span>W<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> imgs<span class="token punctuation">)</span><span class="token punctuation">:</span>        feats <span class="token operator">=</span> self<span class="token punctuation">.</span>backbone<span class="token punctuation">(</span>imgs<span class="token punctuation">)</span>        <span class="token keyword">if</span> self<span class="token punctuation">.</span>with_neck<span class="token punctuation">:</span>            feats <span class="token operator">=</span> self<span class="token punctuation">.</span>neck<span class="token punctuation">(</span>feats<span class="token punctuation">)</span>        ppm_out <span class="token operator">=</span> self<span class="token punctuation">.</span>decoder<span class="token punctuation">(</span>feats<span class="token punctuation">)</span>        e3 <span class="token operator">=</span> self<span class="token punctuation">.</span>crf3<span class="token punctuation">(</span>feats<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> ppm_out<span class="token punctuation">)</span>        e3 <span class="token operator">=</span> nn<span class="token punctuation">.</span>PixelShuffle<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">(</span>e3<span class="token punctuation">)</span>        e2 <span class="token operator">=</span> self<span class="token punctuation">.</span>crf2<span class="token punctuation">(</span>feats<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> e3<span class="token punctuation">)</span>        e2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>PixelShuffle<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">(</span>e2<span class="token punctuation">)</span>        e1 <span class="token operator">=</span> self<span class="token punctuation">.</span>crf1<span class="token punctuation">(</span>feats<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> e2<span class="token punctuation">)</span>        e1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>PixelShuffle<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">(</span>e1<span class="token punctuation">)</span>        e0 <span class="token operator">=</span> self<span class="token punctuation">.</span>crf0<span class="token punctuation">(</span>feats<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> e1<span class="token punctuation">)</span>        <span class="token keyword">if</span> self<span class="token punctuation">.</span>up_mode <span class="token operator">==</span> <span class="token string">'mask'</span><span class="token punctuation">:</span>            mask <span class="token operator">=</span> self<span class="token punctuation">.</span>mask_head<span class="token punctuation">(</span>e0<span class="token punctuation">)</span>            d1 <span class="token operator">=</span> self<span class="token punctuation">.</span>disp_head1<span class="token punctuation">(</span>e0<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>            d1 <span class="token operator">=</span> self<span class="token punctuation">.</span>upsample_mask<span class="token punctuation">(</span>d1<span class="token punctuation">,</span> mask<span class="token punctuation">)</span>        <span class="token keyword">else</span><span class="token punctuation">:</span>            d1 <span class="token operator">=</span> self<span class="token punctuation">.</span>disp_head1<span class="token punctuation">(</span>e0<span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>        depth <span class="token operator">=</span> d1 <span class="token operator">*</span> self<span class="token punctuation">.</span>max_depth        <span class="token keyword">return</span> depth<span class="token keyword">class</span> <span class="token class-name">DispHead</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> input_dim<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>DispHead<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment"># self.norm1 = nn.BatchNorm2d(input_dim)</span>        self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>input_dim<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>        <span class="token comment"># self.relu = nn.ReLU(inplace=True)</span>        self<span class="token punctuation">.</span>sigmoid <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> scale<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment"># x = self.relu(self.norm1(x))</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">if</span> scale <span class="token operator">></span> <span class="token number">1</span><span class="token punctuation">:</span>            x <span class="token operator">=</span> upsample<span class="token punctuation">(</span>x<span class="token punctuation">,</span> scale_factor<span class="token operator">=</span>scale<span class="token punctuation">)</span>        <span class="token keyword">return</span> x<span class="token keyword">class</span> <span class="token class-name">DispUnpack</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> input_dim<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span> hidden_dim<span class="token operator">=</span><span class="token number">128</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>DispUnpack<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>input_dim<span class="token punctuation">,</span> hidden_dim<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>conv2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>hidden_dim<span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>relu <span class="token operator">=</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>sigmoid <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>pixel_shuffle <span class="token operator">=</span> nn<span class="token punctuation">.</span>PixelShuffle<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> output_size<span class="token punctuation">)</span><span class="token punctuation">:</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv2<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># [b, 16, h/4, w/4]</span>        <span class="token comment"># x = torch.reshape(x, [x.shape[0], 1, x.shape[2]*4, x.shape[3]*4])</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>pixel_shuffle<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">return</span> x<span class="token keyword">def</span> <span class="token function">upsample</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> scale_factor<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> mode<span class="token operator">=</span><span class="token string">"bilinear"</span><span class="token punctuation">,</span> align_corners<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""Upsample input tensor by a factor of 2    """</span>    <span class="token keyword">return</span> F<span class="token punctuation">.</span>interpolate<span class="token punctuation">(</span>x<span class="token punctuation">,</span> scale_factor<span class="token operator">=</span>scale_factor<span class="token punctuation">,</span> mode<span class="token operator">=</span>mode<span class="token punctuation">,</span> align_corners<span class="token operator">=</span>align_corners<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> Computer Vision </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Depth Estimation </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MobileOne</title>
      <link href="/2023/03/16/mobileone/"/>
      <url>/2023/03/16/mobileone/</url>
      
        <content type="html"><![CDATA[<h3 id="0-写在前面"><a href="#0-写在前面" class="headerlink" title="0. 写在前面"></a>0. 写在前面</h3><p>这篇文章的核心目标是实现移动端实时运行的骨干网络，但笔者感觉其工作中心在对已有创新的组合测验上，且在端载板卡上的精度降幅有些明显。</p><h3 id="1-论文基本信息"><a href="#1-论文基本信息" class="headerlink" title="1. 论文基本信息"></a>1. 论文基本信息</h3><blockquote><ul><li><a href="https://arxiv.org/abs/2206.04040">论文链接</a></li><li><a href="https://github.com/apple/ml-mobileone">官方仓库</a></li><li><a href="https://github.com/shoutOutYangJie/MobileOne">非官方仓库</a></li><li><a href="https://zhuanlan.zhihu.com/p/591036804">MobileOne实战：使用MobileOne实现图像分类任务(一）</a></li><li><a href="https://zhuanlan.zhihu.com/p/592024232">MobileOne实战：使用MobileOne实现图像分类任务(二）</a></li></ul></blockquote><h3 id="2-论文主要内容"><a href="#2-论文主要内容" class="headerlink" title="2. 论文主要内容"></a>2. 论文主要内容</h3><p>用于移动设备的高效神经网络骨干通常针对 FLOP 或参数计数等指标进行优化。然而，当部署在移动设备上时，这些指标可能与网络的延迟没有很好的相关性。因此，作者通过在移动设备上部署多个移动友好网络来对不同指标进行广泛分析。作者识别和分析最近高效神经网络中的架构和优化瓶颈，并提供缓解这些瓶颈的方法。为此，他们设计了一个高效的骨干 MobileOne，其变体在 iPhone12 上的推理时间低于 1 毫秒，在 ImageNet 上的 top-1 准确率为 75.9%。作者展示了 MobileOne 在高效架构中实现了SOTA性能，同时在移动设备上速度提高了许多倍。他们最好的模型在 ImageNet 上获得了与 MobileFormer 相似的性能，同时速度提高了 38 倍。作者的模型在 ImageNet 上的 top-1 准确率比 EfficientNet 在相似的延迟下高 2.3%。此外，作者还展示了他们的模型可以推广到多个任务——图像分类、目标检测和语义分割，与部署在移动设备上的现有高效架构相比，延迟和准确度显著提高。</p><p><img src="/./images/Computer_Vision/14.png"></p><p><strong>激活函数。</strong>为了分析激活函数对延迟的影响，作者构建了一个 30 层的卷积神经网络，并使用不同的激活函数在 iPhone12 上对其进行基准测试，这些激活函数通常用于高效的 CNN 骨干网络。下表中的所有模型除了激活函数之外都具有相同的架构，但它们的延迟却截然不同。这可以归因于同步成本，其主要是由最近引入的激活函数（如 SE-ReLU [38]、Dynamic Shift-Max [40] 和 DynamicReLUs [41]）引起的。 DynamicReLU 和 Dynamic Shift-Max 在 MicroNet [40] 等极低 FLOP 模型中显示出显著改进，使用这些激活函数的延迟成本可能很高。将来，可以为这些激活函数提供硬件加速，但好处将仅限于实现它们的平台。因此，作者在 MobileOne 中仅使用 ReLU 激活函数。</p><p><img src="/./images/Computer_Vision/15.png"></p><p><strong>架构块。</strong> 影响运行时性能的两个关键因素是内存访问成本和并行度 [4]。在多分支架构中，内存访问成本显著增加，因为必须存储来自每个分支的激活函数来计算图中的下一个张量。如果网络的分支数量较少，则可以避免此类内存瓶颈。由于同步成本，强制同步的架构块（如 Squeeze-Excite 块 [38] 中使用的全局池化操作）也会影响整体运行时间。为了演示内存访问成本和同步成本等隐藏成本，作者在 30 层卷积神经网络中过度使用跳跃连接和Squeeze-Exite块。在下表中，作者展示了这些选择中的每一个如何导致延迟。因此，他们采用了在推理时没有分支的架构，从而降低了内存访问成本。此外，作者将 Squeeze-Excite 块的使用限制在他们最大的变体中，以提高准确性。</p><p><img src="/./images/Computer_Vision/16.png"></p><p>基于作者对不同设计选择的评估，他们开发了 MobileOne 架构。与之前关于结构重新参数化的工作一样 [34、12、13、14]，MobileOne 的训练时间和推理时间架构是不同的。</p><p><strong>MobileOne 块。</strong> MobileOne 块类似于 [34, 12, 13, 14] 中介绍的块，不同之处在于作者的块是为卷积层设计的，这些卷积层被分解为深度层和点层。此外，他们引入了简单的过度参数化分支，这些分支提供了进一步的收益，具体的结构如下图所示。</p><p><img src="/./images/Computer_Vision/17.png"></p><p><img src="/./images/Computer_Vision/20.png"></p><p>为了更好地理解使用训练时间可重新参数化分支的改进，作者通过删除训练时间可重新参数化分支（参见下表）来对 MobileOne 模型的不同版本进行消融研究，同时保持所有其他训练参数与之前描述的相同。</p><p><img src="/./images/Computer_Vision/18.png"></p><p><strong>模型缩放。</strong>最近的工作缩放模型大小，如宽度、深度和分辨率以提高性能 [15, 45]。 MobileOne 与 MobileNet-V2 具有相似的深度缩放，即使用较浅的早期阶段，其中输入分辨率较大，因为这些层与在较小输入分辨率下运行的后期阶段相比要慢得多。</p><p><img src="/./images/Computer_Vision/19.png"></p><p>与大型模型相反，小型模型需要较少的正则化来对抗过拟合。正如 [46] 所证明的那样，在训练的早期阶段进行权重衰减是很重要的。作者发现，在训练过程中对权重衰减正则化所产生的损失进行退火，而不是像 [46] 中研究的那样完全消除权重衰减正则化更有效。在作者所有的实验中，他们使用余弦调度[47]作为学习率。因此，作者只需使用相同的时间表来退火权重衰减系数。</p><p><img src="/./images/Computer_Vision/21.png"></p><p><img src="/./images/Computer_Vision/22.png"></p><h3 id="3-论文源码解析"><a href="#3-论文源码解析" class="headerlink" title="3. 论文源码解析"></a>3. 论文源码解析</h3><p>官方开源的仓库中只含有模型文件不包含损失函数、训练与测试脚本，其他第三方复现的仓库中虽然有相关脚本，但是在训练效果上目前还未得到验证，本次只对模型设计本身进行分析。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#</span><span class="token comment"># For licensing see accompanying LICENSE file.</span><span class="token comment"># Copyright (C) 2022 Apple Inc. All Rights Reserved.</span><span class="token comment">#</span><span class="token keyword">from</span> typing <span class="token keyword">import</span> Optional<span class="token punctuation">,</span> List<span class="token punctuation">,</span> Tuple<span class="token keyword">import</span> copy<span class="token keyword">import</span> torch<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F__all__ <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'MobileOne'</span><span class="token punctuation">,</span> <span class="token string">'mobileone'</span><span class="token punctuation">,</span> <span class="token string">'reparameterize_model'</span><span class="token punctuation">]</span><span class="token keyword">class</span> <span class="token class-name">SEBlock</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">""" Squeeze and Excite module.        Pytorch implementation of `Squeeze-and-Excitation Networks` -        https://arxiv.org/pdf/1709.01507.pdf    """</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>                 in_channels<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">,</span>                 rd_ratio<span class="token punctuation">:</span> <span class="token builtin">float</span> <span class="token operator">=</span> <span class="token number">0.0625</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> <span class="token boolean">None</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">""" Construct a Squeeze and Excite Module.        :param in_channels: Number of input channels.        :param rd_ratio: Input channel reduction ratio.        """</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>SEBlock<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span><span class="token builtin">reduce</span> <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span>in_channels<span class="token punctuation">,</span>                                out_channels<span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">(</span>in_channels <span class="token operator">*</span> rd_ratio<span class="token punctuation">)</span><span class="token punctuation">,</span>                                kernel_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>                                stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>                                bias<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>expand <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">(</span>in_channels <span class="token operator">*</span> rd_ratio<span class="token punctuation">)</span><span class="token punctuation">,</span>                                out_channels<span class="token operator">=</span>in_channels<span class="token punctuation">,</span>                                kernel_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>                                stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>                                bias<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> inputs<span class="token punctuation">:</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">:</span>        <span class="token triple-quoted-string string">""" Apply forward pass. """</span>        b<span class="token punctuation">,</span> c<span class="token punctuation">,</span> h<span class="token punctuation">,</span> w <span class="token operator">=</span> inputs<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> F<span class="token punctuation">.</span>avg_pool2d<span class="token punctuation">(</span>inputs<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">[</span>h<span class="token punctuation">,</span> w<span class="token punctuation">]</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span><span class="token builtin">reduce</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>expand<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> torch<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> c<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> inputs <span class="token operator">*</span> x<span class="token keyword">class</span> <span class="token class-name">MobileOneBlock</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">""" MobileOne building block.        This block has a multi-branched architecture at train-time        and plain-CNN style architecture at inference time        For more details, please refer to our paper:        `An Improved One millisecond Mobile Backbone` -        https://arxiv.org/pdf/2206.04040.pdf    """</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>                 in_channels<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">,</span>                 out_channels<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">,</span>                 kernel_size<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">,</span>                 stride<span class="token punctuation">:</span> <span class="token builtin">int</span> <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">,</span>                 padding<span class="token punctuation">:</span> <span class="token builtin">int</span> <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">,</span>                 dilation<span class="token punctuation">:</span> <span class="token builtin">int</span> <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">,</span>                 groups<span class="token punctuation">:</span> <span class="token builtin">int</span> <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">,</span>                 inference_mode<span class="token punctuation">:</span> <span class="token builtin">bool</span> <span class="token operator">=</span> <span class="token boolean">False</span><span class="token punctuation">,</span>                 use_se<span class="token punctuation">:</span> <span class="token builtin">bool</span> <span class="token operator">=</span> <span class="token boolean">False</span><span class="token punctuation">,</span>                 num_conv_branches<span class="token punctuation">:</span> <span class="token builtin">int</span> <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> <span class="token boolean">None</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">""" Construct a MobileOneBlock module.        :param in_channels: Number of channels in the input.        :param out_channels: Number of channels produced by the block.        :param kernel_size: Size of the convolution kernel.        :param stride: Stride size.        :param padding: Zero-padding size.        :param dilation: Kernel dilation factor.        :param groups: Group number.        :param inference_mode: If True, instantiates model in inference mode.        :param use_se: Whether to use SE-ReLU activations.        :param num_conv_branches: Number of linear conv branches.        """</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>MobileOneBlock<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>inference_mode <span class="token operator">=</span> inference_mode        self<span class="token punctuation">.</span>groups <span class="token operator">=</span> groups        self<span class="token punctuation">.</span>stride <span class="token operator">=</span> stride        self<span class="token punctuation">.</span>kernel_size <span class="token operator">=</span> kernel_size        self<span class="token punctuation">.</span>in_channels <span class="token operator">=</span> in_channels        self<span class="token punctuation">.</span>out_channels <span class="token operator">=</span> out_channels        self<span class="token punctuation">.</span>num_conv_branches <span class="token operator">=</span> num_conv_branches        <span class="token comment"># Check if SE-ReLU is requested</span>        <span class="token keyword">if</span> use_se<span class="token punctuation">:</span>            self<span class="token punctuation">.</span>se <span class="token operator">=</span> SEBlock<span class="token punctuation">(</span>out_channels<span class="token punctuation">)</span>        <span class="token keyword">else</span><span class="token punctuation">:</span>            self<span class="token punctuation">.</span>se <span class="token operator">=</span> nn<span class="token punctuation">.</span>Identity<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>activation <span class="token operator">=</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">if</span> inference_mode<span class="token punctuation">:</span>            self<span class="token punctuation">.</span>reparam_conv <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span>in_channels<span class="token punctuation">,</span>                                          out_channels<span class="token operator">=</span>out_channels<span class="token punctuation">,</span>                                          kernel_size<span class="token operator">=</span>kernel_size<span class="token punctuation">,</span>                                          stride<span class="token operator">=</span>stride<span class="token punctuation">,</span>                                          padding<span class="token operator">=</span>padding<span class="token punctuation">,</span>                                          dilation<span class="token operator">=</span>dilation<span class="token punctuation">,</span>                                          groups<span class="token operator">=</span>groups<span class="token punctuation">,</span>                                          bias<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>        <span class="token keyword">else</span><span class="token punctuation">:</span>            <span class="token comment"># Re-parameterizable skip connection</span>            self<span class="token punctuation">.</span>rbr_skip <span class="token operator">=</span> nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>num_features<span class="token operator">=</span>in_channels<span class="token punctuation">)</span> \                <span class="token keyword">if</span> out_channels <span class="token operator">==</span> in_channels <span class="token keyword">and</span> stride <span class="token operator">==</span> <span class="token number">1</span> <span class="token keyword">else</span> <span class="token boolean">None</span>            <span class="token comment"># Re-parameterizable conv branches</span>            rbr_conv <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span><span class="token punctuation">)</span>            <span class="token keyword">for</span> _ <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>num_conv_branches<span class="token punctuation">)</span><span class="token punctuation">:</span>                rbr_conv<span class="token punctuation">.</span>append<span class="token punctuation">(</span>self<span class="token punctuation">.</span>_conv_bn<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span>kernel_size<span class="token punctuation">,</span>                                              padding<span class="token operator">=</span>padding<span class="token punctuation">)</span><span class="token punctuation">)</span>            self<span class="token punctuation">.</span>rbr_conv <span class="token operator">=</span> nn<span class="token punctuation">.</span>ModuleList<span class="token punctuation">(</span>rbr_conv<span class="token punctuation">)</span>            <span class="token comment"># Re-parameterizable scale branch</span>            self<span class="token punctuation">.</span>rbr_scale <span class="token operator">=</span> <span class="token boolean">None</span>            <span class="token keyword">if</span> kernel_size <span class="token operator">></span> <span class="token number">1</span><span class="token punctuation">:</span>                self<span class="token punctuation">.</span>rbr_scale <span class="token operator">=</span> self<span class="token punctuation">.</span>_conv_bn<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>                                               padding<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">:</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">:</span>        <span class="token triple-quoted-string string">""" Apply forward pass. """</span>        <span class="token comment"># Inference mode forward pass.</span>        <span class="token keyword">if</span> self<span class="token punctuation">.</span>inference_mode<span class="token punctuation">:</span>            <span class="token keyword">return</span> self<span class="token punctuation">.</span>activation<span class="token punctuation">(</span>self<span class="token punctuation">.</span>se<span class="token punctuation">(</span>self<span class="token punctuation">.</span>reparam_conv<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token comment"># Multi-branched train-time forward pass.</span>        <span class="token comment"># Skip branch output</span>        identity_out <span class="token operator">=</span> <span class="token number">0</span>        <span class="token keyword">if</span> self<span class="token punctuation">.</span>rbr_skip <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>            identity_out <span class="token operator">=</span> self<span class="token punctuation">.</span>rbr_skip<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token comment"># Scale branch output</span>        scale_out <span class="token operator">=</span> <span class="token number">0</span>        <span class="token keyword">if</span> self<span class="token punctuation">.</span>rbr_scale <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>            scale_out <span class="token operator">=</span> self<span class="token punctuation">.</span>rbr_scale<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token comment"># Other branches</span>        out <span class="token operator">=</span> scale_out <span class="token operator">+</span> identity_out        <span class="token keyword">for</span> ix <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>num_conv_branches<span class="token punctuation">)</span><span class="token punctuation">:</span>            out <span class="token operator">+=</span> self<span class="token punctuation">.</span>rbr_conv<span class="token punctuation">[</span>ix<span class="token punctuation">]</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>activation<span class="token punctuation">(</span>self<span class="token punctuation">.</span>se<span class="token punctuation">(</span>out<span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">reparameterize</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">""" Following works like `RepVGG: Making VGG-style ConvNets Great Again` -        https://arxiv.org/pdf/2101.03697.pdf. We re-parameterize multi-branched        architecture used at training time to obtain a plain CNN-like structure        for inference.        """</span>        <span class="token keyword">if</span> self<span class="token punctuation">.</span>inference_mode<span class="token punctuation">:</span>            <span class="token keyword">return</span>        kernel<span class="token punctuation">,</span> bias <span class="token operator">=</span> self<span class="token punctuation">.</span>_get_kernel_bias<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>reparam_conv <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span>self<span class="token punctuation">.</span>rbr_conv<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>conv<span class="token punctuation">.</span>in_channels<span class="token punctuation">,</span>                                      out_channels<span class="token operator">=</span>self<span class="token punctuation">.</span>rbr_conv<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>conv<span class="token punctuation">.</span>out_channels<span class="token punctuation">,</span>                                      kernel_size<span class="token operator">=</span>self<span class="token punctuation">.</span>rbr_conv<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>conv<span class="token punctuation">.</span>kernel_size<span class="token punctuation">,</span>                                      stride<span class="token operator">=</span>self<span class="token punctuation">.</span>rbr_conv<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>conv<span class="token punctuation">.</span>stride<span class="token punctuation">,</span>                                      padding<span class="token operator">=</span>self<span class="token punctuation">.</span>rbr_conv<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>conv<span class="token punctuation">.</span>padding<span class="token punctuation">,</span>                                      dilation<span class="token operator">=</span>self<span class="token punctuation">.</span>rbr_conv<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>conv<span class="token punctuation">.</span>dilation<span class="token punctuation">,</span>                                      groups<span class="token operator">=</span>self<span class="token punctuation">.</span>rbr_conv<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>conv<span class="token punctuation">.</span>groups<span class="token punctuation">,</span>                                      bias<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>reparam_conv<span class="token punctuation">.</span>weight<span class="token punctuation">.</span>data <span class="token operator">=</span> kernel        self<span class="token punctuation">.</span>reparam_conv<span class="token punctuation">.</span>bias<span class="token punctuation">.</span>data <span class="token operator">=</span> bias        <span class="token comment"># Delete un-used branches</span>        <span class="token keyword">for</span> para <span class="token keyword">in</span> self<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            para<span class="token punctuation">.</span>detach_<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>__delattr__<span class="token punctuation">(</span><span class="token string">'rbr_conv'</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>__delattr__<span class="token punctuation">(</span><span class="token string">'rbr_scale'</span><span class="token punctuation">)</span>        <span class="token keyword">if</span> <span class="token builtin">hasattr</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token string">'rbr_skip'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            self<span class="token punctuation">.</span>__delattr__<span class="token punctuation">(</span><span class="token string">'rbr_skip'</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>inference_mode <span class="token operator">=</span> <span class="token boolean">True</span>    <span class="token keyword">def</span> <span class="token function">_get_kernel_bias</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> Tuple<span class="token punctuation">[</span>torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">,</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">]</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">""" Method to obtain re-parameterized kernel and bias.        Reference: https://github.com/DingXiaoH/RepVGG/blob/main/repvgg.py#L83        :return: Tuple of (kernel, bias) after fusing branches.        """</span>        <span class="token comment"># get weights and bias of scale branch</span>        kernel_scale <span class="token operator">=</span> <span class="token number">0</span>        bias_scale <span class="token operator">=</span> <span class="token number">0</span>        <span class="token keyword">if</span> self<span class="token punctuation">.</span>rbr_scale <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>            kernel_scale<span class="token punctuation">,</span> bias_scale <span class="token operator">=</span> self<span class="token punctuation">.</span>_fuse_bn_tensor<span class="token punctuation">(</span>self<span class="token punctuation">.</span>rbr_scale<span class="token punctuation">)</span>            <span class="token comment"># Pad scale branch kernel to match conv branch kernel size.</span>            pad <span class="token operator">=</span> self<span class="token punctuation">.</span>kernel_size <span class="token operator">//</span> <span class="token number">2</span>            kernel_scale <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional<span class="token punctuation">.</span>pad<span class="token punctuation">(</span>kernel_scale<span class="token punctuation">,</span>                                                   <span class="token punctuation">[</span>pad<span class="token punctuation">,</span> pad<span class="token punctuation">,</span> pad<span class="token punctuation">,</span> pad<span class="token punctuation">]</span><span class="token punctuation">)</span>        <span class="token comment"># get weights and bias of skip branch</span>        kernel_identity <span class="token operator">=</span> <span class="token number">0</span>        bias_identity <span class="token operator">=</span> <span class="token number">0</span>        <span class="token keyword">if</span> self<span class="token punctuation">.</span>rbr_skip <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>            kernel_identity<span class="token punctuation">,</span> bias_identity <span class="token operator">=</span> self<span class="token punctuation">.</span>_fuse_bn_tensor<span class="token punctuation">(</span>self<span class="token punctuation">.</span>rbr_skip<span class="token punctuation">)</span>        <span class="token comment"># get weights and bias of conv branches</span>        kernel_conv <span class="token operator">=</span> <span class="token number">0</span>        bias_conv <span class="token operator">=</span> <span class="token number">0</span>        <span class="token keyword">for</span> ix <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>num_conv_branches<span class="token punctuation">)</span><span class="token punctuation">:</span>            _kernel<span class="token punctuation">,</span> _bias <span class="token operator">=</span> self<span class="token punctuation">.</span>_fuse_bn_tensor<span class="token punctuation">(</span>self<span class="token punctuation">.</span>rbr_conv<span class="token punctuation">[</span>ix<span class="token punctuation">]</span><span class="token punctuation">)</span>            kernel_conv <span class="token operator">+=</span> _kernel            bias_conv <span class="token operator">+=</span> _bias        kernel_final <span class="token operator">=</span> kernel_conv <span class="token operator">+</span> kernel_scale <span class="token operator">+</span> kernel_identity        bias_final <span class="token operator">=</span> bias_conv <span class="token operator">+</span> bias_scale <span class="token operator">+</span> bias_identity        <span class="token keyword">return</span> kernel_final<span class="token punctuation">,</span> bias_final    <span class="token keyword">def</span> <span class="token function">_fuse_bn_tensor</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> branch<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> Tuple<span class="token punctuation">[</span>torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">,</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">]</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">""" Method to fuse batchnorm layer with preceeding conv layer.        Reference: https://github.com/DingXiaoH/RepVGG/blob/main/repvgg.py#L95        :param branch:        :return: Tuple of (kernel, bias) after fusing batchnorm.        """</span>        <span class="token keyword">if</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>branch<span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">)</span><span class="token punctuation">:</span>            kernel <span class="token operator">=</span> branch<span class="token punctuation">.</span>conv<span class="token punctuation">.</span>weight            running_mean <span class="token operator">=</span> branch<span class="token punctuation">.</span>bn<span class="token punctuation">.</span>running_mean            running_var <span class="token operator">=</span> branch<span class="token punctuation">.</span>bn<span class="token punctuation">.</span>running_var            gamma <span class="token operator">=</span> branch<span class="token punctuation">.</span>bn<span class="token punctuation">.</span>weight            beta <span class="token operator">=</span> branch<span class="token punctuation">.</span>bn<span class="token punctuation">.</span>bias            eps <span class="token operator">=</span> branch<span class="token punctuation">.</span>bn<span class="token punctuation">.</span>eps        <span class="token keyword">else</span><span class="token punctuation">:</span>            <span class="token keyword">assert</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>branch<span class="token punctuation">,</span> nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">)</span>            <span class="token keyword">if</span> <span class="token keyword">not</span> <span class="token builtin">hasattr</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token string">'id_tensor'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>                input_dim <span class="token operator">=</span> self<span class="token punctuation">.</span>in_channels <span class="token operator">//</span> self<span class="token punctuation">.</span>groups                kernel_value <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>in_channels<span class="token punctuation">,</span>                                            input_dim<span class="token punctuation">,</span>                                            self<span class="token punctuation">.</span>kernel_size<span class="token punctuation">,</span>                                            self<span class="token punctuation">.</span>kernel_size<span class="token punctuation">)</span><span class="token punctuation">,</span>                                           dtype<span class="token operator">=</span>branch<span class="token punctuation">.</span>weight<span class="token punctuation">.</span>dtype<span class="token punctuation">,</span>                                           device<span class="token operator">=</span>branch<span class="token punctuation">.</span>weight<span class="token punctuation">.</span>device<span class="token punctuation">)</span>                <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>in_channels<span class="token punctuation">)</span><span class="token punctuation">:</span>                    kernel_value<span class="token punctuation">[</span>i<span class="token punctuation">,</span> i <span class="token operator">%</span> input_dim<span class="token punctuation">,</span>                                 self<span class="token punctuation">.</span>kernel_size <span class="token operator">//</span> <span class="token number">2</span><span class="token punctuation">,</span>                                 self<span class="token punctuation">.</span>kernel_size <span class="token operator">//</span> <span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1</span>                self<span class="token punctuation">.</span>id_tensor <span class="token operator">=</span> kernel_value            kernel <span class="token operator">=</span> self<span class="token punctuation">.</span>id_tensor            running_mean <span class="token operator">=</span> branch<span class="token punctuation">.</span>running_mean            running_var <span class="token operator">=</span> branch<span class="token punctuation">.</span>running_var            gamma <span class="token operator">=</span> branch<span class="token punctuation">.</span>weight            beta <span class="token operator">=</span> branch<span class="token punctuation">.</span>bias            eps <span class="token operator">=</span> branch<span class="token punctuation">.</span>eps        std <span class="token operator">=</span> <span class="token punctuation">(</span>running_var <span class="token operator">+</span> eps<span class="token punctuation">)</span><span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span><span class="token punctuation">)</span>        t <span class="token operator">=</span> <span class="token punctuation">(</span>gamma <span class="token operator">/</span> std<span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> kernel <span class="token operator">*</span> t<span class="token punctuation">,</span> beta <span class="token operator">-</span> running_mean <span class="token operator">*</span> gamma <span class="token operator">/</span> std    <span class="token keyword">def</span> <span class="token function">_conv_bn</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>                 kernel_size<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">,</span>                 padding<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">:</span>        <span class="token triple-quoted-string string">""" Helper method to construct conv-batchnorm layers.        :param kernel_size: Size of the convolution kernel.        :param padding: Zero-padding size.        :return: Conv-BN module.        """</span>        mod_list <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token punctuation">)</span>        mod_list<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">'conv'</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span>self<span class="token punctuation">.</span>in_channels<span class="token punctuation">,</span>                                              out_channels<span class="token operator">=</span>self<span class="token punctuation">.</span>out_channels<span class="token punctuation">,</span>                                              kernel_size<span class="token operator">=</span>kernel_size<span class="token punctuation">,</span>                                              stride<span class="token operator">=</span>self<span class="token punctuation">.</span>stride<span class="token punctuation">,</span>                                              padding<span class="token operator">=</span>padding<span class="token punctuation">,</span>                                              groups<span class="token operator">=</span>self<span class="token punctuation">.</span>groups<span class="token punctuation">,</span>                                              bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        mod_list<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">'bn'</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>num_features<span class="token operator">=</span>self<span class="token punctuation">.</span>out_channels<span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> mod_list<span class="token keyword">class</span> <span class="token class-name">MobileOne</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">""" MobileOne Model        Pytorch implementation of `An Improved One millisecond Mobile Backbone` -        https://arxiv.org/pdf/2206.04040.pdf    """</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>                 num_blocks_per_stage<span class="token punctuation">:</span> List<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                 num_classes<span class="token punctuation">:</span> <span class="token builtin">int</span> <span class="token operator">=</span> <span class="token number">1000</span><span class="token punctuation">,</span>                 width_multipliers<span class="token punctuation">:</span> Optional<span class="token punctuation">[</span>List<span class="token punctuation">[</span><span class="token builtin">float</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>                 inference_mode<span class="token punctuation">:</span> <span class="token builtin">bool</span> <span class="token operator">=</span> <span class="token boolean">False</span><span class="token punctuation">,</span>                 use_se<span class="token punctuation">:</span> <span class="token builtin">bool</span> <span class="token operator">=</span> <span class="token boolean">False</span><span class="token punctuation">,</span>                 num_conv_branches<span class="token punctuation">:</span> <span class="token builtin">int</span> <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> <span class="token boolean">None</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">""" Construct MobileOne model.        :param num_blocks_per_stage: List of number of blocks per stage.        :param num_classes: Number of classes in the dataset.        :param width_multipliers: List of width multiplier for blocks in a stage.        :param inference_mode: If True, instantiates model in inference mode.        :param use_se: Whether to use SE-ReLU activations.        :param num_conv_branches: Number of linear conv branches.        """</span>        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">assert</span> <span class="token builtin">len</span><span class="token punctuation">(</span>width_multipliers<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">4</span>        self<span class="token punctuation">.</span>inference_mode <span class="token operator">=</span> inference_mode        self<span class="token punctuation">.</span>in_planes <span class="token operator">=</span> <span class="token builtin">min</span><span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token builtin">int</span><span class="token punctuation">(</span><span class="token number">64</span> <span class="token operator">*</span> width_multipliers<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>use_se <span class="token operator">=</span> use_se        self<span class="token punctuation">.</span>num_conv_branches <span class="token operator">=</span> num_conv_branches        <span class="token comment"># Build stages</span>        self<span class="token punctuation">.</span>stage0 <span class="token operator">=</span> MobileOneBlock<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> out_channels<span class="token operator">=</span>self<span class="token punctuation">.</span>in_planes<span class="token punctuation">,</span>                                     kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>                                     inference_mode<span class="token operator">=</span>self<span class="token punctuation">.</span>inference_mode<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>cur_layer_idx <span class="token operator">=</span> <span class="token number">1</span>        self<span class="token punctuation">.</span>stage1 <span class="token operator">=</span> self<span class="token punctuation">.</span>_make_stage<span class="token punctuation">(</span><span class="token builtin">int</span><span class="token punctuation">(</span><span class="token number">64</span> <span class="token operator">*</span> width_multipliers<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> num_blocks_per_stage<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                                       num_se_blocks<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>stage2 <span class="token operator">=</span> self<span class="token punctuation">.</span>_make_stage<span class="token punctuation">(</span><span class="token builtin">int</span><span class="token punctuation">(</span><span class="token number">128</span> <span class="token operator">*</span> width_multipliers<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> num_blocks_per_stage<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                                       num_se_blocks<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>stage3 <span class="token operator">=</span> self<span class="token punctuation">.</span>_make_stage<span class="token punctuation">(</span><span class="token builtin">int</span><span class="token punctuation">(</span><span class="token number">256</span> <span class="token operator">*</span> width_multipliers<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> num_blocks_per_stage<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                                       num_se_blocks<span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">(</span>num_blocks_per_stage<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">//</span> <span class="token number">2</span><span class="token punctuation">)</span> <span class="token keyword">if</span> use_se <span class="token keyword">else</span> <span class="token number">0</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>stage4 <span class="token operator">=</span> self<span class="token punctuation">.</span>_make_stage<span class="token punctuation">(</span><span class="token builtin">int</span><span class="token punctuation">(</span><span class="token number">512</span> <span class="token operator">*</span> width_multipliers<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> num_blocks_per_stage<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                                       num_se_blocks<span class="token operator">=</span>num_blocks_per_stage<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span> <span class="token keyword">if</span> use_se <span class="token keyword">else</span> <span class="token number">0</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>gap <span class="token operator">=</span> nn<span class="token punctuation">.</span>AdaptiveAvgPool2d<span class="token punctuation">(</span>output_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>linear <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token builtin">int</span><span class="token punctuation">(</span><span class="token number">512</span> <span class="token operator">*</span> width_multipliers<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> num_classes<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">_make_stage</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>                    planes<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">,</span>                    num_blocks<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">,</span>                    num_se_blocks<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">:</span>        <span class="token triple-quoted-string string">""" Build a stage of MobileOne model.        :param planes: Number of output channels.        :param num_blocks: Number of blocks in this stage.        :param num_se_blocks: Number of SE blocks in this stage.        :return: A stage of MobileOne model.        """</span>        <span class="token comment"># Get strides for all layers</span>        strides <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token operator">*</span><span class="token punctuation">(</span>num_blocks<span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>        blocks <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>        <span class="token keyword">for</span> ix<span class="token punctuation">,</span> stride <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>strides<span class="token punctuation">)</span><span class="token punctuation">:</span>            use_se <span class="token operator">=</span> <span class="token boolean">False</span>            <span class="token keyword">if</span> num_se_blocks <span class="token operator">></span> num_blocks<span class="token punctuation">:</span>                <span class="token keyword">raise</span> ValueError<span class="token punctuation">(</span><span class="token string">"Number of SE blocks cannot "</span>                                 <span class="token string">"exceed number of layers."</span><span class="token punctuation">)</span>            <span class="token keyword">if</span> ix <span class="token operator">>=</span> <span class="token punctuation">(</span>num_blocks <span class="token operator">-</span> num_se_blocks<span class="token punctuation">)</span><span class="token punctuation">:</span>                use_se <span class="token operator">=</span> <span class="token boolean">True</span>            <span class="token comment"># Depthwise conv</span>            blocks<span class="token punctuation">.</span>append<span class="token punctuation">(</span>MobileOneBlock<span class="token punctuation">(</span>in_channels<span class="token operator">=</span>self<span class="token punctuation">.</span>in_planes<span class="token punctuation">,</span>                                         out_channels<span class="token operator">=</span>self<span class="token punctuation">.</span>in_planes<span class="token punctuation">,</span>                                         kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>                                         stride<span class="token operator">=</span>stride<span class="token punctuation">,</span>                                         padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>                                         groups<span class="token operator">=</span>self<span class="token punctuation">.</span>in_planes<span class="token punctuation">,</span>                                         inference_mode<span class="token operator">=</span>self<span class="token punctuation">.</span>inference_mode<span class="token punctuation">,</span>                                         use_se<span class="token operator">=</span>use_se<span class="token punctuation">,</span>                                         num_conv_branches<span class="token operator">=</span>self<span class="token punctuation">.</span>num_conv_branches<span class="token punctuation">)</span><span class="token punctuation">)</span>            <span class="token comment"># Pointwise conv</span>            blocks<span class="token punctuation">.</span>append<span class="token punctuation">(</span>MobileOneBlock<span class="token punctuation">(</span>in_channels<span class="token operator">=</span>self<span class="token punctuation">.</span>in_planes<span class="token punctuation">,</span>                                         out_channels<span class="token operator">=</span>planes<span class="token punctuation">,</span>                                         kernel_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>                                         stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>                                         padding<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span>                                         groups<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>                                         inference_mode<span class="token operator">=</span>self<span class="token punctuation">.</span>inference_mode<span class="token punctuation">,</span>                                         use_se<span class="token operator">=</span>use_se<span class="token punctuation">,</span>                                         num_conv_branches<span class="token operator">=</span>self<span class="token punctuation">.</span>num_conv_branches<span class="token punctuation">)</span><span class="token punctuation">)</span>            self<span class="token punctuation">.</span>in_planes <span class="token operator">=</span> planes            self<span class="token punctuation">.</span>cur_layer_idx <span class="token operator">+=</span> <span class="token number">1</span>        <span class="token keyword">return</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token operator">*</span>blocks<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">:</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">:</span>        <span class="token triple-quoted-string string">""" Apply forward pass. """</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>stage0<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>stage1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>stage2<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>stage3<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>stage4<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>gap<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span>x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>linear<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">return</span> xPARAMS <span class="token operator">=</span> <span class="token punctuation">&#123;</span>    <span class="token string">"s0"</span><span class="token punctuation">:</span> <span class="token punctuation">&#123;</span><span class="token string">"width_multipliers"</span><span class="token punctuation">:</span> <span class="token punctuation">(</span><span class="token number">0.75</span><span class="token punctuation">,</span> <span class="token number">1.0</span><span class="token punctuation">,</span> <span class="token number">1.0</span><span class="token punctuation">,</span> <span class="token number">2.0</span><span class="token punctuation">)</span><span class="token punctuation">,</span>           <span class="token string">"num_conv_branches"</span><span class="token punctuation">:</span> <span class="token number">4</span><span class="token punctuation">&#125;</span><span class="token punctuation">,</span>    <span class="token string">"s1"</span><span class="token punctuation">:</span> <span class="token punctuation">&#123;</span><span class="token string">"width_multipliers"</span><span class="token punctuation">:</span> <span class="token punctuation">(</span><span class="token number">1.5</span><span class="token punctuation">,</span> <span class="token number">1.5</span><span class="token punctuation">,</span> <span class="token number">2.0</span><span class="token punctuation">,</span> <span class="token number">2.5</span><span class="token punctuation">)</span><span class="token punctuation">&#125;</span><span class="token punctuation">,</span>    <span class="token string">"s2"</span><span class="token punctuation">:</span> <span class="token punctuation">&#123;</span><span class="token string">"width_multipliers"</span><span class="token punctuation">:</span> <span class="token punctuation">(</span><span class="token number">1.5</span><span class="token punctuation">,</span> <span class="token number">2.0</span><span class="token punctuation">,</span> <span class="token number">2.5</span><span class="token punctuation">,</span> <span class="token number">4.0</span><span class="token punctuation">)</span><span class="token punctuation">&#125;</span><span class="token punctuation">,</span>    <span class="token string">"s3"</span><span class="token punctuation">:</span> <span class="token punctuation">&#123;</span><span class="token string">"width_multipliers"</span><span class="token punctuation">:</span> <span class="token punctuation">(</span><span class="token number">2.0</span><span class="token punctuation">,</span> <span class="token number">2.5</span><span class="token punctuation">,</span> <span class="token number">3.0</span><span class="token punctuation">,</span> <span class="token number">4.0</span><span class="token punctuation">)</span><span class="token punctuation">&#125;</span><span class="token punctuation">,</span>    <span class="token string">"s4"</span><span class="token punctuation">:</span> <span class="token punctuation">&#123;</span><span class="token string">"width_multipliers"</span><span class="token punctuation">:</span> <span class="token punctuation">(</span><span class="token number">3.0</span><span class="token punctuation">,</span> <span class="token number">3.5</span><span class="token punctuation">,</span> <span class="token number">3.5</span><span class="token punctuation">,</span> <span class="token number">4.0</span><span class="token punctuation">)</span><span class="token punctuation">,</span>           <span class="token string">"use_se"</span><span class="token punctuation">:</span> <span class="token boolean">True</span><span class="token punctuation">&#125;</span><span class="token punctuation">,</span><span class="token punctuation">&#125;</span><span class="token keyword">def</span> <span class="token function">mobileone</span><span class="token punctuation">(</span>num_classes<span class="token punctuation">:</span> <span class="token builtin">int</span> <span class="token operator">=</span> <span class="token number">1000</span><span class="token punctuation">,</span> inference_mode<span class="token punctuation">:</span> <span class="token builtin">bool</span> <span class="token operator">=</span> <span class="token boolean">False</span><span class="token punctuation">,</span>              variant<span class="token punctuation">:</span> <span class="token builtin">str</span> <span class="token operator">=</span> <span class="token string">"s0"</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> nn<span class="token punctuation">.</span>Module<span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""Get MobileOne model.    :param num_classes: Number of classes in the dataset.    :param inference_mode: If True, instantiates model in inference mode.    :param variant: Which type of model to generate.    :return: MobileOne model. """</span>    variant_params <span class="token operator">=</span> PARAMS<span class="token punctuation">[</span>variant<span class="token punctuation">]</span>    <span class="token keyword">return</span> MobileOne<span class="token punctuation">(</span>num_classes<span class="token operator">=</span>num_classes<span class="token punctuation">,</span> inference_mode<span class="token operator">=</span>inference_mode<span class="token punctuation">,</span>                     <span class="token operator">**</span>variant_params<span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">reparameterize_model</span><span class="token punctuation">(</span>model<span class="token punctuation">:</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> nn<span class="token punctuation">.</span>Module<span class="token punctuation">:</span>    <span class="token triple-quoted-string string">""" Method returns a model where a multi-branched structure        used in training is re-parameterized into a single branch        for inference.    :param model: MobileOne model in train mode.    :return: MobileOne model in inference mode.    """</span>    <span class="token comment"># Avoid editing original graph</span>    model <span class="token operator">=</span> copy<span class="token punctuation">.</span>deepcopy<span class="token punctuation">(</span>model<span class="token punctuation">)</span>    <span class="token keyword">for</span> module <span class="token keyword">in</span> model<span class="token punctuation">.</span>modules<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">if</span> <span class="token builtin">hasattr</span><span class="token punctuation">(</span>module<span class="token punctuation">,</span> <span class="token string">'reparameterize'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            module<span class="token punctuation">.</span>reparameterize<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> model<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> Computer Vision </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Backbone Network </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>LISU (ISPRS)</title>
      <link href="/2023/03/15/lisu-isprs/"/>
      <url>/2023/03/15/lisu-isprs/</url>
      
        <content type="html"><![CDATA[<h3 id="LISU-Low-light-indoor-scene-understanding-with-joint-learning-of-reflectance-restoration"><a href="#LISU-Low-light-indoor-scene-understanding-with-joint-learning-of-reflectance-restoration" class="headerlink" title="LISU: Low-light indoor scene understanding with joint learning of reflectance restoration"></a>LISU: Low-light indoor scene understanding with joint learning of reflectance restoration</h3><h3 id="0-写在前面"><a href="#0-写在前面" class="headerlink" title="0. 写在前面"></a>0. 写在前面</h3><p>这篇文章开创性地研究了低光室内语义分割的课题，这个课题好像还挺少有人研究的。但是也有一定的意义，比如低光的室内导航，不知道这个方法能不能迁移到夜晚室外路面的分割，后期有时间笔者再实际的测试一下。</p><h3 id="1-论文基本信息"><a href="#1-论文基本信息" class="headerlink" title="1. 论文基本信息"></a>1. 论文基本信息</h3><blockquote><ul><li><a href="https://pdf.sciencedirectassets.com/271826/1-s2.0-S0924271621X00123/1-s2.0-S0924271621003087/main.pdf?X-Amz-Security-Token=IQoJb3JpZ2luX2VjEAcaCXVzLWVhc3QtMSJGMEQCIAz0ADcYbtZAZD1b6+qw6E89ljLVNeSpFonmAMpl9Vm5AiAWcVpuRvj7u5Oy3KAC4xdbgehJFOS+wtjCscqSxfhrNCq7BQi///////////8BEAUaDDA1OTAwMzU0Njg2NSIM8iK0zGnk++YOhRLTKo8FocLpzeCasf++qCJsuGop6SbGPscY6kIpOIgkXdR+IGE19mEp2fgcfmiLKwhetsI1c5RuNRyesZ6sk2BITV3IsP5AyrAPWR9eMCvuGgQG24mSX23ctHNHSGnUZgKcMe4eyziiDgHtSwu+f7klCFlcC3kr2dvzkPykPNuDixgCfYW+SWKkQwkPLxqdV42Wl9pFs54TGbgvhGrJ/nXbGOgvL1EENA/hYPDOkUE/pTPik0bJ5buHHp3CzLcu1y80OBygNeO46CPhbhiWRRbrb6ptaYnbdNpm5/M3GqFR/QqQARmqpzfTS1HRRqtabk6J9LRk+YDohQQ605ZToCdGSILdKHCH75k2esCf46wyJuNrCtmcE1Dk7+1BZAmlwIGztLITQjTBGw2sbS8ZgTGbfpn2s2qPQOvR16ba/yHL6MUBVzmPt2fYPTcol4zJ0uOiBWWM0u5Rz7/NVdZy2ygFvBDD5mPLR6sMrnsff92XfOW8fKF2lc8O5MtunYeXbKTxckBAoWTiqb9aBEiPN9IvWLXJ1ENqKsP5Zsf/EFa+SsHOSUnrk3E6Kj04ulFKa6JDK7PO/OaUezwq0+o3+f3rh2FRoiXLpCmbRy8o9vsxvPG0PTN08ii/Xm3fJq7JgdFOWF3/r38ewI7gyz+UQJcg/59iU41CQ2EW1KE3kCCF2ktPsVvNuVDHSv//OcJiXenKKMQHEYarBPL1YrclonCnPcVDJ32OVZpisByEi+/x/dI7xSmGky5vI5ikzDpjFjYXXBcbePkbL1sXklobV2pQxK+2ZL3G+amG8il3W+wBPEE2lOknCZPiXYFB8OdUbniP1E7P2MBMRW/4f+vwuvCSdnlByga86uQiKA/o7ktjsHq2hTDU3rygBjqyAUtOZdBhoPmyn9KOn34y5XxCML6UHfXLiXNlFGuE7jTmbiTz29143jmydmz58H2/09fewvvLCn1LaMSPUUpPImlql/vVHNcdHNOt+97i6Eq3bB/hPRZVWaD5KWHCvPm3hkeE4JHT0ezki0DQu/lrTt+FWUEPNNC2SnxW87TTUjB9+L4LjratiiiiSJOJrKuncs4SSiRTR9Gm0ZWYnsWhwaKXq/bdhEotnzrOgCicnFMdwmA=&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20230313T145807Z&X-Amz-SignedHeaders=host&X-Amz-Expires=300&X-Amz-Credential=ASIAQ3PHCVTY5EWKNTOS/20230313/us-east-1/s3/aws4_request&X-Amz-Signature=f940ff2cd1f4fc15462eaa08b0648a98d672f89df2f996b983137b043117207c&hash=14b5f4cd8a710d6851ea00fdc437028b0c5ccddaf2a2ae6896545d658bb11229&host=68042c943591013ac2b2430a89b270f6af2c76d8dfd086a07176afe7c76c2c61&pii=S0924271621003087&tid=spdf-8398ac47-4f1e-42f4-933d-fa66f61ec2ae&sid=1358cf677661f14d470befe8f3a494e5ce16gxrqa&type=client&tsoh=d3d3LnNjaWVuY2VkaXJlY3QuY29t&ua=050b5804595757535700&rr=7a75221dff4dcef1&cc=cn">论文链接</a></li><li><a href="https://github.com/noahzn/LISU">代码链接</a></li></ul></blockquote><h3 id="2-论文主要内容"><a href="#2-论文主要内容" class="headerlink" title="2. 论文主要内容"></a>2. 论文主要内容</h3><p>使用CNN的语义分割已经取得了很不错的成绩，但是当训练数据较少时，网络无法在光照变化下取得令人满意的分割结果。这篇论文，作者研究了在室内低光环境中的语义分割，并且提出了一个真实的和一个渲染的低光数据集用于评估结果。作者提出了一个用于低光分割的多任务网络 LISU，网络由两条分支组成，一条分支是语义分割分支，另一条分支是反射图修复分支。两条分支的深度特征级联起来以提升语义分割的结果。实验结果显示：语义信息可以帮助修复反射图，而修复的反射图更进一步帮助语义分割分支取得更好的效果。同时作者还尝试使用渲染数据进行模型预训练，并再次将最终的mIoU提升了7.2%。</p><p><img src="/./images/Computer_Vision/9.png"></p><p><img src="/./images/Computer_Vision/10.png"></p><p>提出的LISU网络是一个级联网络，由LISU-decomp和LISU-joint组成。作者首先将一副图像通过LISU-decomp进行本征分解得到反射图和光照图。</p><p>直接在反射图上进行分割可以提升分割性能，因为反射图上没有光照的影响，像素颜色表达的是物体本身的颜色。根据Retinex理论，同一场景在不同光照下，反射图是不变的，只有光照图是不一样的，因此在理想情况下，一个物体在不同光照下的反射图上都是不变的，作者根据这一点决定在低光图像的反射图上进行语义分割。</p><p>作者首先利用自监督学习先训练了一个图像分解网络：输入一张图像，网络输出图像的反射图和光照图。随后将低光图像的光照图和低光图像的反射图一起输入进LISU-joint进行反射图修复和语义分割的联合学习。进行联合学习反射图修复的考虑是，因为低光图像分解得到的反射图质量特别差 （degraded reflectance map），损失了很多信息，因此作者希望修复反射图来得到更好的反射图特征。</p><p>作者使用的网络是一个基于U-Net的多任务网络，网络共用一个encoder，但是两个不同的任务有两个不同的decoder学习。同时，两个解码器的特征被联结到一起进行特征的融合。</p><p>网络训练方面，作者采用反射图恢复损失与交叉熵损失组合的方式进行。</p><p><img src="/./images/Computer_Vision/12.png"></p><p><img src="/./images/Computer_Vision/11.png"></p><p><img src="/./images/Computer_Vision/13.png"></p><h3 id="3-论文源码解析"><a href="#3-论文源码解析" class="headerlink" title="3. 论文源码解析"></a>3. 论文源码解析</h3><p>作者模型的实现采用编码器和解码器分开的方式进行，最终实现了两个<code>Class</code>。官方开源的仓库中结构非常清晰，编码器解码器的组合是在模型训练与验证的脚本<code>main.py</code>内实现的。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token triple-quoted-string string">"""@FileName: models.py@Time    : 7/16/2020@Author  : Ning Zhang@GitHub: https://github.com/noahzn"""</span><span class="token keyword">import</span> torch<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F<span class="token keyword">class</span> <span class="token class-name">LISU_DECOMP</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>conv_1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> out_channels<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>conv_2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span> out_channels<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>conv_3 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span> out_channels<span class="token operator">=</span><span class="token number">128</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>conv_4 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">128</span><span class="token punctuation">,</span> out_channels<span class="token operator">=</span><span class="token number">128</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>conv_5 <span class="token operator">=</span> nn<span class="token punctuation">.</span>ConvTranspose2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">128</span><span class="token punctuation">,</span> out_channels<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>                                         output_padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>conv_6 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">128</span><span class="token punctuation">,</span> out_channels<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>conv_7 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">128</span><span class="token punctuation">,</span> out_channels<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>conv_8 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span> out_channels<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> img<span class="token punctuation">)</span><span class="token punctuation">:</span>        c1 <span class="token operator">=</span> self<span class="token punctuation">.</span>conv_1<span class="token punctuation">(</span>img<span class="token punctuation">)</span>        c2 <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv_2<span class="token punctuation">(</span>c1<span class="token punctuation">)</span><span class="token punctuation">)</span>        c3 <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv_3<span class="token punctuation">(</span>c2<span class="token punctuation">)</span><span class="token punctuation">)</span>        c4 <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv_4<span class="token punctuation">(</span>c3<span class="token punctuation">)</span><span class="token punctuation">)</span>        c5 <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv_5<span class="token punctuation">(</span>c4<span class="token punctuation">)</span><span class="token punctuation">)</span>        c6 <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv_6<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>c2<span class="token punctuation">,</span> c5<span class="token punctuation">)</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        c7 <span class="token operator">=</span> self<span class="token punctuation">.</span>conv_7<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>c1<span class="token punctuation">,</span> c6<span class="token punctuation">)</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        c8 <span class="token operator">=</span> self<span class="token punctuation">.</span>conv_8<span class="token punctuation">(</span>c7<span class="token punctuation">)</span>        c9 <span class="token operator">=</span> torch<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span>c8<span class="token punctuation">)</span>        reflectance<span class="token punctuation">,</span> illumination <span class="token operator">=</span> c9<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">,</span> c9<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">:</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span>        <span class="token keyword">return</span> illumination<span class="token punctuation">,</span> reflectance<span class="token keyword">class</span> <span class="token class-name">LISU_JOINT</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>in_channels <span class="token operator">=</span> <span class="token number">4</span>        <span class="token comment"># Encoder layers</span>        self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token punctuation">)</span>        self<span class="token punctuation">.</span>conv2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token punctuation">)</span>        self<span class="token punctuation">.</span>conv3 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token punctuation">)</span>        self<span class="token punctuation">.</span>conv4 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token punctuation">)</span>        self<span class="token punctuation">.</span>conv5 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token punctuation">)</span>        <span class="token comment"># decoder</span>        self<span class="token punctuation">.</span>mid_r <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">)</span>        self<span class="token punctuation">.</span>mid_s <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">)</span>        self<span class="token punctuation">.</span>deconv4_r <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Upsample<span class="token punctuation">(</span>scale_factor<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> mode<span class="token operator">=</span><span class="token string">'bilinear'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        <span class="token punctuation">)</span>        self<span class="token punctuation">.</span>deconv3_r <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">768</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Upsample<span class="token punctuation">(</span>scale_factor<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> mode<span class="token operator">=</span><span class="token string">'bilinear'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        <span class="token punctuation">)</span>        self<span class="token punctuation">.</span>deconv2_r <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">384</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Upsample<span class="token punctuation">(</span>scale_factor<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> mode<span class="token operator">=</span><span class="token string">'bilinear'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        <span class="token punctuation">)</span>        self<span class="token punctuation">.</span>deconv1_r <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">192</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Upsample<span class="token punctuation">(</span>scale_factor<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> mode<span class="token operator">=</span><span class="token string">'bilinear'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">)</span>        self<span class="token punctuation">.</span>deconv4_s <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Upsample<span class="token punctuation">(</span>scale_factor<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> mode<span class="token operator">=</span><span class="token string">'bilinear'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        <span class="token punctuation">)</span>        self<span class="token punctuation">.</span>deconv3_s <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">768</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Upsample<span class="token punctuation">(</span>scale_factor<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> mode<span class="token operator">=</span><span class="token string">'bilinear'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        <span class="token punctuation">)</span>        self<span class="token punctuation">.</span>deconv2_s <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">384</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Upsample<span class="token punctuation">(</span>scale_factor<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> mode<span class="token operator">=</span><span class="token string">'bilinear'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        <span class="token punctuation">)</span>        self<span class="token punctuation">.</span>deconv1_s <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">192</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Upsample<span class="token punctuation">(</span>scale_factor<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> mode<span class="token operator">=</span><span class="token string">'bilinear'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">)</span>        self<span class="token punctuation">.</span>out_r <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">96</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        <span class="token punctuation">)</span>        self<span class="token punctuation">.</span>out_s <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">96</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">14</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        <span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        x1 <span class="token operator">=</span> self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token comment"># 16 x 240 x 320</span>        x2 <span class="token operator">=</span> self<span class="token punctuation">.</span>conv2<span class="token punctuation">(</span>x1<span class="token punctuation">)</span>        <span class="token comment"># 32 x 120 x 160</span>        x3 <span class="token operator">=</span> self<span class="token punctuation">.</span>conv3<span class="token punctuation">(</span>x2<span class="token punctuation">)</span>        <span class="token comment"># 64 x 60 x 80</span>        x4 <span class="token operator">=</span> self<span class="token punctuation">.</span>conv4<span class="token punctuation">(</span>x3<span class="token punctuation">)</span>        <span class="token comment"># 128 x 30 x 40</span>        x5 <span class="token operator">=</span> self<span class="token punctuation">.</span>conv5<span class="token punctuation">(</span>x4<span class="token punctuation">)</span>        <span class="token comment"># 256 x 15 x 20</span>        xmid_r <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>mid_r<span class="token punctuation">(</span>x5<span class="token punctuation">)</span><span class="token punctuation">,</span> x5<span class="token punctuation">)</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>        xmid_s <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>mid_s<span class="token punctuation">(</span>x5<span class="token punctuation">)</span><span class="token punctuation">,</span> x5<span class="token punctuation">)</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>        <span class="token comment"># 512 x 15 x 20</span>        x4d_r <span class="token operator">=</span> self<span class="token punctuation">.</span>deconv4_r<span class="token punctuation">(</span>xmid_r<span class="token punctuation">)</span>        x4d_s <span class="token operator">=</span> self<span class="token punctuation">.</span>deconv4_s<span class="token punctuation">(</span>xmid_s<span class="token punctuation">)</span>        x3d_r <span class="token operator">=</span> self<span class="token punctuation">.</span>deconv3_r<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>x4d_r<span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token punctuation">[</span>x4d_s<span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token punctuation">[</span>x4<span class="token punctuation">]</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        x3d_s <span class="token operator">=</span> self<span class="token punctuation">.</span>deconv3_s<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>x4d_s<span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token punctuation">[</span>x4d_r<span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token punctuation">[</span>x4<span class="token punctuation">]</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        x2d_r <span class="token operator">=</span> self<span class="token punctuation">.</span>deconv2_r<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>x3d_r<span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token punctuation">[</span>x3d_s<span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token punctuation">[</span>x3<span class="token punctuation">]</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        x2d_s <span class="token operator">=</span> self<span class="token punctuation">.</span>deconv2_s<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>x3d_s<span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token punctuation">[</span>x3d_r<span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token punctuation">[</span>x3<span class="token punctuation">]</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        x1d_r <span class="token operator">=</span> self<span class="token punctuation">.</span>deconv1_r<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>x2d_r<span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token punctuation">[</span>x2d_s<span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token punctuation">[</span>x2<span class="token punctuation">]</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        x1d_s <span class="token operator">=</span> self<span class="token punctuation">.</span>deconv1_s<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>x2d_s<span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token punctuation">[</span>x2d_r<span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token punctuation">[</span>x2<span class="token punctuation">]</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        out_r <span class="token operator">=</span> torch<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span>self<span class="token punctuation">.</span>out_r<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>x1d_r<span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token punctuation">[</span>x1d_s<span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token punctuation">[</span>x1<span class="token punctuation">]</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        out_s <span class="token operator">=</span> self<span class="token punctuation">.</span>out_s<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>x1d_s<span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token punctuation">[</span>x1d_r<span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token punctuation">[</span>x1<span class="token punctuation">]</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> out_r<span class="token punctuation">,</span> out_s<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> Computer Vision </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Image Processing </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>IAT (BMVC 2022)</title>
      <link href="/2023/03/14/iat-bmvc-2022/"/>
      <url>/2023/03/14/iat-bmvc-2022/</url>
      
        <content type="html"><![CDATA[<h3 id="You-Only-Need-90K-Parameters-to-Adapt-Light-A-Light-Weight-Transformer-for-Image-Enhancement-and-Exposure-Correction"><a href="#You-Only-Need-90K-Parameters-to-Adapt-Light-A-Light-Weight-Transformer-for-Image-Enhancement-and-Exposure-Correction" class="headerlink" title="You Only Need 90K Parameters to Adapt Light: A Light Weight Transformer for Image Enhancement and Exposure Correction"></a>You Only Need 90K Parameters to Adapt Light: A Light Weight Transformer for Image Enhancement and Exposure Correction</h3><h3 id="0-写在前面"><a href="#0-写在前面" class="headerlink" title="0. 写在前面"></a>0. 写在前面</h3><p>虽然作者说该模型采用了轻量化的设计思想，<code>Params</code>只有<strong>90K</strong>，但是经过笔者实际测试发现，模型在推理时的<code>FLOAT</code>高达<strong>5.5G</strong>，因此远远不是实时性运行的算法。</p><h3 id="1-论文基本信息"><a href="#1-论文基本信息" class="headerlink" title="1. 论文基本信息"></a>1. 论文基本信息</h3><blockquote><ul><li><a href="https://arxiv.org/abs/2205.14871">论文链接</a></li><li><a href="https://github.com/cuiziteng/Illumination-Adaptive-Transformer">代码链接</a></li><li><a href="https://zhuanlan.zhihu.com/p/535695807">作者解读</a></li></ul></blockquote><h3 id="2-论文主要内容"><a href="#2-论文主要内容" class="headerlink" title="2. 论文主要内容"></a>2. 论文主要内容</h3><p><img src="/./images/Computer_Vision/0.jpg"></p><p>自然场景下存在着各种不良光照场景，如低光照环境和摄影造成的过(欠)曝光环境，相机在不良光照下完成摄影任务时，因为接收到过多&#x2F;过少的光子数量，和相机内部的处理过程 (如低光照场景需要调高ISO，这会导致噪声也同时放大)，往往得到的图像也会收到影响，无论从视觉感观还是完成一些视觉任务（如检测，分割等）都会受到影响。区别于传统的HE或者RetiNex做法以及此前的CNN做法，作者提出了Illimination-Adaptive-Transformer (IAT), IAT模型借鉴了目标检测网络DETR思路，通过动态query学习的机制来调整计算摄影中的一些相关参数，建立了一个end-to-end的Transformer，来克服这些不良光照所造成的视觉感观&#x2F;视觉任务影响。</p><p><img src="/./images/Computer_Vision/1.png"></p><p><img src="/./images/Computer_Vision/2.png"></p><p>在实验部分，作者做了大量的实验，包括低光照增强&#x2F;曝光矫正，以及低光照场景下的目标检测，低光照场景下的语义分割，以及复杂光照场景下的目标检测。具体而言，低光照增强用的是<strong>LOL-V1</strong>和<strong>LOL-V2-real</strong>数据集；曝光矫正采用的是<strong>Exposure</strong>数据集。低光照检测&#x2F;分割方面，作者分别用低光照检测数据集EXDark和低光照分割数据集ACDC以及多光源场景检测数据集TYOL进行验证。检测器采用的是YOLOv3。</p><p><img src="/./images/Computer_Vision/3.png"></p><p><img src="/./images/Computer_Vision/4.png"></p><p><img src="/./images/Computer_Vision/5.png"></p><p><img src="/./images/Computer_Vision/6.png"></p><p>可以看出低光照增强方法对于目标检测任务有些许提升，但是在后续的语义分割任务(e)上，增强算法反而无法提升目标的分割性能，这是由于图像增强算法与高层视觉算法的目的与评价指标不一致所导致的，图像增强是为了更好提升人眼视觉（评价指标PSNR,SSIM），而目标检测和语义分割属于机器视觉(评价指标mIOU, mAP)。</p><p>针对于这种情况，作者采用了joint-training范式来训练网络，即将图像增强网络和后续检测分割网络联合，一起更新参数，其中图像增强网络还可以加载不同的预训练模型(如LOL数据集预训练和MIT-5K数据集预训练)。</p><p><img src="/./images/Computer_Vision/7.png"></p><p><img src="/./images/Computer_Vision/8.png"></p><h3 id="3-论文源码解析"><a href="#3-论文源码解析" class="headerlink" title="3. 论文源码解析"></a>3. 论文源码解析</h3><h4 id="3-1-IAT-model-py"><a href="#3-1-IAT-model-py" class="headerlink" title="3.1 IAT_model.py"></a>3.1 IAT_model.py</h4><p>IAT模型除了常规的导入<code>torch</code>、<code>numpy</code>外，还需要额外导入两个作者自己实现的一些模型结构细节，首先是<code>Global_pred</code>其次是<code>CBlock_ln</code>和<code>SwinTransformerBlock</code>。</p><ul><li><code>Global_pred.py</code></li></ul><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> imp<span class="token keyword">import</span> torch<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn<span class="token keyword">from</span> timm<span class="token punctuation">.</span>models<span class="token punctuation">.</span>layers <span class="token keyword">import</span> trunc_normal_<span class="token punctuation">,</span> DropPath<span class="token punctuation">,</span> to_2tuple<span class="token keyword">import</span> os<span class="token keyword">class</span> <span class="token class-name">Mlp</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment"># taken from https://github.com/rwightman/pytorch-image-models/blob/master/timm/models/vision_transformer.py</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_features<span class="token punctuation">,</span> hidden_features<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> act_layer<span class="token operator">=</span>nn<span class="token punctuation">.</span>GELU<span class="token punctuation">,</span> drop<span class="token operator">=</span><span class="token number">0.</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        out_features <span class="token operator">=</span> out_features <span class="token keyword">or</span> in_features        hidden_features <span class="token operator">=</span> hidden_features <span class="token keyword">or</span> in_features        self<span class="token punctuation">.</span>fc1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>in_features<span class="token punctuation">,</span> hidden_features<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>act <span class="token operator">=</span> act_layer<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>fc2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>hidden_features<span class="token punctuation">,</span> out_features<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>drop <span class="token operator">=</span> nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>drop<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>fc1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>act<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>drop<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>fc2<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>drop<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">return</span> x<span class="token keyword">class</span> <span class="token class-name">query_Attention</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> dim<span class="token punctuation">,</span> num_heads<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> qkv_bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> qk_scale<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> attn_drop<span class="token operator">=</span><span class="token number">0.</span><span class="token punctuation">,</span> proj_drop<span class="token operator">=</span><span class="token number">0.</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>num_heads <span class="token operator">=</span> num_heads        head_dim <span class="token operator">=</span> dim <span class="token operator">//</span> num_heads        <span class="token comment"># NOTE scale factor was wrong in my original version, can set manually to be compat with prev weights</span>        self<span class="token punctuation">.</span>scale <span class="token operator">=</span> qk_scale <span class="token keyword">or</span> head_dim <span class="token operator">**</span> <span class="token operator">-</span><span class="token number">0.5</span>        self<span class="token punctuation">.</span>q <span class="token operator">=</span> nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> dim<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>k <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>dim<span class="token punctuation">,</span> dim<span class="token punctuation">,</span> bias<span class="token operator">=</span>qkv_bias<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>v <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>dim<span class="token punctuation">,</span> dim<span class="token punctuation">,</span> bias<span class="token operator">=</span>qkv_bias<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>attn_drop <span class="token operator">=</span> nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>attn_drop<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>proj <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>dim<span class="token punctuation">,</span> dim<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>proj_drop <span class="token operator">=</span> nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>proj_drop<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        B<span class="token punctuation">,</span> N<span class="token punctuation">,</span> C <span class="token operator">=</span> x<span class="token punctuation">.</span>shape        k <span class="token operator">=</span> self<span class="token punctuation">.</span>k<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>B<span class="token punctuation">,</span> N<span class="token punctuation">,</span> self<span class="token punctuation">.</span>num_heads<span class="token punctuation">,</span> C <span class="token operator">//</span> self<span class="token punctuation">.</span>num_heads<span class="token punctuation">)</span><span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>        v <span class="token operator">=</span> self<span class="token punctuation">.</span>v<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>B<span class="token punctuation">,</span> N<span class="token punctuation">,</span> self<span class="token punctuation">.</span>num_heads<span class="token punctuation">,</span> C <span class="token operator">//</span> self<span class="token punctuation">.</span>num_heads<span class="token punctuation">)</span><span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>        q <span class="token operator">=</span> self<span class="token punctuation">.</span>q<span class="token punctuation">.</span>expand<span class="token punctuation">(</span>B<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span>B<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>num_heads<span class="token punctuation">,</span> C <span class="token operator">//</span> self<span class="token punctuation">.</span>num_heads<span class="token punctuation">)</span><span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>        attn <span class="token operator">=</span> <span class="token punctuation">(</span>q @ k<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">*</span> self<span class="token punctuation">.</span>scale        attn <span class="token operator">=</span> attn<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>        attn <span class="token operator">=</span> self<span class="token punctuation">.</span>attn_drop<span class="token punctuation">(</span>attn<span class="token punctuation">)</span>        x <span class="token operator">=</span> <span class="token punctuation">(</span>attn @ v<span class="token punctuation">)</span><span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>B<span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> C<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>proj<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>proj_drop<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">return</span> x<span class="token keyword">class</span> <span class="token class-name">query_SABlock</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> dim<span class="token punctuation">,</span> num_heads<span class="token punctuation">,</span> mlp_ratio<span class="token operator">=</span><span class="token number">4.</span><span class="token punctuation">,</span> qkv_bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> qk_scale<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> drop<span class="token operator">=</span><span class="token number">0.</span><span class="token punctuation">,</span> attn_drop<span class="token operator">=</span><span class="token number">0.</span><span class="token punctuation">,</span>                 drop_path<span class="token operator">=</span><span class="token number">0.</span><span class="token punctuation">,</span> act_layer<span class="token operator">=</span>nn<span class="token punctuation">.</span>GELU<span class="token punctuation">,</span> norm_layer<span class="token operator">=</span>nn<span class="token punctuation">.</span>LayerNorm<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>pos_embed <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>dim<span class="token punctuation">,</span> dim<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> groups<span class="token operator">=</span>dim<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>norm1 <span class="token operator">=</span> norm_layer<span class="token punctuation">(</span>dim<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>attn <span class="token operator">=</span> query_Attention<span class="token punctuation">(</span>            dim<span class="token punctuation">,</span>            num_heads<span class="token operator">=</span>num_heads<span class="token punctuation">,</span> qkv_bias<span class="token operator">=</span>qkv_bias<span class="token punctuation">,</span> qk_scale<span class="token operator">=</span>qk_scale<span class="token punctuation">,</span>            attn_drop<span class="token operator">=</span>attn_drop<span class="token punctuation">,</span> proj_drop<span class="token operator">=</span>drop<span class="token punctuation">)</span>        <span class="token comment"># NOTE: drop path for stochastic depth, we shall see if this is better than dropout here</span>        self<span class="token punctuation">.</span>drop_path <span class="token operator">=</span> DropPath<span class="token punctuation">(</span>drop_path<span class="token punctuation">)</span> <span class="token keyword">if</span> drop_path <span class="token operator">></span> <span class="token number">0.</span> <span class="token keyword">else</span> nn<span class="token punctuation">.</span>Identity<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>norm2 <span class="token operator">=</span> norm_layer<span class="token punctuation">(</span>dim<span class="token punctuation">)</span>        mlp_hidden_dim <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>dim <span class="token operator">*</span> mlp_ratio<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>mlp <span class="token operator">=</span> Mlp<span class="token punctuation">(</span>in_features<span class="token operator">=</span>dim<span class="token punctuation">,</span> hidden_features<span class="token operator">=</span>mlp_hidden_dim<span class="token punctuation">,</span> act_layer<span class="token operator">=</span>act_layer<span class="token punctuation">,</span> drop<span class="token operator">=</span>drop<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        x <span class="token operator">=</span> x <span class="token operator">+</span> self<span class="token punctuation">.</span>pos_embed<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> x<span class="token punctuation">.</span>flatten<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>drop_path<span class="token punctuation">(</span>self<span class="token punctuation">.</span>attn<span class="token punctuation">(</span>self<span class="token punctuation">.</span>norm1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> x <span class="token operator">+</span> self<span class="token punctuation">.</span>drop_path<span class="token punctuation">(</span>self<span class="token punctuation">.</span>mlp<span class="token punctuation">(</span>self<span class="token punctuation">.</span>norm2<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> x<span class="token keyword">class</span> <span class="token class-name">conv_embedding</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>conv_embedding<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>proj <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> out_channels <span class="token operator">//</span> <span class="token number">2</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>out_channels <span class="token operator">//</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>GELU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            <span class="token comment"># nn.Conv2d(out_channels // 2, out_channels // 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),</span>            <span class="token comment"># nn.BatchNorm2d(out_channels // 2),</span>            <span class="token comment"># nn.GELU(),</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>out_channels <span class="token operator">//</span> <span class="token number">2</span><span class="token punctuation">,</span> out_channels<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>out_channels<span class="token punctuation">)</span><span class="token punctuation">,</span>        <span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>proj<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">return</span> x<span class="token keyword">class</span> <span class="token class-name">Global_pred</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_channels<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> out_channels<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span> num_heads<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'exp'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>Global_pred<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">if</span> <span class="token builtin">type</span> <span class="token operator">==</span> <span class="token string">'exp'</span><span class="token punctuation">:</span>            self<span class="token punctuation">.</span>gamma_base <span class="token operator">=</span> nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span> <span class="token comment"># False in exposure correction</span>        <span class="token keyword">else</span><span class="token punctuation">:</span>            self<span class="token punctuation">.</span>gamma_base <span class="token operator">=</span> nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>          self<span class="token punctuation">.</span>color_base <span class="token operator">=</span> nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>eye<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>  <span class="token comment"># basic color matrix</span>        <span class="token comment"># main blocks</span>        self<span class="token punctuation">.</span>conv_large <span class="token operator">=</span> conv_embedding<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>generator <span class="token operator">=</span> query_SABlock<span class="token punctuation">(</span>dim<span class="token operator">=</span>out_channels<span class="token punctuation">,</span> num_heads<span class="token operator">=</span>num_heads<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>gamma_linear <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>out_channels<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>color_linear <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>out_channels<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span><span class="token builtin">apply</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>_init_weights<span class="token punctuation">)</span>        <span class="token keyword">for</span> name<span class="token punctuation">,</span> p <span class="token keyword">in</span> self<span class="token punctuation">.</span>named_parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">if</span> name <span class="token operator">==</span> <span class="token string">'generator.attn.v.weight'</span><span class="token punctuation">:</span>                nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>constant_<span class="token punctuation">(</span>p<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">_init_weights</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> m<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">if</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>m<span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">)</span><span class="token punctuation">:</span>            trunc_normal_<span class="token punctuation">(</span>m<span class="token punctuation">.</span>weight<span class="token punctuation">,</span> std<span class="token operator">=</span><span class="token number">.02</span><span class="token punctuation">)</span>            <span class="token keyword">if</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>m<span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">)</span> <span class="token keyword">and</span> m<span class="token punctuation">.</span>bias <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>                nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>constant_<span class="token punctuation">(</span>m<span class="token punctuation">.</span>bias<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span>        <span class="token keyword">elif</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>m<span class="token punctuation">,</span> nn<span class="token punctuation">.</span>LayerNorm<span class="token punctuation">)</span><span class="token punctuation">:</span>            nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>constant_<span class="token punctuation">(</span>m<span class="token punctuation">.</span>bias<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span>            nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>constant_<span class="token punctuation">(</span>m<span class="token punctuation">.</span>weight<span class="token punctuation">,</span> <span class="token number">1.0</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment">#print(self.gamma_base)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>conv_large<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>generator<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        gamma<span class="token punctuation">,</span> color <span class="token operator">=</span> x<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> x<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span>        gamma <span class="token operator">=</span> self<span class="token punctuation">.</span>gamma_linear<span class="token punctuation">(</span>gamma<span class="token punctuation">)</span><span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">+</span> self<span class="token punctuation">.</span>gamma_base        <span class="token comment">#print(self.gamma_base, self.gamma_linear(gamma))</span>        color <span class="token operator">=</span> self<span class="token punctuation">.</span>color_linear<span class="token punctuation">(</span>color<span class="token punctuation">)</span><span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span> <span class="token operator">+</span> self<span class="token punctuation">.</span>color_base        <span class="token keyword">return</span> gamma<span class="token punctuation">,</span> color<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">"__main__"</span><span class="token punctuation">:</span>    os<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">'CUDA_VISIBLE_DEVICES'</span><span class="token punctuation">]</span><span class="token operator">=</span><span class="token string">'3'</span>    <span class="token comment">#net = Local_pred_new().cuda()</span>    img <span class="token operator">=</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">400</span><span class="token punctuation">,</span> <span class="token number">600</span><span class="token punctuation">)</span>    global_net <span class="token operator">=</span> Global_pred<span class="token punctuation">(</span><span class="token punctuation">)</span>    gamma<span class="token punctuation">,</span> color <span class="token operator">=</span> global_net<span class="token punctuation">(</span>img<span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>gamma<span class="token punctuation">.</span>shape<span class="token punctuation">,</span> color<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ul><li><code>blocks.py</code></li></ul><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token triple-quoted-string string">"""Code copy from uniformer source code:https://github.com/Sense-X/UniFormer"""</span><span class="token keyword">import</span> os<span class="token keyword">import</span> torch<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn<span class="token keyword">from</span> functools <span class="token keyword">import</span> partial<span class="token keyword">import</span> math<span class="token keyword">from</span> timm<span class="token punctuation">.</span>models<span class="token punctuation">.</span>vision_transformer <span class="token keyword">import</span> VisionTransformer<span class="token punctuation">,</span> _cfg<span class="token keyword">from</span> timm<span class="token punctuation">.</span>models<span class="token punctuation">.</span>registry <span class="token keyword">import</span> register_model<span class="token keyword">from</span> timm<span class="token punctuation">.</span>models<span class="token punctuation">.</span>layers <span class="token keyword">import</span> trunc_normal_<span class="token punctuation">,</span> DropPath<span class="token punctuation">,</span> to_2tuple<span class="token comment"># ResMLP's normalization</span><span class="token keyword">class</span> <span class="token class-name">Aff</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> dim<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment"># learnable</span>        self<span class="token punctuation">.</span>alpha <span class="token operator">=</span> nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> dim<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>beta <span class="token operator">=</span> nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> dim<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        x <span class="token operator">=</span> x <span class="token operator">*</span> self<span class="token punctuation">.</span>alpha <span class="token operator">+</span> self<span class="token punctuation">.</span>beta        <span class="token keyword">return</span> x<span class="token comment"># Color Normalization</span><span class="token keyword">class</span> <span class="token class-name">Aff_channel</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> dim<span class="token punctuation">,</span> channel_first <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment"># learnable</span>        self<span class="token punctuation">.</span>alpha <span class="token operator">=</span> nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> dim<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>beta <span class="token operator">=</span> nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> dim<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>color <span class="token operator">=</span> nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>eye<span class="token punctuation">(</span>dim<span class="token punctuation">)</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>channel_first <span class="token operator">=</span> channel_first    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">if</span> self<span class="token punctuation">.</span>channel_first<span class="token punctuation">:</span>            x1 <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensordot<span class="token punctuation">(</span>x<span class="token punctuation">,</span> self<span class="token punctuation">.</span>color<span class="token punctuation">,</span> dims<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>            x2 <span class="token operator">=</span> x1 <span class="token operator">*</span> self<span class="token punctuation">.</span>alpha <span class="token operator">+</span> self<span class="token punctuation">.</span>beta        <span class="token keyword">else</span><span class="token punctuation">:</span>            x1 <span class="token operator">=</span> x <span class="token operator">*</span> self<span class="token punctuation">.</span>alpha <span class="token operator">+</span> self<span class="token punctuation">.</span>beta            x2 <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensordot<span class="token punctuation">(</span>x1<span class="token punctuation">,</span> self<span class="token punctuation">.</span>color<span class="token punctuation">,</span> dims<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> x2<span class="token keyword">class</span> <span class="token class-name">Mlp</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment"># taken from https://github.com/rwightman/pytorch-image-models/blob/master/timm/models/vision_transformer.py</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_features<span class="token punctuation">,</span> hidden_features<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> act_layer<span class="token operator">=</span>nn<span class="token punctuation">.</span>GELU<span class="token punctuation">,</span> drop<span class="token operator">=</span><span class="token number">0.</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        out_features <span class="token operator">=</span> out_features <span class="token keyword">or</span> in_features        hidden_features <span class="token operator">=</span> hidden_features <span class="token keyword">or</span> in_features        self<span class="token punctuation">.</span>fc1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>in_features<span class="token punctuation">,</span> hidden_features<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>act <span class="token operator">=</span> act_layer<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>fc2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>hidden_features<span class="token punctuation">,</span> out_features<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>drop <span class="token operator">=</span> nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>drop<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>fc1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>act<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>drop<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>fc2<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>drop<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">return</span> x<span class="token keyword">class</span> <span class="token class-name">CMlp</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment"># taken from https://github.com/rwightman/pytorch-image-models/blob/master/timm/models/vision_transformer.py</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_features<span class="token punctuation">,</span> hidden_features<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> act_layer<span class="token operator">=</span>nn<span class="token punctuation">.</span>GELU<span class="token punctuation">,</span> drop<span class="token operator">=</span><span class="token number">0.</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        out_features <span class="token operator">=</span> out_features <span class="token keyword">or</span> in_features        hidden_features <span class="token operator">=</span> hidden_features <span class="token keyword">or</span> in_features        self<span class="token punctuation">.</span>fc1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_features<span class="token punctuation">,</span> hidden_features<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>act <span class="token operator">=</span> act_layer<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>fc2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>hidden_features<span class="token punctuation">,</span> out_features<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>drop <span class="token operator">=</span> nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>drop<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>fc1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>act<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>drop<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>fc2<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>drop<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">return</span> x<span class="token keyword">class</span> <span class="token class-name">CBlock_ln</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> dim<span class="token punctuation">,</span> mlp_ratio<span class="token operator">=</span><span class="token number">4.</span><span class="token punctuation">,</span> qkv_bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> qk_scale<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> drop<span class="token operator">=</span><span class="token number">0.</span><span class="token punctuation">,</span> attn_drop<span class="token operator">=</span><span class="token number">0.</span><span class="token punctuation">,</span>                 drop_path<span class="token operator">=</span><span class="token number">0.</span><span class="token punctuation">,</span> act_layer<span class="token operator">=</span>nn<span class="token punctuation">.</span>GELU<span class="token punctuation">,</span> norm_layer<span class="token operator">=</span>Aff_channel<span class="token punctuation">,</span> init_values<span class="token operator">=</span><span class="token number">1e-4</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>pos_embed <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>dim<span class="token punctuation">,</span> dim<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> groups<span class="token operator">=</span>dim<span class="token punctuation">)</span>        <span class="token comment">#self.norm1 = Aff_channel(dim)</span>        self<span class="token punctuation">.</span>norm1 <span class="token operator">=</span> norm_layer<span class="token punctuation">(</span>dim<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>dim<span class="token punctuation">,</span> dim<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>conv2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>dim<span class="token punctuation">,</span> dim<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>attn <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>dim<span class="token punctuation">,</span> dim<span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> groups<span class="token operator">=</span>dim<span class="token punctuation">)</span>        <span class="token comment"># NOTE: drop path for stochastic depth, we shall see if this is better than dropout here</span>        self<span class="token punctuation">.</span>drop_path <span class="token operator">=</span> DropPath<span class="token punctuation">(</span>drop_path<span class="token punctuation">)</span> <span class="token keyword">if</span> drop_path <span class="token operator">></span> <span class="token number">0.</span> <span class="token keyword">else</span> nn<span class="token punctuation">.</span>Identity<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment">#self.norm2 = Aff_channel(dim)</span>        self<span class="token punctuation">.</span>norm2 <span class="token operator">=</span> norm_layer<span class="token punctuation">(</span>dim<span class="token punctuation">)</span>        mlp_hidden_dim <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>dim <span class="token operator">*</span> mlp_ratio<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>gamma_1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>init_values <span class="token operator">*</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> dim<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>gamma_2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>init_values <span class="token operator">*</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> dim<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>mlp <span class="token operator">=</span> CMlp<span class="token punctuation">(</span>in_features<span class="token operator">=</span>dim<span class="token punctuation">,</span> hidden_features<span class="token operator">=</span>mlp_hidden_dim<span class="token punctuation">,</span> act_layer<span class="token operator">=</span>act_layer<span class="token punctuation">,</span> drop<span class="token operator">=</span>drop<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        x <span class="token operator">=</span> x <span class="token operator">+</span> self<span class="token punctuation">.</span>pos_embed<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        B<span class="token punctuation">,</span> C<span class="token punctuation">,</span> H<span class="token punctuation">,</span> W <span class="token operator">=</span> x<span class="token punctuation">.</span>shape        <span class="token comment">#print(x.shape)</span>        norm_x <span class="token operator">=</span> x<span class="token punctuation">.</span>flatten<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>        <span class="token comment">#print(norm_x.shape)</span>        norm_x <span class="token operator">=</span> self<span class="token punctuation">.</span>norm1<span class="token punctuation">(</span>norm_x<span class="token punctuation">)</span>        norm_x <span class="token operator">=</span> norm_x<span class="token punctuation">.</span>view<span class="token punctuation">(</span>B<span class="token punctuation">,</span> H<span class="token punctuation">,</span> W<span class="token punctuation">,</span> C<span class="token punctuation">)</span><span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> x <span class="token operator">+</span> self<span class="token punctuation">.</span>drop_path<span class="token punctuation">(</span>self<span class="token punctuation">.</span>gamma_1<span class="token operator">*</span>self<span class="token punctuation">.</span>conv2<span class="token punctuation">(</span>self<span class="token punctuation">.</span>attn<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>norm_x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        norm_x <span class="token operator">=</span> x<span class="token punctuation">.</span>flatten<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>        norm_x <span class="token operator">=</span> self<span class="token punctuation">.</span>norm2<span class="token punctuation">(</span>norm_x<span class="token punctuation">)</span>        norm_x <span class="token operator">=</span> norm_x<span class="token punctuation">.</span>view<span class="token punctuation">(</span>B<span class="token punctuation">,</span> H<span class="token punctuation">,</span> W<span class="token punctuation">,</span> C<span class="token punctuation">)</span><span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> x <span class="token operator">+</span> self<span class="token punctuation">.</span>drop_path<span class="token punctuation">(</span>self<span class="token punctuation">.</span>gamma_2<span class="token operator">*</span>self<span class="token punctuation">.</span>mlp<span class="token punctuation">(</span>norm_x<span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> x<span class="token keyword">def</span> <span class="token function">window_partition</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> window_size<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""    Args:        x: (B, H, W, C)        window_size (int): window size    Returns:        windows: (num_windows*B, window_size, window_size, C)    """</span>    B<span class="token punctuation">,</span> H<span class="token punctuation">,</span> W<span class="token punctuation">,</span> C <span class="token operator">=</span> x<span class="token punctuation">.</span>shape    <span class="token comment">#print(x.shape)</span>    x <span class="token operator">=</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span>B<span class="token punctuation">,</span> H <span class="token operator">//</span> window_size<span class="token punctuation">,</span> window_size<span class="token punctuation">,</span> W <span class="token operator">//</span> window_size<span class="token punctuation">,</span> window_size<span class="token punctuation">,</span> C<span class="token punctuation">)</span>    windows <span class="token operator">=</span> x<span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">.</span>contiguous<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> window_size<span class="token punctuation">,</span> window_size<span class="token punctuation">,</span> C<span class="token punctuation">)</span>    <span class="token keyword">return</span> windows<span class="token keyword">def</span> <span class="token function">window_reverse</span><span class="token punctuation">(</span>windows<span class="token punctuation">,</span> window_size<span class="token punctuation">,</span> H<span class="token punctuation">,</span> W<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""    Args:        windows: (num_windows*B, window_size, window_size, C)        window_size (int): Window size        H (int): Height of image        W (int): Width of image    Returns:        x: (B, H, W, C)    """</span>    B <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>windows<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">/</span> <span class="token punctuation">(</span>H <span class="token operator">*</span> W <span class="token operator">/</span> window_size <span class="token operator">/</span> window_size<span class="token punctuation">)</span><span class="token punctuation">)</span>    x <span class="token operator">=</span> windows<span class="token punctuation">.</span>view<span class="token punctuation">(</span>B<span class="token punctuation">,</span> H <span class="token operator">//</span> window_size<span class="token punctuation">,</span> W <span class="token operator">//</span> window_size<span class="token punctuation">,</span> window_size<span class="token punctuation">,</span> window_size<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>    x <span class="token operator">=</span> x<span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">.</span>contiguous<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span>B<span class="token punctuation">,</span> H<span class="token punctuation">,</span> W<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> x<span class="token keyword">class</span> <span class="token class-name">WindowAttention</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">r""" Window based multi-head self attention (W-MSA) module with relative position bias.    It supports both of shifted and non-shifted window.    Args:        dim (int): Number of input channels.        window_size (tuple[int]): The height and width of the window.        num_heads (int): Number of attention heads.        qkv_bias (bool, optional):  If True, add a learnable bias to query, key, value. Default: True        qk_scale (float | None, optional): Override default qk scale of head_dim ** -0.5 if set        attn_drop (float, optional): Dropout ratio of attention weight. Default: 0.0        proj_drop (float, optional): Dropout ratio of output. Default: 0.0    """</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> dim<span class="token punctuation">,</span> window_size<span class="token punctuation">,</span> num_heads<span class="token punctuation">,</span> qkv_bias<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> qk_scale<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> attn_drop<span class="token operator">=</span><span class="token number">0.</span><span class="token punctuation">,</span> proj_drop<span class="token operator">=</span><span class="token number">0.</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>dim <span class="token operator">=</span> dim        self<span class="token punctuation">.</span>window_size <span class="token operator">=</span> window_size  <span class="token comment"># Wh, Ww</span>        self<span class="token punctuation">.</span>num_heads <span class="token operator">=</span> num_heads        head_dim <span class="token operator">=</span> dim <span class="token operator">//</span> num_heads        self<span class="token punctuation">.</span>scale <span class="token operator">=</span> qk_scale <span class="token keyword">or</span> head_dim <span class="token operator">**</span> <span class="token operator">-</span><span class="token number">0.5</span>        self<span class="token punctuation">.</span>qkv <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>dim<span class="token punctuation">,</span> dim <span class="token operator">*</span> <span class="token number">3</span><span class="token punctuation">,</span> bias<span class="token operator">=</span>qkv_bias<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>attn_drop <span class="token operator">=</span> nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>attn_drop<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>proj <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>dim<span class="token punctuation">,</span> dim<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>proj_drop <span class="token operator">=</span> nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>proj_drop<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>softmax <span class="token operator">=</span> nn<span class="token punctuation">.</span>Softmax<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        B_<span class="token punctuation">,</span> N<span class="token punctuation">,</span> C <span class="token operator">=</span> x<span class="token punctuation">.</span>shape        qkv <span class="token operator">=</span> self<span class="token punctuation">.</span>qkv<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>B_<span class="token punctuation">,</span> N<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>num_heads<span class="token punctuation">,</span> C <span class="token operator">//</span> self<span class="token punctuation">.</span>num_heads<span class="token punctuation">)</span><span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>        q<span class="token punctuation">,</span> k<span class="token punctuation">,</span> v <span class="token operator">=</span> qkv<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> qkv<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> qkv<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span>  <span class="token comment"># make torchscript happy (cannot use tensor as tuple)</span>        q <span class="token operator">=</span> q <span class="token operator">*</span> self<span class="token punctuation">.</span>scale        attn <span class="token operator">=</span> <span class="token punctuation">(</span>q @ k<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        attn <span class="token operator">=</span> self<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>attn<span class="token punctuation">)</span>        attn <span class="token operator">=</span> self<span class="token punctuation">.</span>attn_drop<span class="token punctuation">(</span>attn<span class="token punctuation">)</span>        x <span class="token operator">=</span> <span class="token punctuation">(</span>attn @ v<span class="token punctuation">)</span><span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>B_<span class="token punctuation">,</span> N<span class="token punctuation">,</span> C<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>proj<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>proj_drop<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">return</span> x<span class="token comment">## Layer_norm, Aff_norm, Aff_channel_norm</span><span class="token keyword">class</span> <span class="token class-name">SwinTransformerBlock</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">r""" Swin Transformer Block.    Args:        dim (int): Number of input channels.        input_resolution (tuple[int]): Input resulotion.        num_heads (int): Number of attention heads.        window_size (int): Window size.        shift_size (int): Shift size for SW-MSA.        mlp_ratio (float): Ratio of mlp hidden dim to embedding dim.        qkv_bias (bool, optional): If True, add a learnable bias to query, key, value. Default: True        qk_scale (float | None, optional): Override default qk scale of head_dim ** -0.5 if set.        drop (float, optional): Dropout rate. Default: 0.0        attn_drop (float, optional): Attention dropout rate. Default: 0.0        drop_path (float, optional): Stochastic depth rate. Default: 0.0        act_layer (nn.Module, optional): Activation layer. Default: nn.GELU        norm_layer (nn.Module, optional): Normalization layer.  Default: nn.LayerNorm    """</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> dim<span class="token punctuation">,</span> num_heads<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> window_size<span class="token operator">=</span><span class="token number">8</span><span class="token punctuation">,</span> shift_size<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span>                 mlp_ratio<span class="token operator">=</span><span class="token number">4.</span><span class="token punctuation">,</span> qkv_bias<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> qk_scale<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> drop<span class="token operator">=</span><span class="token number">0.</span><span class="token punctuation">,</span> attn_drop<span class="token operator">=</span><span class="token number">0.</span><span class="token punctuation">,</span> drop_path<span class="token operator">=</span><span class="token number">0.</span><span class="token punctuation">,</span>                 act_layer<span class="token operator">=</span>nn<span class="token punctuation">.</span>GELU<span class="token punctuation">,</span> norm_layer<span class="token operator">=</span>Aff_channel<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>dim <span class="token operator">=</span> dim        self<span class="token punctuation">.</span>num_heads <span class="token operator">=</span> num_heads        self<span class="token punctuation">.</span>window_size <span class="token operator">=</span> window_size        self<span class="token punctuation">.</span>shift_size <span class="token operator">=</span> shift_size        self<span class="token punctuation">.</span>mlp_ratio <span class="token operator">=</span> mlp_ratio        self<span class="token punctuation">.</span>pos_embed <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>dim<span class="token punctuation">,</span> dim<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> groups<span class="token operator">=</span>dim<span class="token punctuation">)</span>        <span class="token comment">#self.norm1 = norm_layer(dim)</span>        self<span class="token punctuation">.</span>norm1 <span class="token operator">=</span> norm_layer<span class="token punctuation">(</span>dim<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>attn <span class="token operator">=</span> WindowAttention<span class="token punctuation">(</span>            dim<span class="token punctuation">,</span> window_size<span class="token operator">=</span>to_2tuple<span class="token punctuation">(</span>self<span class="token punctuation">.</span>window_size<span class="token punctuation">)</span><span class="token punctuation">,</span> num_heads<span class="token operator">=</span>num_heads<span class="token punctuation">,</span>            qkv_bias<span class="token operator">=</span>qkv_bias<span class="token punctuation">,</span> qk_scale<span class="token operator">=</span>qk_scale<span class="token punctuation">,</span> attn_drop<span class="token operator">=</span>attn_drop<span class="token punctuation">,</span> proj_drop<span class="token operator">=</span>drop<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>drop_path <span class="token operator">=</span> DropPath<span class="token punctuation">(</span>drop_path<span class="token punctuation">)</span> <span class="token keyword">if</span> drop_path <span class="token operator">></span> <span class="token number">0.</span> <span class="token keyword">else</span> nn<span class="token punctuation">.</span>Identity<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment">#self.norm2 = norm_layer(dim)</span>        self<span class="token punctuation">.</span>norm2 <span class="token operator">=</span> norm_layer<span class="token punctuation">(</span>dim<span class="token punctuation">)</span>        mlp_hidden_dim <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>dim <span class="token operator">*</span> mlp_ratio<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>mlp <span class="token operator">=</span> Mlp<span class="token punctuation">(</span>in_features<span class="token operator">=</span>dim<span class="token punctuation">,</span> hidden_features<span class="token operator">=</span>mlp_hidden_dim<span class="token punctuation">,</span> act_layer<span class="token operator">=</span>act_layer<span class="token punctuation">,</span> drop<span class="token operator">=</span>drop<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        x <span class="token operator">=</span> x <span class="token operator">+</span> self<span class="token punctuation">.</span>pos_embed<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        B<span class="token punctuation">,</span> C<span class="token punctuation">,</span> H<span class="token punctuation">,</span> W <span class="token operator">=</span> x<span class="token punctuation">.</span>shape        x <span class="token operator">=</span> x<span class="token punctuation">.</span>flatten<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>        shortcut <span class="token operator">=</span> x        x <span class="token operator">=</span> self<span class="token punctuation">.</span>norm1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span>B<span class="token punctuation">,</span> H<span class="token punctuation">,</span> W<span class="token punctuation">,</span> C<span class="token punctuation">)</span>        <span class="token comment"># cyclic shift</span>        <span class="token keyword">if</span> self<span class="token punctuation">.</span>shift_size <span class="token operator">></span> <span class="token number">0</span><span class="token punctuation">:</span>            shifted_x <span class="token operator">=</span> torch<span class="token punctuation">.</span>roll<span class="token punctuation">(</span>x<span class="token punctuation">,</span> shifts<span class="token operator">=</span><span class="token punctuation">(</span><span class="token operator">-</span>self<span class="token punctuation">.</span>shift_size<span class="token punctuation">,</span> <span class="token operator">-</span>self<span class="token punctuation">.</span>shift_size<span class="token punctuation">)</span><span class="token punctuation">,</span> dims<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">else</span><span class="token punctuation">:</span>            shifted_x <span class="token operator">=</span> x        <span class="token comment"># partition windows</span>        x_windows <span class="token operator">=</span> window_partition<span class="token punctuation">(</span>shifted_x<span class="token punctuation">,</span> self<span class="token punctuation">.</span>window_size<span class="token punctuation">)</span>  <span class="token comment"># nW*B, window_size, window_size, C</span>        x_windows <span class="token operator">=</span> x_windows<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>window_size <span class="token operator">*</span> self<span class="token punctuation">.</span>window_size<span class="token punctuation">,</span> C<span class="token punctuation">)</span>  <span class="token comment"># nW*B, window_size*window_size, C</span>        <span class="token comment"># W-MSA/SW-MSA</span>        attn_windows <span class="token operator">=</span> self<span class="token punctuation">.</span>attn<span class="token punctuation">(</span>x_windows<span class="token punctuation">)</span>  <span class="token comment"># nW*B, window_size*window_size, C</span>        <span class="token comment"># merge windows</span>        attn_windows <span class="token operator">=</span> attn_windows<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>window_size<span class="token punctuation">,</span> self<span class="token punctuation">.</span>window_size<span class="token punctuation">,</span> C<span class="token punctuation">)</span>        shifted_x <span class="token operator">=</span> window_reverse<span class="token punctuation">(</span>attn_windows<span class="token punctuation">,</span> self<span class="token punctuation">.</span>window_size<span class="token punctuation">,</span> H<span class="token punctuation">,</span> W<span class="token punctuation">)</span>  <span class="token comment"># B H' W' C</span>        x <span class="token operator">=</span> shifted_x        x <span class="token operator">=</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span>B<span class="token punctuation">,</span> H <span class="token operator">*</span> W<span class="token punctuation">,</span> C<span class="token punctuation">)</span>        <span class="token comment"># FFN</span>        x <span class="token operator">=</span> shortcut <span class="token operator">+</span> self<span class="token punctuation">.</span>drop_path<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> x <span class="token operator">+</span> self<span class="token punctuation">.</span>drop_path<span class="token punctuation">(</span>self<span class="token punctuation">.</span>mlp<span class="token punctuation">(</span>self<span class="token punctuation">.</span>norm2<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> x<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>B<span class="token punctuation">,</span> C<span class="token punctuation">,</span> H<span class="token punctuation">,</span> W<span class="token punctuation">)</span>        <span class="token keyword">return</span> x<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">"__main__"</span><span class="token punctuation">:</span>    os<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">'CUDA_VISIBLE_DEVICES'</span><span class="token punctuation">]</span><span class="token operator">=</span><span class="token string">'1'</span>    cb_blovk <span class="token operator">=</span> CBlock_ln<span class="token punctuation">(</span>dim <span class="token operator">=</span> <span class="token number">16</span><span class="token punctuation">)</span>    x <span class="token operator">=</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">400</span><span class="token punctuation">,</span> <span class="token number">600</span><span class="token punctuation">)</span>    swin <span class="token operator">=</span> SwinTransformerBlock<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">,</span> num_heads<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">)</span>    x <span class="token operator">=</span> cb_blovk<span class="token punctuation">(</span>x<span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>x<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ul><li><code>IAT_main.py</code></li></ul><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F<span class="token keyword">import</span> os<span class="token keyword">import</span> math<span class="token keyword">from</span> timm<span class="token punctuation">.</span>models<span class="token punctuation">.</span>layers <span class="token keyword">import</span> trunc_normal_<span class="token keyword">from</span> blocks <span class="token keyword">import</span> CBlock_ln<span class="token punctuation">,</span> SwinTransformerBlock<span class="token keyword">from</span> global_net <span class="token keyword">import</span> Global_pred<span class="token keyword">from</span> thop <span class="token keyword">import</span> clever_format<span class="token keyword">from</span> thop <span class="token keyword">import</span> profile<span class="token keyword">class</span> <span class="token class-name">Local_pred</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">,</span> number<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'ccc'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>Local_pred<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment"># initial convolution</span>        self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> dim<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> groups<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>relu <span class="token operator">=</span> nn<span class="token punctuation">.</span>LeakyReLU<span class="token punctuation">(</span>negative_slope<span class="token operator">=</span><span class="token number">0.2</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>        <span class="token comment"># main blocks</span>        block <span class="token operator">=</span> CBlock_ln<span class="token punctuation">(</span>dim<span class="token punctuation">)</span>        block_t <span class="token operator">=</span> SwinTransformerBlock<span class="token punctuation">(</span>dim<span class="token punctuation">)</span>  <span class="token comment"># head number</span>        <span class="token keyword">if</span> <span class="token builtin">type</span> <span class="token operator">==</span><span class="token string">'ccc'</span><span class="token punctuation">:</span>              <span class="token comment">#blocks1, blocks2 = [block for _ in range(number)], [block for _ in range(number)]</span>            blocks1 <span class="token operator">=</span> <span class="token punctuation">[</span>CBlock_ln<span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span> drop_path<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">)</span><span class="token punctuation">,</span> CBlock_ln<span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span> drop_path<span class="token operator">=</span><span class="token number">0.05</span><span class="token punctuation">)</span><span class="token punctuation">,</span> CBlock_ln<span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span> drop_path<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">)</span><span class="token punctuation">]</span>            blocks2 <span class="token operator">=</span> <span class="token punctuation">[</span>CBlock_ln<span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span> drop_path<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">)</span><span class="token punctuation">,</span> CBlock_ln<span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span> drop_path<span class="token operator">=</span><span class="token number">0.05</span><span class="token punctuation">)</span><span class="token punctuation">,</span> CBlock_ln<span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span> drop_path<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">)</span><span class="token punctuation">]</span>        <span class="token keyword">elif</span> <span class="token builtin">type</span> <span class="token operator">==</span><span class="token string">'ttt'</span><span class="token punctuation">:</span>            blocks1<span class="token punctuation">,</span> blocks2 <span class="token operator">=</span> <span class="token punctuation">[</span>block_t <span class="token keyword">for</span> _ <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>number<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span>block_t <span class="token keyword">for</span> _ <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>number<span class="token punctuation">)</span><span class="token punctuation">]</span>        <span class="token keyword">elif</span> <span class="token builtin">type</span> <span class="token operator">==</span><span class="token string">'cct'</span><span class="token punctuation">:</span>            blocks1<span class="token punctuation">,</span> blocks2 <span class="token operator">=</span> <span class="token punctuation">[</span>block<span class="token punctuation">,</span> block<span class="token punctuation">,</span> block_t<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span>block<span class="token punctuation">,</span> block<span class="token punctuation">,</span> block_t<span class="token punctuation">]</span>        <span class="token comment">#    block1 = [CBlock_ln(16), nn.Conv2d(16,24,3,1,1)]</span>        self<span class="token punctuation">.</span>mul_blocks <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token operator">*</span>blocks1<span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>dim<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>add_blocks <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token operator">*</span>blocks2<span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>dim<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Tanh<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> img<span class="token punctuation">)</span><span class="token punctuation">:</span>        img1 <span class="token operator">=</span> self<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>img<span class="token punctuation">)</span><span class="token punctuation">)</span>        mul <span class="token operator">=</span> self<span class="token punctuation">.</span>mul_blocks<span class="token punctuation">(</span>img1<span class="token punctuation">)</span>        add <span class="token operator">=</span> self<span class="token punctuation">.</span>add_blocks<span class="token punctuation">(</span>img1<span class="token punctuation">)</span>        <span class="token keyword">return</span> mul<span class="token punctuation">,</span> add<span class="token comment"># Short Cut Connection on Final Layer</span><span class="token keyword">class</span> <span class="token class-name">Local_pred_S</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_dim<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">,</span> number<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'ccc'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>Local_pred_S<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment"># initial convolution</span>        self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_dim<span class="token punctuation">,</span> dim<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> groups<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>relu <span class="token operator">=</span> nn<span class="token punctuation">.</span>LeakyReLU<span class="token punctuation">(</span>negative_slope<span class="token operator">=</span><span class="token number">0.2</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>        <span class="token comment"># main blocks</span>        block <span class="token operator">=</span> CBlock_ln<span class="token punctuation">(</span>dim<span class="token punctuation">)</span>        block_t <span class="token operator">=</span> SwinTransformerBlock<span class="token punctuation">(</span>dim<span class="token punctuation">)</span>  <span class="token comment"># head number</span>        <span class="token keyword">if</span> <span class="token builtin">type</span> <span class="token operator">==</span><span class="token string">'ccc'</span><span class="token punctuation">:</span>            blocks1 <span class="token operator">=</span> <span class="token punctuation">[</span>CBlock_ln<span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span> drop_path<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">)</span><span class="token punctuation">,</span> CBlock_ln<span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span> drop_path<span class="token operator">=</span><span class="token number">0.05</span><span class="token punctuation">)</span><span class="token punctuation">,</span> CBlock_ln<span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span> drop_path<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">)</span><span class="token punctuation">]</span>            blocks2 <span class="token operator">=</span> <span class="token punctuation">[</span>CBlock_ln<span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span> drop_path<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">)</span><span class="token punctuation">,</span> CBlock_ln<span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span> drop_path<span class="token operator">=</span><span class="token number">0.05</span><span class="token punctuation">)</span><span class="token punctuation">,</span> CBlock_ln<span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span> drop_path<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">)</span><span class="token punctuation">]</span>        <span class="token keyword">elif</span> <span class="token builtin">type</span> <span class="token operator">==</span><span class="token string">'ttt'</span><span class="token punctuation">:</span>            blocks1<span class="token punctuation">,</span> blocks2 <span class="token operator">=</span> <span class="token punctuation">[</span>block_t <span class="token keyword">for</span> _ <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>number<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span>block_t <span class="token keyword">for</span> _ <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>number<span class="token punctuation">)</span><span class="token punctuation">]</span>        <span class="token keyword">elif</span> <span class="token builtin">type</span> <span class="token operator">==</span><span class="token string">'cct'</span><span class="token punctuation">:</span>            blocks1<span class="token punctuation">,</span> blocks2 <span class="token operator">=</span> <span class="token punctuation">[</span>block<span class="token punctuation">,</span> block<span class="token punctuation">,</span> block_t<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span>block<span class="token punctuation">,</span> block<span class="token punctuation">,</span> block_t<span class="token punctuation">]</span>        <span class="token comment">#    block1 = [CBlock_ln(16), nn.Conv2d(16,24,3,1,1)]</span>        self<span class="token punctuation">.</span>mul_blocks <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token operator">*</span>blocks1<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>add_blocks <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token operator">*</span>blocks2<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>mul_end <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>dim<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>add_end <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>dim<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Tanh<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span><span class="token builtin">apply</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>_init_weights<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">_init_weights</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> m<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">if</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>m<span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">)</span><span class="token punctuation">:</span>            trunc_normal_<span class="token punctuation">(</span>m<span class="token punctuation">.</span>weight<span class="token punctuation">,</span> std<span class="token operator">=</span><span class="token number">.02</span><span class="token punctuation">)</span>            <span class="token keyword">if</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>m<span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">)</span> <span class="token keyword">and</span> m<span class="token punctuation">.</span>bias <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>                nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>constant_<span class="token punctuation">(</span>m<span class="token punctuation">.</span>bias<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span>        <span class="token keyword">elif</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>m<span class="token punctuation">,</span> nn<span class="token punctuation">.</span>LayerNorm<span class="token punctuation">)</span><span class="token punctuation">:</span>            nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>constant_<span class="token punctuation">(</span>m<span class="token punctuation">.</span>bias<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span>            nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>constant_<span class="token punctuation">(</span>m<span class="token punctuation">.</span>weight<span class="token punctuation">,</span> <span class="token number">1.0</span><span class="token punctuation">)</span>        <span class="token keyword">elif</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>m<span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">)</span><span class="token punctuation">:</span>            fan_out <span class="token operator">=</span> m<span class="token punctuation">.</span>kernel_size<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">*</span> m<span class="token punctuation">.</span>kernel_size<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">*</span> m<span class="token punctuation">.</span>out_channels            fan_out <span class="token operator">//=</span> m<span class="token punctuation">.</span>groups            m<span class="token punctuation">.</span>weight<span class="token punctuation">.</span>data<span class="token punctuation">.</span>normal_<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> math<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span><span class="token number">2.0</span> <span class="token operator">/</span> fan_out<span class="token punctuation">)</span><span class="token punctuation">)</span>            <span class="token keyword">if</span> m<span class="token punctuation">.</span>bias <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>                m<span class="token punctuation">.</span>bias<span class="token punctuation">.</span>data<span class="token punctuation">.</span>zero_<span class="token punctuation">(</span><span class="token punctuation">)</span>                            <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> img<span class="token punctuation">)</span><span class="token punctuation">:</span>        img1 <span class="token operator">=</span> self<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>img<span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token comment"># short cut connection</span>        mul <span class="token operator">=</span> self<span class="token punctuation">.</span>mul_blocks<span class="token punctuation">(</span>img1<span class="token punctuation">)</span> <span class="token operator">+</span> img1        add <span class="token operator">=</span> self<span class="token punctuation">.</span>add_blocks<span class="token punctuation">(</span>img1<span class="token punctuation">)</span> <span class="token operator">+</span> img1        mul <span class="token operator">=</span> self<span class="token punctuation">.</span>mul_end<span class="token punctuation">(</span>mul<span class="token punctuation">)</span>        add <span class="token operator">=</span> self<span class="token punctuation">.</span>add_end<span class="token punctuation">(</span>add<span class="token punctuation">)</span>        <span class="token keyword">return</span> mul<span class="token punctuation">,</span> add<span class="token keyword">class</span> <span class="token class-name">IAT</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_dim<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> with_global<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'lol'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>IAT<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment">#self.local_net = Local_pred()</span>                self<span class="token punctuation">.</span>local_net <span class="token operator">=</span> Local_pred_S<span class="token punctuation">(</span>in_dim<span class="token operator">=</span>in_dim<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>with_global <span class="token operator">=</span> with_global        <span class="token keyword">if</span> self<span class="token punctuation">.</span>with_global<span class="token punctuation">:</span>            self<span class="token punctuation">.</span>global_net <span class="token operator">=</span> Global_pred<span class="token punctuation">(</span>in_channels<span class="token operator">=</span>in_dim<span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">type</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">apply_color</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> image<span class="token punctuation">,</span> ccm<span class="token punctuation">)</span><span class="token punctuation">:</span>        shape <span class="token operator">=</span> image<span class="token punctuation">.</span>shape        image <span class="token operator">=</span> image<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>        image <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensordot<span class="token punctuation">(</span>image<span class="token punctuation">,</span> ccm<span class="token punctuation">,</span> dims<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        image <span class="token operator">=</span> image<span class="token punctuation">.</span>view<span class="token punctuation">(</span>shape<span class="token punctuation">)</span>        <span class="token keyword">return</span> torch<span class="token punctuation">.</span>clamp<span class="token punctuation">(</span>image<span class="token punctuation">,</span> <span class="token number">1e-8</span><span class="token punctuation">,</span> <span class="token number">1.0</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> img_low<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment">#print(self.with_global)</span>        mul<span class="token punctuation">,</span> add <span class="token operator">=</span> self<span class="token punctuation">.</span>local_net<span class="token punctuation">(</span>img_low<span class="token punctuation">)</span>        img_high <span class="token operator">=</span> <span class="token punctuation">(</span>img_low<span class="token punctuation">.</span>mul<span class="token punctuation">(</span>mul<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>add<span class="token punctuation">(</span>add<span class="token punctuation">)</span>        <span class="token keyword">if</span> <span class="token keyword">not</span> self<span class="token punctuation">.</span>with_global<span class="token punctuation">:</span>            <span class="token keyword">return</span> mul<span class="token punctuation">,</span> add<span class="token punctuation">,</span> img_high                <span class="token keyword">else</span><span class="token punctuation">:</span>            gamma<span class="token punctuation">,</span> color <span class="token operator">=</span> self<span class="token punctuation">.</span>global_net<span class="token punctuation">(</span>img_low<span class="token punctuation">)</span>            b <span class="token operator">=</span> img_high<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>            img_high <span class="token operator">=</span> img_high<span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment"># (B,C,H,W) -- (B,H,W,C)</span>            img_high <span class="token operator">=</span> torch<span class="token punctuation">.</span>stack<span class="token punctuation">(</span><span class="token punctuation">[</span>self<span class="token punctuation">.</span>apply_color<span class="token punctuation">(</span>img_high<span class="token punctuation">[</span>i<span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">,</span> color<span class="token punctuation">[</span>i<span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">**</span>gamma<span class="token punctuation">[</span>i<span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>b<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>            img_high <span class="token operator">=</span> img_high<span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>  <span class="token comment"># (B,H,W,C) -- (B,C,H,W)</span>            <span class="token keyword">return</span> mul<span class="token punctuation">,</span> add<span class="token punctuation">,</span> img_high<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">"__main__"</span><span class="token punctuation">:</span>    os<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">'CUDA_VISIBLE_DEVICES'</span><span class="token punctuation">]</span><span class="token operator">=</span><span class="token string">'3'</span>    img <span class="token operator">=</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">400</span><span class="token punctuation">,</span> <span class="token number">600</span><span class="token punctuation">)</span>    net <span class="token operator">=</span> IAT<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'total parameters:'</span><span class="token punctuation">,</span> <span class="token builtin">sum</span><span class="token punctuation">(</span>param<span class="token punctuation">.</span>numel<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">for</span> param <span class="token keyword">in</span> net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    _<span class="token punctuation">,</span> _<span class="token punctuation">,</span> high <span class="token operator">=</span> net<span class="token punctuation">(</span>img<span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>high<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>    <span class="token comment"># 测算模型的float与Params</span>    flops<span class="token punctuation">,</span> params <span class="token operator">=</span> profile<span class="token punctuation">(</span>net<span class="token punctuation">,</span> inputs<span class="token operator">=</span><span class="token punctuation">(</span>img<span class="token punctuation">,</span> <span class="token punctuation">)</span><span class="token punctuation">)</span>    flops<span class="token punctuation">,</span> params <span class="token operator">=</span> clever_format<span class="token punctuation">(</span><span class="token punctuation">[</span>flops<span class="token punctuation">,</span> params<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">"%.3f"</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>flops<span class="token punctuation">,</span> params<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="3-2-检测-x2F-分割脚本"><a href="#3-2-检测-x2F-分割脚本" class="headerlink" title="3.2 检测&#x2F;分割脚本"></a>3.2 检测&#x2F;分割脚本</h4><p>如作者在论文中阐述的，预训练的IAT作为弱光图像预处理然后进行检测&#x2F;分割的效果不好，联合训练的方式是IAT和检测&#x2F;分割模型都采用预训练的模型，然后再进行检测&#x2F;分割任务的二次训练，同步更新IAT与检测&#x2F;分割模型的参数。联合训练的具体添加方式如下：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">_<span class="token punctuation">,</span> _<span class="token punctuation">,</span> x <span class="token operator">=</span> IAT_model<span class="token punctuation">(</span>img<span class="token punctuation">)</span>x <span class="token operator">=</span> task_backbone<span class="token punctuation">(</span>x<span class="token punctuation">)</span>output <span class="token operator">=</span> task_head<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> Computer Vision </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Image Processing </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ROS实操_TF坐标变换</title>
      <link href="/2023/03/10/ros-shi-cao-tf-zuo-biao-bian-huan/"/>
      <url>/2023/03/10/ros-shi-cao-tf-zuo-biao-bian-huan/</url>
      
        <content type="html"><![CDATA[<p><strong>需求描述:</strong> </p><p>程序启动之初: 产生两只乌龟，中间的乌龟(A) 和 左下乌龟(B), B 会自动运行至A的位置，并且键盘控制时，只是控制 A 的运动，但是 B 可以跟随 A 运行。</p><p><strong>实现分析:</strong> </p><p>乌龟跟随实现的核心，是乌龟A和B都要发布相对世界坐标系的坐标信息，然后，订阅到该信息需要转换获取A相对于B坐标系的信息，最后，再生成速度信息，并控制B运动。</p><blockquote><ol><li>启动乌龟显示节点</li><li>在乌龟显示窗体中生成一只新的乌龟(需要使用服务)</li><li>编写两只乌龟发布坐标信息的节点</li><li>编写订阅节点订阅坐标信息并生成新的相对关系生成速度信息</li></ol></blockquote><p><strong>实现流程:</strong> C++ 与 Python 实现流程一致</p><blockquote><ol><li>新建功能包，添加依赖</li><li>编写服务客户端，用于生成一只新的乌龟</li><li>编写发布方，发布两只乌龟的坐标信息</li><li>编写订阅方，订阅两只乌龟信息，生成速度信息并发布</li><li>运行</li></ol></blockquote><p><strong>准备工作:</strong> </p><p>1.了解如何创建第二只乌龟，且不受键盘控制</p><p>创建第二只乌龟需要使用rosservice,话题使用的是 spawn</p><pre class="line-numbers language-none"><code class="language-none">rosservice call &#x2F;spawn &quot;x: 1.0y: 1.0theta: 1.0name: &#39;turtle_flow&#39;&quot; name: &quot;turtle_flow&quot;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>键盘是无法控制第二只乌龟运动的，因为使用的话题: &#x2F;第二只乌龟名称&#x2F;cmd_vel,对应的要控制乌龟运动必须发布对应的话题消息</p><p>2.了解如何获取两只乌龟的坐标</p><p>是通过话题 &#x2F;乌龟名称&#x2F;pose 来获取的</p><pre class="line-numbers language-none"><code class="language-none">x: 1.0 &#x2F;&#x2F;x坐标y: 1.0 &#x2F;&#x2F;y坐标theta: -1.21437060833 &#x2F;&#x2F;角度linear_velocity: 0.0 &#x2F;&#x2F;线速度angular_velocity: 1.0 &#x2F;&#x2F;角速度<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="1-创建功能包"><a href="#1-创建功能包" class="headerlink" title="1. 创建功能包"></a>1. 创建功能包</h3><p>创建项目功能包依赖于 tf2、tf2_ros、tf2_geometry_msgs、roscpp rospy std_msgs geometry_msgs、turtlesim</p><pre class="line-numbers language-none"><code class="language-none">catkin_create_pkg tflearn tf2 tf2_ros tf2_geometry_msgs roscpp rospy std_msgs geometry_msgs turtlesimcd tflearnmkdir scriptstouch tf_service.pytouch tf_publisher.pytouch tf_subscriber.py<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="2-服务客户端（生成乌龟）"><a href="#2-服务客户端（生成乌龟）" class="headerlink" title="2. 服务客户端（生成乌龟）"></a>2. 服务客户端（生成乌龟）</h3><p><code>tf_service.py</code></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#! /usr/bin/env python</span><span class="token comment"># coding=utf-8</span><span class="token triple-quoted-string string">"""      调用 service 服务在窗体指定位置生成一只乌龟    流程:        1.导包        2.初始化 ros 节点        3.创建服务客户端        4.等待服务启动        5.创建请求数据        6.发送请求并处理响应"""</span><span class="token comment">#1.导包</span><span class="token keyword">import</span> rospy<span class="token keyword">from</span> turtlesim<span class="token punctuation">.</span>srv <span class="token keyword">import</span> Spawn<span class="token punctuation">,</span> SpawnRequest<span class="token punctuation">,</span> SpawnResponse<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">"__main__"</span><span class="token punctuation">:</span>    <span class="token comment"># 2.初始化 ros 节点</span>    rospy<span class="token punctuation">.</span>init_node<span class="token punctuation">(</span><span class="token string">"turtle_spawn_p"</span><span class="token punctuation">)</span>    <span class="token comment"># 3.创建服务客户端</span>    client <span class="token operator">=</span> rospy<span class="token punctuation">.</span>ServiceProxy<span class="token punctuation">(</span><span class="token string">"/spawn"</span><span class="token punctuation">,</span>Spawn<span class="token punctuation">)</span>    <span class="token comment"># 4.等待服务启动</span>    client<span class="token punctuation">.</span>wait_for_service<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment"># 5.创建请求数据</span>    req <span class="token operator">=</span> SpawnRequest<span class="token punctuation">(</span><span class="token punctuation">)</span>    req<span class="token punctuation">.</span>x <span class="token operator">=</span> <span class="token number">1.0</span>    req<span class="token punctuation">.</span>y <span class="token operator">=</span> <span class="token number">1.0</span>    req<span class="token punctuation">.</span>theta <span class="token operator">=</span> <span class="token number">3.14</span>    req<span class="token punctuation">.</span>name <span class="token operator">=</span> <span class="token string">"turtle2"</span>    <span class="token comment"># 6.发送请求并处理响应</span>    <span class="token keyword">try</span><span class="token punctuation">:</span>        response <span class="token operator">=</span> client<span class="token punctuation">.</span>call<span class="token punctuation">(</span>req<span class="token punctuation">)</span>        rospy<span class="token punctuation">.</span>loginfo<span class="token punctuation">(</span><span class="token string">"乌龟创建成功，名字是:%s"</span><span class="token punctuation">,</span>response<span class="token punctuation">.</span>name<span class="token punctuation">)</span>    <span class="token keyword">except</span> Exception <span class="token keyword">as</span> e<span class="token punctuation">:</span>        rospy<span class="token punctuation">.</span>loginfo<span class="token punctuation">(</span><span class="token string">"服务调用失败...."</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="3-发布方（发布两只乌龟的坐标信息）"><a href="#3-发布方（发布两只乌龟的坐标信息）" class="headerlink" title="3. 发布方（发布两只乌龟的坐标信息）"></a>3. 发布方（发布两只乌龟的坐标信息）</h3><p><code>tf_publisher.py</code></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#! /usr/bin/env python</span><span class="token comment"># coding=utf-8</span><span class="token triple-quoted-string string">"""      该文件实现:需要订阅 turtle1 和 turtle2 的 pose，然后广播相对 world 的坐标系信息    注意: 订阅的两只 turtle,除了命名空间(turtle1 和 turtle2)不同外,          其他的话题名称和实现逻辑都是一样的，          所以我们可以将所需的命名空间通过 args 动态传入    实现流程:        1.导包        2.初始化 ros 节点        3.解析传入的命名空间        4.创建订阅对象        5.回调函数处理订阅的 pose 信息            5-1.创建 TF 广播器            5-2.将 pose 信息转换成 TransFormStamped            5-3.发布        6.spin"""</span><span class="token comment"># 1.导包</span><span class="token keyword">import</span> rospy<span class="token keyword">import</span> sys<span class="token keyword">from</span> turtlesim<span class="token punctuation">.</span>msg <span class="token keyword">import</span> Pose<span class="token keyword">from</span> geometry_msgs<span class="token punctuation">.</span>msg <span class="token keyword">import</span> TransformStamped<span class="token keyword">import</span> tf2_ros<span class="token keyword">import</span> tf_conversionsturtle_name <span class="token operator">=</span> <span class="token string">""</span><span class="token keyword">def</span> <span class="token function">doPose</span><span class="token punctuation">(</span>pose<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment"># rospy.loginfo("x = %.2f",pose.x)</span>    <span class="token comment">#1.创建坐标系广播器</span>    broadcaster <span class="token operator">=</span> tf2_ros<span class="token punctuation">.</span>TransformBroadcaster<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment">#2.将 pose 信息转换成 TransFormStamped</span>    tfs <span class="token operator">=</span> TransformStamped<span class="token punctuation">(</span><span class="token punctuation">)</span>    tfs<span class="token punctuation">.</span>header<span class="token punctuation">.</span>frame_id <span class="token operator">=</span> <span class="token string">"world"</span>    tfs<span class="token punctuation">.</span>header<span class="token punctuation">.</span>stamp <span class="token operator">=</span> rospy<span class="token punctuation">.</span>Time<span class="token punctuation">.</span>now<span class="token punctuation">(</span><span class="token punctuation">)</span>    tfs<span class="token punctuation">.</span>child_frame_id <span class="token operator">=</span> turtle_name    tfs<span class="token punctuation">.</span>transform<span class="token punctuation">.</span>translation<span class="token punctuation">.</span>x <span class="token operator">=</span> pose<span class="token punctuation">.</span>x    tfs<span class="token punctuation">.</span>transform<span class="token punctuation">.</span>translation<span class="token punctuation">.</span>y <span class="token operator">=</span> pose<span class="token punctuation">.</span>y    tfs<span class="token punctuation">.</span>transform<span class="token punctuation">.</span>translation<span class="token punctuation">.</span>z <span class="token operator">=</span> <span class="token number">0.0</span>    qtn <span class="token operator">=</span> tf_conversions<span class="token punctuation">.</span>transformations<span class="token punctuation">.</span>quaternion_from_euler<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> pose<span class="token punctuation">.</span>theta<span class="token punctuation">)</span>    tfs<span class="token punctuation">.</span>transform<span class="token punctuation">.</span>rotation<span class="token punctuation">.</span>x <span class="token operator">=</span> qtn<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>    tfs<span class="token punctuation">.</span>transform<span class="token punctuation">.</span>rotation<span class="token punctuation">.</span>y <span class="token operator">=</span> qtn<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>    tfs<span class="token punctuation">.</span>transform<span class="token punctuation">.</span>rotation<span class="token punctuation">.</span>z <span class="token operator">=</span> qtn<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span>    tfs<span class="token punctuation">.</span>transform<span class="token punctuation">.</span>rotation<span class="token punctuation">.</span>w <span class="token operator">=</span> qtn<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span>    <span class="token comment">#3.广播器发布 tfs</span>    broadcaster<span class="token punctuation">.</span>sendTransform<span class="token punctuation">(</span>tfs<span class="token punctuation">)</span><span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">"__main__"</span><span class="token punctuation">:</span>    <span class="token comment"># 2.初始化 ros 节点</span>    rospy<span class="token punctuation">.</span>init_node<span class="token punctuation">(</span><span class="token string">"sub_tfs_p"</span><span class="token punctuation">)</span>    <span class="token comment"># 3.解析传入的命名空间</span>    rospy<span class="token punctuation">.</span>loginfo<span class="token punctuation">(</span><span class="token string">"-------------------------------%d"</span><span class="token punctuation">,</span><span class="token builtin">len</span><span class="token punctuation">(</span>sys<span class="token punctuation">.</span>argv<span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>sys<span class="token punctuation">.</span>argv<span class="token punctuation">)</span> <span class="token operator">&lt;</span> <span class="token number">2</span><span class="token punctuation">:</span>        rospy<span class="token punctuation">.</span>loginfo<span class="token punctuation">(</span><span class="token string">"请传入参数:乌龟的命名空间"</span><span class="token punctuation">)</span>    <span class="token keyword">else</span><span class="token punctuation">:</span>        turtle_name <span class="token operator">=</span> sys<span class="token punctuation">.</span>argv<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>    rospy<span class="token punctuation">.</span>loginfo<span class="token punctuation">(</span><span class="token string">"///////////////////乌龟:%s"</span><span class="token punctuation">,</span>turtle_name<span class="token punctuation">)</span>    rospy<span class="token punctuation">.</span>Subscriber<span class="token punctuation">(</span>turtle_name <span class="token operator">+</span> <span class="token string">"/pose"</span><span class="token punctuation">,</span>Pose<span class="token punctuation">,</span>doPose<span class="token punctuation">)</span>    <span class="token comment">#     4.创建订阅对象</span>    <span class="token comment">#     5.回调函数处理订阅的 pose 信息</span>    <span class="token comment">#         5-1.创建 TF 广播器</span>    <span class="token comment">#         5-2.将 pose 信息转换成 TransFormStamped</span>    <span class="token comment">#         5-3.发布</span>    <span class="token comment">#     6.spin</span>    rospy<span class="token punctuation">.</span>spin<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="4-订阅方（解析坐标信息并生成速度信息）"><a href="#4-订阅方（解析坐标信息并生成速度信息）" class="headerlink" title="4. 订阅方（解析坐标信息并生成速度信息）"></a>4. 订阅方（解析坐标信息并生成速度信息）</h3><p><code>tf_subscriber.py</code></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#! /usr/bin/env python</span><span class="token comment"># coding=utf-8</span><span class="token triple-quoted-string string">"""      订阅 turtle1 和 turtle2 的 TF 广播信息，查找并转换时间最近的 TF 信息    将 turtle1 转换成相对 turtle2 的坐标，在计算线速度和角速度并发布    实现流程:        1.导包        2.初始化 ros 节点        3.创建 TF 订阅对象        4.处理订阅到的 TF            4-1.查找坐标系的相对关系            4-2.生成速度信息，然后发布"""</span><span class="token comment"># 1.导包</span><span class="token keyword">import</span> rospy<span class="token keyword">import</span> tf2_ros<span class="token keyword">from</span> geometry_msgs<span class="token punctuation">.</span>msg <span class="token keyword">import</span> TransformStamped<span class="token punctuation">,</span> Twist<span class="token keyword">import</span> math<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">"__main__"</span><span class="token punctuation">:</span>    <span class="token comment"># 2.初始化 ros 节点</span>    rospy<span class="token punctuation">.</span>init_node<span class="token punctuation">(</span><span class="token string">"sub_tfs_p"</span><span class="token punctuation">)</span>    <span class="token comment"># 3.创建 TF 订阅对象</span>    <span class="token builtin">buffer</span> <span class="token operator">=</span> tf2_ros<span class="token punctuation">.</span>Buffer<span class="token punctuation">(</span><span class="token punctuation">)</span>    listener <span class="token operator">=</span> tf2_ros<span class="token punctuation">.</span>TransformListener<span class="token punctuation">(</span><span class="token builtin">buffer</span><span class="token punctuation">)</span>    <span class="token comment"># 4.处理订阅到的 TF</span>    rate <span class="token operator">=</span> rospy<span class="token punctuation">.</span>Rate<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span>    <span class="token comment"># 创建速度发布对象</span>    pub <span class="token operator">=</span> rospy<span class="token punctuation">.</span>Publisher<span class="token punctuation">(</span><span class="token string">"/turtle2/cmd_vel"</span><span class="token punctuation">,</span>Twist<span class="token punctuation">,</span>queue_size<span class="token operator">=</span><span class="token number">1000</span><span class="token punctuation">)</span>    <span class="token keyword">while</span> <span class="token keyword">not</span> rospy<span class="token punctuation">.</span>is_shutdown<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        rate<span class="token punctuation">.</span>sleep<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">try</span><span class="token punctuation">:</span>            <span class="token comment">#def lookup_transform(self, target_frame, source_frame, time, timeout=rospy.Duration(0.0)):</span>            trans <span class="token operator">=</span> <span class="token builtin">buffer</span><span class="token punctuation">.</span>lookup_transform<span class="token punctuation">(</span><span class="token string">"turtle2"</span><span class="token punctuation">,</span><span class="token string">"turtle1"</span><span class="token punctuation">,</span>rospy<span class="token punctuation">.</span>Time<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>            <span class="token comment"># rospy.loginfo("相对坐标:(%.2f,%.2f,%.2f)",</span>            <span class="token comment">#             trans.transform.translation.x,</span>            <span class="token comment">#             trans.transform.translation.y,</span>            <span class="token comment">#             trans.transform.translation.z</span>            <span class="token comment">#             )   </span>            <span class="token comment"># 根据转变后的坐标计算出速度和角速度信息</span>            twist <span class="token operator">=</span> Twist<span class="token punctuation">(</span><span class="token punctuation">)</span>            <span class="token comment"># 间距 = x^2 + y^2  然后开方</span>            twist<span class="token punctuation">.</span>linear<span class="token punctuation">.</span>x <span class="token operator">=</span> <span class="token number">0.5</span> <span class="token operator">*</span> math<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>math<span class="token punctuation">.</span><span class="token builtin">pow</span><span class="token punctuation">(</span>trans<span class="token punctuation">.</span>transform<span class="token punctuation">.</span>translation<span class="token punctuation">.</span>x<span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span> <span class="token operator">+</span> math<span class="token punctuation">.</span><span class="token builtin">pow</span><span class="token punctuation">(</span>trans<span class="token punctuation">.</span>transform<span class="token punctuation">.</span>translation<span class="token punctuation">.</span>y<span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>            twist<span class="token punctuation">.</span>angular<span class="token punctuation">.</span>z <span class="token operator">=</span> <span class="token number">4</span> <span class="token operator">*</span> math<span class="token punctuation">.</span>atan2<span class="token punctuation">(</span>trans<span class="token punctuation">.</span>transform<span class="token punctuation">.</span>translation<span class="token punctuation">.</span>y<span class="token punctuation">,</span> trans<span class="token punctuation">.</span>transform<span class="token punctuation">.</span>translation<span class="token punctuation">.</span>x<span class="token punctuation">)</span>            pub<span class="token punctuation">.</span>publish<span class="token punctuation">(</span>twist<span class="token punctuation">)</span>        <span class="token keyword">except</span> Exception <span class="token keyword">as</span> e<span class="token punctuation">:</span>            rospy<span class="token punctuation">.</span>logwarn<span class="token punctuation">(</span><span class="token string">"警告:%s"</span><span class="token punctuation">,</span>e<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-none"><code class="language-none">chmod +x tf_service.pychmod +x tf_publisher.pychmod +x tf_subscriber.py<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>编辑<code>tflearn</code>下的<strong>CmakeLists.txt文件</strong></p><pre class="line-numbers language-none"><code class="language-none">catkin_install_python(PROGRAMS   scripts&#x2F;tf_service.py  scripts&#x2F;tf_publisher.py  scripts&#x2F;tf_subscriber.py  DESTINATION $&#123;CATKIN_PACKAGE_BIN_DESTINATION&#125;)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="5-运行"><a href="#5-运行" class="headerlink" title="5. 运行"></a>5. 运行</h3><p>使用 launch 文件组织需要运行的节点，内容示例如下:</p><pre class="line-numbers language-none"><code class="language-none">&lt;launch&gt;    &lt;node pkg&#x3D;&quot;turtlesim&quot; type&#x3D;&quot;turtlesim_node&quot; name&#x3D;&quot;turtle1&quot; output&#x3D;&quot;screen&quot; &#x2F;&gt;    &lt;node pkg&#x3D;&quot;turtlesim&quot; type&#x3D;&quot;turtle_teleop_key&quot; name&#x3D;&quot;key_control&quot; output&#x3D;&quot;screen&quot;&#x2F;&gt;    &lt;node pkg&#x3D;&quot;demo06_test_flow_p&quot; type&#x3D;&quot;test01_turtle_spawn_p.py&quot; name&#x3D;&quot;turtle_spawn&quot; output&#x3D;&quot;screen&quot;&#x2F;&gt;    &lt;node pkg&#x3D;&quot;demo06_test_flow_p&quot; type&#x3D;&quot;test02_turtle_tf_pub_p.py&quot; name&#x3D;&quot;tf_pub1&quot; args&#x3D;&quot;turtle1&quot; output&#x3D;&quot;screen&quot;&#x2F;&gt;    &lt;node pkg&#x3D;&quot;demo06_test_flow_p&quot; type&#x3D;&quot;test02_turtle_tf_pub_p.py&quot; name&#x3D;&quot;tf_pub2&quot; args&#x3D;&quot;turtle2&quot; output&#x3D;&quot;screen&quot;&#x2F;&gt;    &lt;node pkg&#x3D;&quot;demo06_test_flow_p&quot; type&#x3D;&quot;test03_turtle_tf_sub_p.py&quot; name&#x3D;&quot;tf_sub&quot; output&#x3D;&quot;screen&quot;&#x2F;&gt;&lt;&#x2F;launch&gt;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>工作空间下，编译并初始化环境变量</p><pre class="line-numbers language-none"><code class="language-none">catkin_makesource devel&#x2F;setup.bashroslaunch tflearn tf_learn.launch<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> Tutorial </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ROS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ROS节点运行管理launch文件</title>
      <link href="/2023/03/10/ros-jie-dian-yun-xing-guan-li-launch-wen-jian/"/>
      <url>/2023/03/10/ros-jie-dian-yun-xing-guan-li-launch-wen-jian/</url>
      
        <content type="html"><![CDATA[<blockquote><p>一个程序中可能需要启动多个节点，比如:ROS 内置的小乌龟案例，如果要控制乌龟运动，要启动多个窗口，分别启动 roscore、乌龟界面节点、键盘控制节点。如果每次都调用 rosrun 逐一启动，显然效率低下，如何优化?</p></blockquote><p>采用的优化策略便是使用roslaunch 命令集合 launch 文件启动管理节点，并且在后续教程中，也多次使用到了 launch 文件。</p><h3 id="1-概念"><a href="#1-概念" class="headerlink" title="1. 概念"></a>1. 概念</h3><p>launch 文件是一个 XML 格式的文件，可以启动本地和远程的多个节点，还可以在参数服务器中设置参数。</p><h3 id="2-作用"><a href="#2-作用" class="headerlink" title="2. 作用"></a>2. 作用</h3><p>简化节点的配置与启动，提高ROS程序的启动效率。</p><h3 id="3-使用"><a href="#3-使用" class="headerlink" title="3. 使用"></a>3. 使用</h3><p>以 turtlesim 为例演示</p><h4 id="3-1-新建launch文件"><a href="#3-1-新建launch文件" class="headerlink" title="3.1 新建launch文件"></a>3.1 新建launch文件</h4><p>在功能包下添加 launch目录, 目录下新建 xxxx.launch 文件，编辑 launch 文件</p><pre class="line-numbers language-none"><code class="language-none">&lt;launch&gt;    &lt;node pkg&#x3D;&quot;turtlesim&quot; type&#x3D;&quot;turtlesim_node&quot;     name&#x3D;&quot;myTurtle&quot; output&#x3D;&quot;screen&quot; &#x2F;&gt;    &lt;node pkg&#x3D;&quot;turtlesim&quot; type&#x3D;&quot;turtle_teleop_key&quot;  name&#x3D;&quot;myTurtleContro&quot; output&#x3D;&quot;screen&quot; &#x2F;&gt;&lt;&#x2F;launch&gt;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><h4 id="3-2-调用launch文件"><a href="#3-2-调用launch文件" class="headerlink" title="3.2 调用launch文件"></a>3.2 调用launch文件</h4><pre class="line-numbers language-none"><code class="language-none">roslaunch 包名 xxx.launch<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><strong>注意:</strong> roslaunch 命令执行launch文件时，首先会判断是否启动了 roscore,如果启动了，则不再启动，否则，会自动调用 roscore</p><p><strong>PS:</strong> 本节主要介绍launch文件的使用语法，launch 文件中的标签，以及不同标签的一些常用属性，可以参考<a href="http://wiki.ros.org/roslaunch/XML">ROS维基</a>。</p>]]></content>
      
      
      <categories>
          
          <category> Tutorial </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ROS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ROS实操_参数设置</title>
      <link href="/2023/03/10/ros-shi-cao-can-shu-she-zhi/"/>
      <url>/2023/03/10/ros-shi-cao-can-shu-she-zhi/</url>
      
        <content type="html"><![CDATA[<p><strong>需求描述:</strong>  修改turtlesim乌龟显示节点窗体的背景色，已知背景色是通过参数服务器的方式以 rgb 方式设置的。</p><p><strong>实现分析:</strong> </p><blockquote><ol><li>首先，需要启动乌龟显示节点。</li><li>要通过ROS命令，来获取参数服务器中设置背景色的参数。</li><li>编写参数设置节点，修改参数服务器中的参数值。</li></ol></blockquote><p><strong>实现流程:</strong> </p><blockquote><ol><li>通过ros命令获取参数。</li><li>编码实现服参数设置节点。</li><li>启动 roscore、turtlesim_node 与参数设置节点，查看运行结果。</li></ol></blockquote><h3 id="1-参数名获取"><a href="#1-参数名获取" class="headerlink" title="1. 参数名获取"></a>1. 参数名获取</h3><p><strong>获取参数列表:</strong> </p><pre class="line-numbers language-none"><code class="language-none">rosparam list<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><strong>响应结果:</strong> </p><pre class="line-numbers language-none"><code class="language-none">&#x2F;turtlesim&#x2F;background_b&#x2F;turtlesim&#x2F;background_g&#x2F;turtlesim&#x2F;background_r<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h3 id="2-参数修改"><a href="#2-参数修改" class="headerlink" title="2. 参数修改"></a>2. 参数修改</h3><p>本次案例在<code>ROS实操_话题发布</code>创建的<code>dotopic</code>功能包内进行，因此无需开展功能的包的创建等相关操作，只需在<code>scripts</code>目录内配置订阅节点相关的python文件即可</p><pre class="line-numbers language-none"><code class="language-none">touch set_topic.py<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#! /usr/bin/env python</span><span class="token comment"># coding=utf-8</span><span class="token keyword">import</span> rospy<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">"__main__"</span><span class="token punctuation">:</span>    rospy<span class="token punctuation">.</span>init_node<span class="token punctuation">(</span><span class="token string">"hehe"</span><span class="token punctuation">)</span>    <span class="token comment"># rospy.set_param("/turtlesim/background_r",255)</span>    <span class="token comment"># rospy.set_param("/turtlesim/background_g",255)</span>    <span class="token comment"># rospy.set_param("/turtlesim/background_b",255)</span>    rospy<span class="token punctuation">.</span>set_param<span class="token punctuation">(</span><span class="token string">"background_r"</span><span class="token punctuation">,</span><span class="token number">255</span><span class="token punctuation">)</span>    rospy<span class="token punctuation">.</span>set_param<span class="token punctuation">(</span><span class="token string">"background_g"</span><span class="token punctuation">,</span><span class="token number">255</span><span class="token punctuation">)</span>    rospy<span class="token punctuation">.</span>set_param<span class="token punctuation">(</span><span class="token string">"background_b"</span><span class="token punctuation">,</span><span class="token number">255</span><span class="token punctuation">)</span>  <span class="token comment"># 调用时，需要传入 __ns:=xxx</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-none"><code class="language-none">chmod +x set_topic.py<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>编辑<code>dotopic</code>下的<strong>CmakeLists.txt文件</strong> </p><pre class="line-numbers language-none"><code class="language-none">catkin_install_python(PROGRAMS   scripts&#x2F;pub_topic.py  scripts&#x2F;sub_topic.py  scripts&#x2F;service_topic.py  scripts&#x2F;set_topic.py  DESTINATION $&#123;CATKIN_PACKAGE_BIN_DESTINATION&#125;)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="3-运行"><a href="#3-运行" class="headerlink" title="3. 运行"></a>3. 运行</h3><p>工作空间下，编译并初始化环境变量</p><pre class="line-numbers language-none"><code class="language-none">catkin_makesource devel&#x2F;setup.bashroscorerosrun dotopic set_topic.pyrosrun turtlesim turtlesim_node<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>注意节点启动顺序，如果先启动乌龟显示节点，后启动背景色设置节点，那么颜色设置不会生效。</p><h3 id="4-其他设置方式"><a href="#4-其他设置方式" class="headerlink" title="4. 其他设置方式"></a>4. 其他设置方式</h3><p><strong>方式1:修改小乌龟节点的背景色(命令行实现)</strong> </p><pre class="line-numbers language-none"><code class="language-none">rosparam set &#x2F;turtlesim&#x2F;background_b 自定义数值rosparam set &#x2F;turtlesim&#x2F;background_g 自定义数值rosparam set &#x2F;turtlesim&#x2F;background_r 自定义数值<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>方式2:启动节点时，直接设置参数</strong> </p><pre class="line-numbers language-none"><code class="language-none">rosrun turtlesim turtlesim_node _background_r:&#x3D;100 _background_g&#x3D;0 _background_b&#x3D;0<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><strong>方式3:通过launch文件传参</strong> </p><pre class="line-numbers language-none"><code class="language-none">&lt;launch&gt;    &lt;node pkg&#x3D;&quot;turtlesim&quot; type&#x3D;&quot;turtlesim_node&quot; name&#x3D;&quot;set_bg&quot; output&#x3D;&quot;screen&quot;&gt;        &lt;!-- launch 传参策略1 --&gt;        &lt;!-- &lt;param name&#x3D;&quot;background_b&quot; value&#x3D;&quot;0&quot; type&#x3D;&quot;int&quot; &#x2F;&gt;        &lt;param name&#x3D;&quot;background_g&quot; value&#x3D;&quot;0&quot; type&#x3D;&quot;int&quot; &#x2F;&gt;        &lt;param name&#x3D;&quot;background_r&quot; value&#x3D;&quot;0&quot; type&#x3D;&quot;int&quot; &#x2F;&gt; --&gt;        &lt;!-- launch 传参策略2 --&gt;        &lt;rosparam command&#x3D;&quot;load&quot; file&#x3D;&quot;$(find demo03_test_parameter)&#x2F;cfg&#x2F;color.yaml&quot; &#x2F;&gt;    &lt;&#x2F;node&gt;&lt;&#x2F;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> Tutorial </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ROS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ROS实操_服务调用</title>
      <link href="/2023/03/10/ros-shi-cao-fu-wu-diao-yong/"/>
      <url>/2023/03/10/ros-shi-cao-fu-wu-diao-yong/</url>
      
        <content type="html"><![CDATA[<p><strong>需求描述:</strong> 编码实现向 turtlesim 发送请求，在乌龟显示节点的窗体指定位置生成一乌龟，这是一个服务请求操作。</p><p><strong>实现分析:</strong> </p><blockquote><ol><li>首先，需要启动乌龟显示节点。</li><li>要通过ROS命令，来获取乌龟生成服务的服务名称以及服务消息类型。</li><li>编写服务请求节点，生成新的乌龟。</li></ol></blockquote><p><strong>实现流程:</strong> </p><blockquote><ol><li>通过ros命令获取服务与服务消息信息。</li><li>编码实现服务请求节点。</li><li>启动 roscore、turtlesim_node 、乌龟生成节点，生成新的乌龟。</li></ol></blockquote><h3 id="1-服务名称与服务消息获取"><a href="#1-服务名称与服务消息获取" class="headerlink" title="1. 服务名称与服务消息获取"></a>1. 服务名称与服务消息获取</h3><p><strong>获取话题:</strong> &#x2F;spawn</p><pre class="line-numbers language-none"><code class="language-none">rosservice list<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><strong>获取消息类型:</strong> turtlesim&#x2F;Spawn</p><pre class="line-numbers language-none"><code class="language-none">rosservice type &#x2F;spawn<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><strong>获取消息格式:</strong> </p><pre class="line-numbers language-none"><code class="language-none">rossrv info turtlesim&#x2F;Spawn<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><strong>响应结果:</strong> </p><pre class="line-numbers language-none"><code class="language-none">float32 xfloat32 yfloat32 thetastring name---string name<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="2-服务客户端实现"><a href="#2-服务客户端实现" class="headerlink" title="2. 服务客户端实现"></a>2. 服务客户端实现</h3><p>本次案例在<code>ROS实操_话题发布</code>创建的<code>dotopic</code>功能包内进行，因此无需开展功能的包的创建等相关操作，只需在<code>scripts</code>目录内配置订阅节点相关的python文件即可。</p><pre class="line-numbers language-none"><code class="language-none">touch service_topic.py<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#! /usr/bin/env python</span><span class="token comment"># coding=utf-8</span><span class="token triple-quoted-string string">"""    生成一只小乌龟    准备工作:        1.服务话题 /spawn        2.服务消息类型 turtlesim/Spawn        3.运行前先启动 turtlesim_node 节点    实现流程:        1.导包          需要包含 turtlesim 包下资源，注意在 package.xml 配置        2.初始化 ros 节点        3.创建 service 客户端        4.等待服务启动        5.发送请求        6.处理响应"""</span><span class="token keyword">import</span> rospy<span class="token keyword">from</span> turtlesim<span class="token punctuation">.</span>srv <span class="token keyword">import</span> Spawn<span class="token punctuation">,</span>SpawnRequest<span class="token punctuation">,</span>SpawnResponse<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">"__main__"</span><span class="token punctuation">:</span>    <span class="token comment"># 2.初始化 ros 节点</span>    rospy<span class="token punctuation">.</span>init_node<span class="token punctuation">(</span><span class="token string">"set_turtle_p"</span><span class="token punctuation">)</span>    <span class="token comment"># 3.创建 service 客户端</span>    client <span class="token operator">=</span> rospy<span class="token punctuation">.</span>ServiceProxy<span class="token punctuation">(</span><span class="token string">"/spawn"</span><span class="token punctuation">,</span>Spawn<span class="token punctuation">)</span>    <span class="token comment"># 4.等待服务启动</span>    client<span class="token punctuation">.</span>wait_for_service<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment"># 5.发送请求</span>    req <span class="token operator">=</span> SpawnRequest<span class="token punctuation">(</span><span class="token punctuation">)</span>    req<span class="token punctuation">.</span>x <span class="token operator">=</span> <span class="token number">2.0</span>    req<span class="token punctuation">.</span>y <span class="token operator">=</span> <span class="token number">2.0</span>    req<span class="token punctuation">.</span>theta <span class="token operator">=</span> <span class="token operator">-</span><span class="token number">1.57</span>    req<span class="token punctuation">.</span>name <span class="token operator">=</span> <span class="token string">"my_turtle_p"</span>    <span class="token keyword">try</span><span class="token punctuation">:</span>        response <span class="token operator">=</span> client<span class="token punctuation">.</span>call<span class="token punctuation">(</span>req<span class="token punctuation">)</span>        <span class="token comment"># 6.处理响应</span>        rospy<span class="token punctuation">.</span>loginfo<span class="token punctuation">(</span><span class="token string">"乌龟创建成功!，叫:%s"</span><span class="token punctuation">,</span>response<span class="token punctuation">.</span>name<span class="token punctuation">)</span>    <span class="token keyword">except</span> expression <span class="token keyword">as</span> identifier<span class="token punctuation">:</span>        rospy<span class="token punctuation">.</span>loginfo<span class="token punctuation">(</span><span class="token string">"服务调用失败"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-none"><code class="language-none">chmod +x sub_topic.py<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>编辑<code>dotopic</code>下的<strong>CmakeLists.txt文件</strong> </p><pre class="line-numbers language-none"><code class="language-none">catkin_install_python(PROGRAMS   scripts&#x2F;pub_topic.py  scripts&#x2F;sub_topic.py  scripts&#x2F;service_topic.py  DESTINATION $&#123;CATKIN_PACKAGE_BIN_DESTINATION&#125;)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="3-运行"><a href="#3-运行" class="headerlink" title="3. 运行"></a>3. 运行</h3><p>工作空间下，编译并初始化环境变量</p><pre class="line-numbers language-none"><code class="language-none">catkin_makesource devel&#x2F;setup.bashroscorerosrun turtlesim turtlesim_noderosrun dotopic pub_topic.pyrosrun dotopic service_topic.py<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> Tutorial </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ROS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ROS实操_话题订阅</title>
      <link href="/2023/03/10/ros-shi-cao-hua-ti-ding-yue/"/>
      <url>/2023/03/10/ros-shi-cao-hua-ti-ding-yue/</url>
      
        <content type="html"><![CDATA[<p><strong>需求描述:</strong>  已知turtlesim中的乌龟显示节点，会发布当前乌龟的位姿(窗体中乌龟的坐标以及朝向)，要求控制乌龟运动，并时时打印当前乌龟的位姿。</p><p><strong>实现分析:</strong> </p><blockquote><ol><li>首先，需要启动乌龟显示以及运动控制节点并控制乌龟运动。</li><li>要通过ROS命令，来获取乌龟位姿发布的话题以及消息。</li><li>编写订阅节点，订阅并打印乌龟的位姿。</li></ol></blockquote><p><strong>实现流程:</strong> </p><blockquote><ol><li>通过ros命令获取话题与消息信息。</li><li>编码实现位姿获取节点。</li><li>启动 roscore、turtlesim_node 、控制节点以及位姿订阅节点，控制乌龟运动并输出乌龟的位姿。</li></ol></blockquote><h3 id="1-话题与消息获取"><a href="#1-话题与消息获取" class="headerlink" title="1. 话题与消息获取"></a>1. 话题与消息获取</h3><p><strong>获取话题:</strong> &#x2F;turtle1&#x2F;pose</p><pre class="line-numbers language-none"><code class="language-none">rostopic list<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><strong>获取消息类型:</strong> turtlesim&#x2F;Pose</p><pre class="line-numbers language-none"><code class="language-none">rostopic type  &#x2F;turtle1&#x2F;pose<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>**获取消息格式: **</p><pre class="line-numbers language-none"><code class="language-none">rosmsg info turtlesim&#x2F;Pose<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><strong>响应结果:</strong> </p><pre class="line-numbers language-none"><code class="language-none">float32 xfloat32 yfloat32 thetafloat32 linear_velocityfloat32 angular_velocity<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="2-实现订阅节点"><a href="#2-实现订阅节点" class="headerlink" title="2. 实现订阅节点"></a>2. 实现订阅节点</h3><p>本次案例在<code>ROS实操_话题发布</code>创建的<code>dotopic</code>功能包内进行，因此无需开展功能的包的创建等相关操作，只需在<code>scripts</code>目录内配置订阅节点相关的python文件即可。</p><pre class="line-numbers language-none"><code class="language-none">touch sub_topic.py<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#! /usr/bin/env python</span><span class="token comment"># coding=utf-8</span><span class="token triple-quoted-string string">"""    订阅小乌龟的位姿: 时时获取小乌龟在窗体中的坐标并打印    准备工作:        1.获取话题名称 /turtle1/pose        2.获取消息类型 turtlesim/Pose        3.运行前启动 turtlesim_node 与 turtle_teleop_key 节点    实现流程:        1.导包        2.初始化 ROS 节点        3.创建订阅者对象        4.回调函数处理订阅的数据        5.spin"""</span><span class="token keyword">import</span> rospy<span class="token keyword">from</span> turtlesim<span class="token punctuation">.</span>msg <span class="token keyword">import</span> Pose<span class="token keyword">def</span> <span class="token function">doPose</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token punctuation">:</span>    rospy<span class="token punctuation">.</span>loginfo<span class="token punctuation">(</span><span class="token string">"乌龟坐标:x=%.2f, y=%.2f,theta=%.2f"</span><span class="token punctuation">,</span>data<span class="token punctuation">.</span>x<span class="token punctuation">,</span>data<span class="token punctuation">.</span>y<span class="token punctuation">,</span>data<span class="token punctuation">.</span>theta<span class="token punctuation">)</span><span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">"__main__"</span><span class="token punctuation">:</span>    <span class="token comment"># 2.初始化 ROS 节点</span>    rospy<span class="token punctuation">.</span>init_node<span class="token punctuation">(</span><span class="token string">"sub_pose_p"</span><span class="token punctuation">)</span>    <span class="token comment"># 3.创建订阅者对象</span>    sub <span class="token operator">=</span> rospy<span class="token punctuation">.</span>Subscriber<span class="token punctuation">(</span><span class="token string">"/turtle1/pose"</span><span class="token punctuation">,</span>Pose<span class="token punctuation">,</span>doPose<span class="token punctuation">,</span>queue_size<span class="token operator">=</span><span class="token number">1000</span><span class="token punctuation">)</span>    <span class="token comment">#     4.回调函数处理订阅的数据</span>    <span class="token comment">#     5.spin</span>    rospy<span class="token punctuation">.</span>spin<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-none"><code class="language-none">chmod +x sub_topic.py<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>编辑<code>dotopic</code>下的<strong>CmakeLists.txt文件</strong></p><pre class="line-numbers language-none"><code class="language-none">catkin_install_python(PROGRAMS   scripts&#x2F;pub_topic.py  scripts&#x2F;sub_topic.py  DESTINATION $&#123;CATKIN_PACKAGE_BIN_DESTINATION&#125;)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="3-运行"><a href="#3-运行" class="headerlink" title="3. 运行"></a>3. 运行</h3><p>工作空间下，编译并初始化环境变量</p><pre class="line-numbers language-none"><code class="language-none">catkin_makesource devel&#x2F;setup.bashroscorerosrun turtlesim turtlesim_noderosrun dotopic sub_topic.pyrosrun dotopic pub_topic.py<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> Tutorial </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ROS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ROS实操_话题发布</title>
      <link href="/2023/03/10/ros-shi-cao-hua-ti-fa-bu/"/>
      <url>/2023/03/10/ros-shi-cao-hua-ti-fa-bu/</url>
      
        <content type="html"><![CDATA[<p><strong>需求描述:</strong> 编码实现乌龟运动控制，让小乌龟做圆周运动。</p><p><strong>实现分析:</strong> </p><blockquote><ol><li>乌龟运动控制实现，关键节点有两个，一个是乌龟运动显示节点 turtlesim_node，另一个是控制节点，二者是订阅发布模式实现通信的，乌龟运动显示节点直接调用即可，运动控制节点之前是使用的 turtle_teleop_key通过键盘 控制，现在需要自定义控制节点。</li><li>控制节点自实现时，首先需要了解控制节点与显示节点通信使用的话题与消息，可以使用ros命令结合计算图来获取。</li><li>了解了话题与消息之后，通过 C++ 或 Python 编写运动控制节点，通过指定的话题，按照一定的逻辑发布消息即可。</li></ol></blockquote><p><strong>实现流程:</strong> </p><blockquote><ol><li>通过计算图结合ros命令获取话题与消息信息。</li><li>编码实现运动控制节点。</li><li>启动 roscore、turtlesim_node 以及自定义的控制节点，查看运行结果。</li></ol></blockquote><h3 id="1-话题与消息获取"><a href="#1-话题与消息获取" class="headerlink" title="1. 话题与消息获取"></a>1. 话题与消息获取</h3><p><strong>准备:</strong>  先启动键盘控制乌龟运动案例。</p><h4 id="1-1-话题获取"><a href="#1-1-话题获取" class="headerlink" title="1.1 话题获取"></a>1.1 话题获取</h4><p><strong>获取话题:</strong> &#x2F;turtle1&#x2F;cmd_vel</p><p>通过 rostopic 列出话题:</p><pre class="line-numbers language-none"><code class="language-none">rostopic list<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="1-2-消息获取"><a href="#1-2-消息获取" class="headerlink" title="1.2 消息获取"></a>1.2 消息获取</h4><p><strong>获取消息类型:</strong> geometry_msgs&#x2F;Twist</p><pre class="line-numbers language-none"><code class="language-none">rostopic type &#x2F;turtle1&#x2F;cmd_vel<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><strong>获取消息格式:</strong> </p><pre class="line-numbers language-none"><code class="language-none">rosmsg info geometry_msgs&#x2F;Twist<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><strong>响应结果:</strong> </p><pre class="line-numbers language-none"><code class="language-none">geometry_msgs&#x2F;Vector3 linear  float64 x  float64 y  float64 zgeometry_msgs&#x2F;Vector3 angular  float64 x  float64 y  float64 z<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>linear(线速度) 下的xyz分别对应在x、y和z方向上的速度(单位是 m&#x2F;s)；</p><p>angular(角速度)下的xyz分别对应x轴上的翻滚、y轴上俯仰和z轴上偏航的速度(单位是rad&#x2F;s)。</p><h3 id="2-实现发布节点"><a href="#2-实现发布节点" class="headerlink" title="2. 实现发布节点"></a>2. 实现发布节点</h3><p>创建功能包需要依赖的功能包: roscpp rospy std_msgs geometry_msgs</p><pre class="line-numbers language-none"><code class="language-none">carkin_create_pkg dotopic rospy std_msgs geometry_msgscd dotopicmkdir scriptscd scriptstouch pub_topic.py<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#! /usr/bin/env python</span><span class="token triple-quoted-string string">"""    编写 ROS 节点，控制小乌龟画圆    准备工作:        1.获取topic(已知: /turtle1/cmd_vel)        2.获取消息类型(已知: geometry_msgs/Twist)        3.运行前，注意先启动 turtlesim_node 节点    实现流程:        1.导包        2.初始化 ROS 节点        3.创建发布者对象        4.循环发布运动控制消息"""</span><span class="token keyword">import</span> rospy<span class="token keyword">from</span> geometry_msgs<span class="token punctuation">.</span>msg <span class="token keyword">import</span> Twist<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">"__main__"</span><span class="token punctuation">:</span>    <span class="token comment"># 2.初始化 ROS 节点</span>    rospy<span class="token punctuation">.</span>init_node<span class="token punctuation">(</span><span class="token string">"control_circle_p"</span><span class="token punctuation">)</span>    <span class="token comment"># 3.创建发布者对象</span>    pub <span class="token operator">=</span> rospy<span class="token punctuation">.</span>Publisher<span class="token punctuation">(</span><span class="token string">"/turtle1/cmd_vel"</span><span class="token punctuation">,</span>Twist<span class="token punctuation">,</span>queue_size<span class="token operator">=</span><span class="token number">1000</span><span class="token punctuation">)</span>    <span class="token comment"># 4.循环发布运动控制消息</span>    rate <span class="token operator">=</span> rospy<span class="token punctuation">.</span>Rate<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span>    msg <span class="token operator">=</span> Twist<span class="token punctuation">(</span><span class="token punctuation">)</span>    msg<span class="token punctuation">.</span>linear<span class="token punctuation">.</span>x <span class="token operator">=</span> <span class="token number">1.0</span>    msg<span class="token punctuation">.</span>linear<span class="token punctuation">.</span>y <span class="token operator">=</span> <span class="token number">0.0</span>    msg<span class="token punctuation">.</span>linear<span class="token punctuation">.</span>z <span class="token operator">=</span> <span class="token number">0.0</span>    msg<span class="token punctuation">.</span>angular<span class="token punctuation">.</span>x <span class="token operator">=</span> <span class="token number">0.0</span>    msg<span class="token punctuation">.</span>angular<span class="token punctuation">.</span>y <span class="token operator">=</span> <span class="token number">0.0</span>    msg<span class="token punctuation">.</span>angular<span class="token punctuation">.</span>z <span class="token operator">=</span> <span class="token number">0.5</span>    <span class="token keyword">while</span> <span class="token keyword">not</span> rospy<span class="token punctuation">.</span>is_shutdown<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        pub<span class="token punctuation">.</span>publish<span class="token punctuation">(</span>msg<span class="token punctuation">)</span>        rate<span class="token punctuation">.</span>sleep<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-none"><code class="language-none">chmod +x pub_topic.py<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>编辑<code>**dotopic**</code>下的<strong>CmakeLists.txt文件</strong></p><pre class="line-numbers language-none"><code class="language-none">catkin_install_python(PROGRAMS   scripts&#x2F;pub_topic.py  DESTINATION $&#123;CATKIN_PACKAGE_BIN_DESTINATION&#125;)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><h3 id="3-运行"><a href="#3-运行" class="headerlink" title="3. 运行"></a>3. 运行</h3><p>工作空间下，编译并初始化环境变量</p><pre class="line-numbers language-none"><code class="language-none">catkin_makesource devel&#x2F;setup.bashroscorerosrun turtlesim turtlesim_noderosrun dotopic pub_topic.py<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> Tutorial </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ROS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ROS常用命令</title>
      <link href="/2023/03/10/ros-chang-yong-ming-ling/"/>
      <url>/2023/03/10/ros-chang-yong-ming-ling/</url>
      
        <content type="html"><![CDATA[<p>机器人系统中启动的节点少则几个，多则十几个、几十个，不同的节点名称各异，通信时使用话题、服务、消息、参数等等都各不相同，一个显而易见的问题是: 当需要自定义节点和其他某个已经存在的节点通信时，如何获取对方的话题、以及消息载体的格式呢？</p><p>在 ROS 同提供了一些实用的命令行工具，可以用于获取不同节点的各类信息，常用的命令如下:</p><blockquote><ul><li>rosnode : 操作节点</li><li>rostopic : 操作话题</li><li>rosservice : 操作服务</li><li>rosmsg : 操作msg消息</li><li>rossrv : 操作srv消息</li><li>rosparam : 操作参数</li></ul></blockquote><p><strong>作用：</strong> 和之前介绍的文件系统操作命令比较，文件操作命令是静态的，操作的是磁盘上的文件，而上述命令是动态的，在ROS程序启动后，可以动态的获取运行中的节点或参数的相关信息。</p><h3 id="1-rosnode"><a href="#1-rosnode" class="headerlink" title="1. rosnode"></a>1. rosnode</h3><p>rosnode 是用于获取节点信息的命令</p><pre class="line-numbers language-none"><code class="language-none">rosnode ping    测试到节点的连接状态rosnode list    列出活动节点rosnode info    打印节点信息rosnode machine    列出指定设备上节点rosnode kill    杀死某个节点rosnode cleanup    清除不可连接的节点， 例：启动乌龟节点，然后 ctrl + c 关闭，该节点并没被彻底清除，可用 cleanup 清除节点<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="2-rostopic"><a href="#2-rostopic" class="headerlink" title="2. rostopic"></a>2. rostopic</h3><p><strong>rostopic</strong>包含rostopic命令行工具，用于显示有关ROS 主题的调试信息，包括发布者，订阅者，发布频率和ROS消息。它还包含一个实验性Python库，用于动态获取有关主题的信息并与之交互。</p><pre class="line-numbers language-none"><code class="language-none">rostopic bw     显示主题使用的带宽rostopic delay  显示带有 header 的主题延迟rostopic echo   打印消息到屏幕rostopic find   根据类型查找主题rostopic hz     显示主题的发布频率rostopic info   显示主题相关信息rostopic list   显示所有活动状态下的主题rostopic pub    将数据发布到主题rostopic type   打印主题类型<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ul><li><strong>rostopic list</strong>(-v)</li></ul><p>直接调用即可，控制台将打印当前运行状态下的主题名称</p><p>rostopic list -v : 获取话题详情(比如列出：发布者和订阅者个数…</p><ul><li><strong>rostopic pub</strong></li></ul><p>可以直接调用命令向订阅者发布消息</p><p>为roboware 自动生成的 发布&#x2F;订阅 模型案例中的 订阅者 发布一条字符串</p><pre class="line-numbers language-none"><code class="language-none">rostopic pub &#x2F;主题名称 消息类型 消息内容rostopic pub &#x2F;chatter std_msgs gagaxixi<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>为 小乌龟案例的 订阅者 发布一条运动信息</p><pre class="line-numbers language-none"><code class="language-none">rostopic pub &#x2F;turtle1&#x2F;cmd_vel geometry_msgs&#x2F;Twist &quot;linear:  x: 1.0  y: 0.0  z: 0.0angular:  x: 0.0  y: 0.0  z: 2.0&quot;&#x2F;&#x2F;只发布一次运动信息rostopic pub -r 10 &#x2F;turtle1&#x2F;cmd_vel geometry_msgs&#x2F;Twist &quot;linear:  x: 1.0  y: 0.0  z: 0.0angular:  x: 0.0  y: 0.0  z: 2.0&quot;&#x2F;&#x2F; 以 10HZ 的频率循环发送运动信息<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="3-rosmsg"><a href="#3-rosmsg" class="headerlink" title="3. rosmsg"></a>3. rosmsg</h3><p>rosmsg是用于显示有关 ROS消息类型的 信息的命令行工具。</p><pre class="line-numbers language-none"><code class="language-none">rosmsg show    显示消息描述rosmsg info    显示消息信息rosmsg list    列出所有消息rosmsg md5    显示 md5 加密后的消息rosmsg package    显示某个功能包下的所有消息rosmsg packages    列出包含消息的功能包<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ul><li><strong>rosmsg package</strong></li></ul><p>列出某个包下的所有msg</p><pre class="line-numbers language-none"><code class="language-none">&#x2F;&#x2F;rosmsg package 包名 rosmsg package turtlesim<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><ul><li><strong>rosmsg show</strong></li></ul><p>显示消息描述</p><pre class="line-numbers language-none"><code class="language-none">&#x2F;&#x2F;rosmsg show 消息名称rosmsg show turtlesim&#x2F;Pose结果:float32 xfloat32 yfloat32 thetafloat32 linear_velocityfloat32 angular_velocity<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="4-rosservice"><a href="#4-rosservice" class="headerlink" title="4. rosservice"></a>4. rosservice</h3><p>rosservice包含用于列出和查询ROS<a href="http://wiki.ros.org/Services">Services</a>的rosservice命令行工具。</p><p>调用部分服务时，如果对相关工作空间没有配置 path，需要进入工作空间调用 source .&#x2F;devel&#x2F;setup.bash</p><pre class="line-numbers language-none"><code class="language-none">rosservice args 打印服务参数rosservice call    使用提供的参数调用服务rosservice find    按照服务类型查找服务rosservice info    打印有关服务的信息rosservice list    列出所有活动的服务rosservice type    打印服务类型rosservice uri    打印服务的 ROSRPC uri<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ul><li><strong>rosservice list</strong></li></ul><p>列出所有活动的 service</p><pre class="line-numbers language-none"><code class="language-none">~ rosservice list&#x2F;clear&#x2F;kill&#x2F;listener&#x2F;get_loggers&#x2F;listener&#x2F;set_logger_level&#x2F;reset&#x2F;rosout&#x2F;get_loggers&#x2F;rosout&#x2F;set_logger_level&#x2F;rostopic_4985_1578723066421&#x2F;get_loggers&#x2F;rostopic_4985_1578723066421&#x2F;set_logger_level&#x2F;rostopic_5582_1578724343069&#x2F;get_loggers&#x2F;rostopic_5582_1578724343069&#x2F;set_logger_level&#x2F;spawn&#x2F;turtle1&#x2F;set_pen&#x2F;turtle1&#x2F;teleport_absolute&#x2F;turtle1&#x2F;teleport_relative&#x2F;turtlesim&#x2F;get_loggers&#x2F;turtlesim&#x2F;set_logger_level<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ul><li><strong>rosservice args</strong></li></ul><p>打印服务参数</p><pre class="line-numbers language-none"><code class="language-none">rosservice args &#x2F;spawnx y theta name<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><ul><li><strong>rosservice call</strong></li></ul><p>调用服务</p><p>为小乌龟的案例生成一只新的乌龟</p><pre class="line-numbers language-none"><code class="language-none">rosservice call &#x2F;spawn &quot;x: 1.0y: 2.0theta: 0.0name: &#39;xxx&#39;&quot;name: &quot;xxx&quot;&#x2F;&#x2F;生成一只叫 xxx 的乌龟<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="5-rossrv"><a href="#5-rossrv" class="headerlink" title="5. rossrv"></a>5. rossrv</h3><p>rossrv是用于显示有关ROS服务类型的信息的命令行工具，与 rosmsg 使用语法高度雷同。</p><pre class="line-numbers language-none"><code class="language-none">rossrv show    显示服务消息详情rossrv info    显示服务消息相关信息rossrv list    列出所有服务信息rossrv md5    显示 md5 加密后的服务消息rossrv package    显示某个包下所有服务消息rossrv packages    显示包含服务消息的所有包<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="6-rosparam"><a href="#6-rosparam" class="headerlink" title="6. rosparam"></a>6. rosparam</h3><p>rosparam包含rosparam命令行工具，用于使用YAML编码文件在参数服务器上获取和设置ROS参数。</p><pre class="line-numbers language-none"><code class="language-none">rosparam set    设置参数rosparam get    获取参数rosparam load    从外部文件加载参数rosparam dump    将参数写出到外部文件rosparam delete    删除参数rosparam list    列出所有参数<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ul><li><strong>rosparam list</strong></li></ul><p>列出所有参数</p><pre class="line-numbers language-none"><code class="language-none">rosparam list&#x2F;&#x2F;默认结果&#x2F;rosdistro&#x2F;roslaunch&#x2F;uris&#x2F;host_helloros_virtual_machine__42911&#x2F;rosversion&#x2F;run_id<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ul><li><strong>rosparam set</strong></li></ul><p>设置参数</p><pre class="line-numbers language-none"><code class="language-none">rosparam set name huluwa&#x2F;&#x2F;再次调用 rosparam list 结果&#x2F;name&#x2F;rosdistro&#x2F;roslaunch&#x2F;uris&#x2F;host_helloros_virtual_machine__42911&#x2F;rosversion&#x2F;run_id<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ul><li><strong>rosparam get</strong></li></ul><p>获取参数</p><pre class="line-numbers language-none"><code class="language-none">rosparam get name&#x2F;&#x2F;结果huluwa<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><ul><li><strong>rosparam delete</strong></li></ul><p>删除参数</p><pre class="line-numbers language-none"><code class="language-none">rosparam delete name&#x2F;&#x2F;结果&#x2F;&#x2F;去除了name<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><ul><li><strong>rosparam load(先准备 yaml 文件)</strong></li></ul><p>从外部文件加载参数</p><pre class="line-numbers language-none"><code class="language-none">rosparam load xxx.yaml<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ul><li><strong>rosparam dump</strong></li></ul><p>将参数写出到外部文件</p><pre class="line-numbers language-none"><code class="language-none">rosparam dump yyy.yaml<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> Tutorial </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ROS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ROS参数服务器</title>
      <link href="/2023/03/10/ros-can-shu-fu-wu-qi/"/>
      <url>/2023/03/10/ros-can-shu-fu-wu-qi/</url>
      
        <content type="html"><![CDATA[<h3 id="1-参数服务器"><a href="#1-参数服务器" class="headerlink" title="1. 参数服务器"></a>1. 参数服务器</h3><p>参数服务器在ROS中主要用于实现不同节点之间的数据共享。参数服务器相当于是独立于所有节点的一个公共容器，可以将数据存储在该容器中，被不同的节点调用，当然不同的节点也可以往其中存储数据，关于参数服务器的典型应用场景如下:</p><blockquote><p>导航实现时，会进行路径规划，比如: 全局路径规划，设计一个从出发点到目标点的大致路径。本地路径规划，会根据当前路况生成时时的行进路径</p></blockquote><p>上述场景中，全局路径规划和本地路径规划时，就会使用到参数服务器：路径规划时，需要参考小车的尺寸，我们可以将这些尺寸信息存储到参数服务器，全局路径规划节点与本地路径规划节点都可以从参数服务器中调用这些参数。</p><blockquote><p>参数服务器，一般适用于存在数据共享的一些应用场景。</p><p><strong>注意:</strong> 参数服务器不是为高性能而设计的，因此最好用于存储静态的非二进制的简单数据。</p></blockquote><p>参数可使用数据类型:</p><blockquote><ul><li>32-bit integers</li><li>booleans</li><li>strings</li><li>doubles</li><li>iso8601 dates</li><li>lists</li><li>base64-encoded binary data</li><li>字典</li></ul></blockquote><h3 id="2-创建并使用参数服务器"><a href="#2-创建并使用参数服务器" class="headerlink" title="2. 创建并使用参数服务器"></a>2. 创建并使用参数服务器</h3><p><strong>需求:</strong> 实现参数服务器参数的增删改查操作。</p><p>预先准备好ROS工作空间，具体的操作可以参考另外一篇博客笔记，<a href="https://kolbey.github.io/2023/03/09/ros-chuang-jian-xiang-mu-liu-cheng/">ROS创建项目流程</a>。具体的操作流程如下：</p><blockquote><ul><li>创建工作空间；</li><li>进入src创建ROS包并添加依赖；</li><li>进入ROS包添加scripts目录并编辑下列python文件</li><li>为python文件添加可执行权限</li><li>在ROS包下的CMakeLists.txt中添加<code>**catkin_install_python**</code>内的<code>**scripts/自定义文件名.py**</code>;</li><li>在工作环境目录下进行编译<code>**catkin_make**</code>；</li><li>在新建的terminal内初始化环境变量<code>**source devel/setup.bash**</code>；</li><li>启动<code>roscore</code>，启动脚本<code>**rosrun ros包名称 自定义文件名.py**</code>。</li></ul></blockquote><h4 id="2-1-参数服务器新增（修改）参数"><a href="#2-1-参数服务器新增（修改）参数" class="headerlink" title="2.1 参数服务器新增（修改）参数"></a>2.1 参数服务器新增（修改）参数</h4><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#! /usr/bin/env python</span><span class="token triple-quoted-string string">"""    参数服务器操作之新增与修改(二者API一样)_Python实现:"""</span><span class="token keyword">import</span> rospy<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">"__main__"</span><span class="token punctuation">:</span>    rospy<span class="token punctuation">.</span>init_node<span class="token punctuation">(</span><span class="token string">"set_update_paramter_p"</span><span class="token punctuation">)</span>    <span class="token comment"># 设置各种类型参数</span>    rospy<span class="token punctuation">.</span>set_param<span class="token punctuation">(</span><span class="token string">"p_int"</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">)</span>    rospy<span class="token punctuation">.</span>set_param<span class="token punctuation">(</span><span class="token string">"p_double"</span><span class="token punctuation">,</span><span class="token number">3.14</span><span class="token punctuation">)</span>    rospy<span class="token punctuation">.</span>set_param<span class="token punctuation">(</span><span class="token string">"p_bool"</span><span class="token punctuation">,</span><span class="token boolean">True</span><span class="token punctuation">)</span>    rospy<span class="token punctuation">.</span>set_param<span class="token punctuation">(</span><span class="token string">"p_string"</span><span class="token punctuation">,</span><span class="token string">"hello python"</span><span class="token punctuation">)</span>    rospy<span class="token punctuation">.</span>set_param<span class="token punctuation">(</span><span class="token string">"p_list"</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token string">"hello"</span><span class="token punctuation">,</span><span class="token string">"haha"</span><span class="token punctuation">,</span><span class="token string">"xixi"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    rospy<span class="token punctuation">.</span>set_param<span class="token punctuation">(</span><span class="token string">"p_dict"</span><span class="token punctuation">,</span><span class="token punctuation">&#123;</span><span class="token string">"name"</span><span class="token punctuation">:</span><span class="token string">"hulu"</span><span class="token punctuation">,</span><span class="token string">"age"</span><span class="token punctuation">:</span><span class="token number">8</span><span class="token punctuation">&#125;</span><span class="token punctuation">)</span>    <span class="token comment"># 修改</span>    rospy<span class="token punctuation">.</span>set_param<span class="token punctuation">(</span><span class="token string">"p_int"</span><span class="token punctuation">,</span><span class="token number">100</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="2-2-参数服务器获取参数"><a href="#2-2-参数服务器获取参数" class="headerlink" title="2.2 参数服务器获取参数"></a>2.2 参数服务器获取参数</h4><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#! /usr/bin/env python</span><span class="token triple-quoted-string string">"""    参数服务器操作之查询_Python实现:            get_param(键,默认值)            当键存在时，返回对应的值，如果不存在返回默认值        get_param_cached        get_param_names        has_param        search_param"""</span><span class="token keyword">import</span> rospy<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">"__main__"</span><span class="token punctuation">:</span>    rospy<span class="token punctuation">.</span>init_node<span class="token punctuation">(</span><span class="token string">"get_param_p"</span><span class="token punctuation">)</span>    <span class="token comment">#获取参数</span>    int_value <span class="token operator">=</span> rospy<span class="token punctuation">.</span>get_param<span class="token punctuation">(</span><span class="token string">"p_int"</span><span class="token punctuation">,</span><span class="token number">10000</span><span class="token punctuation">)</span>    double_value <span class="token operator">=</span> rospy<span class="token punctuation">.</span>get_param<span class="token punctuation">(</span><span class="token string">"p_double"</span><span class="token punctuation">)</span>    bool_value <span class="token operator">=</span> rospy<span class="token punctuation">.</span>get_param<span class="token punctuation">(</span><span class="token string">"p_bool"</span><span class="token punctuation">)</span>    string_value <span class="token operator">=</span> rospy<span class="token punctuation">.</span>get_param<span class="token punctuation">(</span><span class="token string">"p_string"</span><span class="token punctuation">)</span>    p_list <span class="token operator">=</span> rospy<span class="token punctuation">.</span>get_param<span class="token punctuation">(</span><span class="token string">"p_list"</span><span class="token punctuation">)</span>    p_dict <span class="token operator">=</span> rospy<span class="token punctuation">.</span>get_param<span class="token punctuation">(</span><span class="token string">"p_dict"</span><span class="token punctuation">)</span>    rospy<span class="token punctuation">.</span>loginfo<span class="token punctuation">(</span><span class="token string">"获取的数据:%d,%.2f,%d,%s"</span><span class="token punctuation">,</span>                int_value<span class="token punctuation">,</span>                double_value<span class="token punctuation">,</span>                bool_value<span class="token punctuation">,</span>                string_value<span class="token punctuation">)</span>    <span class="token keyword">for</span> ele <span class="token keyword">in</span> p_list<span class="token punctuation">:</span>        rospy<span class="token punctuation">.</span>loginfo<span class="token punctuation">(</span><span class="token string">"ele = %s"</span><span class="token punctuation">,</span> ele<span class="token punctuation">)</span>    rospy<span class="token punctuation">.</span>loginfo<span class="token punctuation">(</span><span class="token string">"name = %s, age = %d"</span><span class="token punctuation">,</span>p_dict<span class="token punctuation">[</span><span class="token string">"name"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>p_dict<span class="token punctuation">[</span><span class="token string">"age"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    <span class="token comment"># get_param_cached</span>    int_cached <span class="token operator">=</span> rospy<span class="token punctuation">.</span>get_param_cached<span class="token punctuation">(</span><span class="token string">"p_int"</span><span class="token punctuation">)</span>    rospy<span class="token punctuation">.</span>loginfo<span class="token punctuation">(</span><span class="token string">"缓存数据:%d"</span><span class="token punctuation">,</span>int_cached<span class="token punctuation">)</span>    <span class="token comment"># get_param_names</span>    names <span class="token operator">=</span> rospy<span class="token punctuation">.</span>get_param_names<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">for</span> name <span class="token keyword">in</span> names<span class="token punctuation">:</span>        rospy<span class="token punctuation">.</span>loginfo<span class="token punctuation">(</span><span class="token string">"name = %s"</span><span class="token punctuation">,</span>name<span class="token punctuation">)</span>    rospy<span class="token punctuation">.</span>loginfo<span class="token punctuation">(</span><span class="token string">"-"</span><span class="token operator">*</span><span class="token number">80</span><span class="token punctuation">)</span>    <span class="token comment"># has_param</span>    flag <span class="token operator">=</span> rospy<span class="token punctuation">.</span>has_param<span class="token punctuation">(</span><span class="token string">"p_int"</span><span class="token punctuation">)</span>    rospy<span class="token punctuation">.</span>loginfo<span class="token punctuation">(</span><span class="token string">"包含p_int吗？%d"</span><span class="token punctuation">,</span>flag<span class="token punctuation">)</span>    <span class="token comment"># search_param</span>    key <span class="token operator">=</span> rospy<span class="token punctuation">.</span>search_param<span class="token punctuation">(</span><span class="token string">"p_int"</span><span class="token punctuation">)</span>    rospy<span class="token punctuation">.</span>loginfo<span class="token punctuation">(</span><span class="token string">"搜索的键 = %s"</span><span class="token punctuation">,</span>key<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="2-3-参数服务器删除参数"><a href="#2-3-参数服务器删除参数" class="headerlink" title="2.3 参数服务器删除参数"></a>2.3 参数服务器删除参数</h4><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#! /usr/bin/env python</span><span class="token triple-quoted-string string">"""    参数服务器操作之删除_Python实现:    rospy.delete_param("键")    键存在时，可以删除成功，键不存在时，会抛出异常"""</span><span class="token keyword">import</span> rospy<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">"__main__"</span><span class="token punctuation">:</span>    rospy<span class="token punctuation">.</span>init_node<span class="token punctuation">(</span><span class="token string">"delete_param_p"</span><span class="token punctuation">)</span>    <span class="token keyword">try</span><span class="token punctuation">:</span>        rospy<span class="token punctuation">.</span>delete_param<span class="token punctuation">(</span><span class="token string">"p_int"</span><span class="token punctuation">)</span>    <span class="token keyword">except</span> Exception <span class="token keyword">as</span> e<span class="token punctuation">:</span>        rospy<span class="token punctuation">.</span>loginfo<span class="token punctuation">(</span><span class="token string">"删除失败"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> Tutorial </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ROS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ROS服务通信</title>
      <link href="/2023/03/10/ros-fu-wu-tong-xin/"/>
      <url>/2023/03/10/ros-fu-wu-tong-xin/</url>
      
        <content type="html"><![CDATA[<h3 id="1-服务通信自定义srv"><a href="#1-服务通信自定义srv" class="headerlink" title="1. 服务通信自定义srv"></a>1. 服务通信自定义srv</h3><p>服务通信也是ROS中一种极其常用的通信模式，服务通信是基于<strong>请求响应</strong>模式的，是一种应答机制。也即: 一个节点A向另一个节点B发送请求，B接收处理请求并产生响应结果返回给A。比如如下场景:</p><blockquote><p>机器人巡逻过程中，控制系统分析传感器数据发现可疑物体或人… 此时需要拍摄照片并留存。</p></blockquote><p>在上述场景中，就使用到了服务通信。一个节点需要向相机节点发送拍照请求，相机节点处理请求，并返回处理结果。与上述应用类似的，服务通信更适用于对时时性有要求、具有一定逻辑处理的应用场景。</p><p><strong>需求:</strong> 服务通信中，客户端提交两个整数至服务端，服务端求和并响应结果到客户端，请创建服务器与客户端通信的数据载体。</p><p><strong>流程:</strong> srv 文件内的可用数据类型与 msg 文件一致，且定义 srv 实现流程与自定义 msg 实现流程类似:</p><blockquote><ol><li>按照固定格式创建srv文件</li><li>编辑配置文件</li><li>编译生成中间文件</li></ol></blockquote><h4 id="1-1-定义srv文件"><a href="#1-1-定义srv文件" class="headerlink" title="1.1 定义srv文件"></a>1.1 定义srv文件</h4><p>服务通信中，数据分成两部分，请求与响应，在 srv 文件中请求和响应使用<code>---</code>分割，具体实现如下:</p><p>功能包下新建 srv 目录，添加 xxx.srv 文件，内容:</p><pre class="line-numbers language-none"><code class="language-none"># 客户端请求时发送的两个数字int32 num1int32 num2---# 服务器响应发送的数据int32 sum<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="1-2-编辑配置文件"><a href="#1-2-编辑配置文件" class="headerlink" title="1.2 编辑配置文件"></a>1.2 编辑配置文件</h4><p><strong>package.xml</strong>中添加编译依赖与执行依赖</p><pre class="line-numbers language-none"><code class="language-none">&lt;build_depend&gt;message_generation&lt;&#x2F;build_depend&gt;&lt;exec_depend&gt;message_runtime&lt;&#x2F;exec_depend&gt;&lt;!-- exce_depend 以前对应的是 run_depend 现在非法--&gt;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>CMakeLists.txt</strong>编辑 srv 相关配置</p><pre class="line-numbers language-none"><code class="language-none">find_package(catkin REQUIRED COMPONENTS  roscpp  rospy  std_msgs  message_generation)# 需要加入 message_generation,必须有 std_msgs<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-none"><code class="language-none">add_service_files(  FILES  AddInts.srv)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-none"><code class="language-none">generate_messages(  DEPENDENCIES  std_msgs)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p><strong>注意:</strong>  官网没有在 catkin_package 中配置 message_runtime,经测试配置也可以</p><h4 id="1-3-编译"><a href="#1-3-编译" class="headerlink" title="1.3 编译"></a>1.3 编译</h4><p>在工作空间下进行编译，<strong>注意</strong>单纯改动python文件不需要进行编译，其他改动一般都是需要编译的，此外，每次新打开的terminal都需要通过<strong>source配置环境</strong>。</p><pre class="line-numbers language-none"><code class="language-none">#  编译---工作空间catkin_make#  工作空间内配置环境变量---新建terminal时source devel&#x2F;setup.bash<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>编译后产生中间文件供C++或Python调用，后续调用相关 srv时，是从这些中间文件调用的：</strong></p><p>C++ 需要调用的中间文件(…&#x2F;工作空间&#x2F;devel&#x2F;include&#x2F;包名&#x2F;xxx.h)</p><p><img src="/./images/ROS%E6%9E%B6%E6%9E%84/3.png"></p><p>Python 需要调用的中间文件(…&#x2F;工作空间&#x2F;devel&#x2F;lib&#x2F;python3&#x2F;dist-packages&#x2F;包名&#x2F;srv)</p><p><img src="/./images/ROS%E6%9E%B6%E6%9E%84/4.png"></p><h3 id="2-服务通信自定义srv调用"><a href="#2-服务通信自定义srv调用" class="headerlink" title="2. 服务通信自定义srv调用"></a>2. 服务通信自定义srv调用</h3><p><strong>需求:</strong> 编写服务通信，客户端提交两个整数至服务端，服务端求和并响应结果到客户端。</p><p><strong>流程:</strong></p><blockquote><ol><li>编写服务端实现；</li><li>编写客户端实现；</li><li>为python文件添加可执行权限；</li><li>编辑配置文件；</li><li>编译并执行。</li></ol></blockquote><h4 id="2-1-服务端"><a href="#2-1-服务端" class="headerlink" title="2.1 服务端"></a>2.1 服务端</h4><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#! /usr/bin/env python</span><span class="token triple-quoted-string string">"""    需求:         编写两个节点实现服务通信，客户端节点需要提交两个整数到服务器        服务器需要解析客户端提交的数据，相加后，将结果响应回客户端，        客户端再解析    服务器端实现:        1.导包        2.初始化 ROS 节点        3.创建服务对象        4.回调函数处理请求并产生响应        5.spin 函数"""</span><span class="token comment"># 1.导包</span><span class="token keyword">import</span> rospy<span class="token keyword">from</span> demo03_server_client<span class="token punctuation">.</span>srv <span class="token keyword">import</span> AddInts<span class="token punctuation">,</span>AddIntsRequest<span class="token punctuation">,</span>AddIntsResponse<span class="token comment"># 回调函数的参数是请求对象，返回值是响应对象</span><span class="token keyword">def</span> <span class="token function">doReq</span><span class="token punctuation">(</span>req<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment"># 解析提交的数据</span>    <span class="token builtin">sum</span> <span class="token operator">=</span> req<span class="token punctuation">.</span>num1 <span class="token operator">+</span> req<span class="token punctuation">.</span>num2    rospy<span class="token punctuation">.</span>loginfo<span class="token punctuation">(</span><span class="token string">"提交的数据:num1 = %d, num2 = %d, sum = %d"</span><span class="token punctuation">,</span>req<span class="token punctuation">.</span>num1<span class="token punctuation">,</span> req<span class="token punctuation">.</span>num2<span class="token punctuation">,</span> <span class="token builtin">sum</span><span class="token punctuation">)</span>    <span class="token comment"># 创建响应对象，赋值并返回</span>    <span class="token comment"># resp = AddIntsResponse()</span>    <span class="token comment"># resp.sum = sum</span>    resp <span class="token operator">=</span> AddIntsResponse<span class="token punctuation">(</span><span class="token builtin">sum</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> resp<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">"__main__"</span><span class="token punctuation">:</span>    <span class="token comment"># 2.初始化 ROS 节点</span>    rospy<span class="token punctuation">.</span>init_node<span class="token punctuation">(</span><span class="token string">"addints_server_p"</span><span class="token punctuation">)</span>    <span class="token comment"># 3.创建服务对象</span>    server <span class="token operator">=</span> rospy<span class="token punctuation">.</span>Service<span class="token punctuation">(</span><span class="token string">"AddInts"</span><span class="token punctuation">,</span>AddInts<span class="token punctuation">,</span>doReq<span class="token punctuation">)</span>    <span class="token comment"># 4.回调函数处理请求并产生响应</span>    <span class="token comment"># 5.spin 函数</span>    rospy<span class="token punctuation">.</span>spin<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="2-2-客户端"><a href="#2-2-客户端" class="headerlink" title="2.2 客户端"></a>2.2 客户端</h4><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#! /usr/bin/env python</span><span class="token triple-quoted-string string">"""    需求:         编写两个节点实现服务通信，客户端节点需要提交两个整数到服务器        服务器需要解析客户端提交的数据，相加后，将结果响应回客户端，        客户端再解析    客户端实现:        1.导包        2.初始化 ROS 节点        3.创建请求对象        4.发送请求        5.接收并处理响应    优化:        加入数据的动态获取"""</span><span class="token comment">#1.导包</span><span class="token keyword">import</span> rospy<span class="token keyword">from</span> demo03_server_client<span class="token punctuation">.</span>srv <span class="token keyword">import</span> <span class="token operator">*</span><span class="token keyword">import</span> sys<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">"__main__"</span><span class="token punctuation">:</span>    <span class="token comment">#优化实现</span>    <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>sys<span class="token punctuation">.</span>argv<span class="token punctuation">)</span> <span class="token operator">!=</span> <span class="token number">3</span><span class="token punctuation">:</span>        rospy<span class="token punctuation">.</span>logerr<span class="token punctuation">(</span><span class="token string">"请正确提交参数"</span><span class="token punctuation">)</span>        sys<span class="token punctuation">.</span>exit<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>    <span class="token comment"># 2.初始化 ROS 节点</span>    rospy<span class="token punctuation">.</span>init_node<span class="token punctuation">(</span><span class="token string">"AddInts_Client_p"</span><span class="token punctuation">)</span>    <span class="token comment"># 3.创建请求对象</span>    client <span class="token operator">=</span> rospy<span class="token punctuation">.</span>ServiceProxy<span class="token punctuation">(</span><span class="token string">"AddInts"</span><span class="token punctuation">,</span>AddInts<span class="token punctuation">)</span>    <span class="token comment"># 请求前，等待服务已经就绪</span>    <span class="token comment"># 方式1:</span>    <span class="token comment"># rospy.wait_for_service("AddInts")</span>    <span class="token comment"># 方式2</span>    client<span class="token punctuation">.</span>wait_for_service<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment"># 4.发送请求,接收并处理响应</span>    <span class="token comment"># 方式1</span>    <span class="token comment"># resp = client(3,4)</span>    <span class="token comment"># 方式2</span>    <span class="token comment"># resp = client(AddIntsRequest(1,5))</span>    <span class="token comment"># 方式3</span>    req <span class="token operator">=</span> AddIntsRequest<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment"># req.num1 = 100</span>    <span class="token comment"># req.num2 = 200 </span>    <span class="token comment">#优化</span>    req<span class="token punctuation">.</span>num1 <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>sys<span class="token punctuation">.</span>argv<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    req<span class="token punctuation">.</span>num2 <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>sys<span class="token punctuation">.</span>argv<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span>     resp <span class="token operator">=</span> client<span class="token punctuation">.</span>call<span class="token punctuation">(</span>req<span class="token punctuation">)</span>    rospy<span class="token punctuation">.</span>loginfo<span class="token punctuation">(</span><span class="token string">"响应结果:%d"</span><span class="token punctuation">,</span>resp<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="2-3-设置权限"><a href="#2-3-设置权限" class="headerlink" title="2.3 设置权限"></a>2.3 设置权限</h4><p>终端下进入 scripts 执行:<code>chmod +x *.py</code></p><h4 id="2-4-配置CMakeLists-txt"><a href="#2-4-配置CMakeLists-txt" class="headerlink" title="2.4 配置CMakeLists.txt"></a>2.4 配置CMakeLists.txt</h4><p><strong>CMakeLists.txt</strong></p><pre class="line-numbers language-none"><code class="language-none">catkin_install_python(PROGRAMS  scripts&#x2F;AddInts_Server_p.py   scripts&#x2F;AddInts_Client_p.py  DESTINATION $&#123;CATKIN_PACKAGE_BIN_DESTINATION&#125;)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="2-5-执行"><a href="#2-5-执行" class="headerlink" title="2.5 执行"></a>2.5 执行</h4><p><strong>流程:</strong></p><ul><li>需要先启动服务:<code>rosrun 包名 服务</code></li><li>然后再调用客户端 :<code>rosrun 包名 客户端 参数1 参数2</code></li></ul>]]></content>
      
      
      <categories>
          
          <category> Tutorial </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ROS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ROS话题通信</title>
      <link href="/2023/03/09/ros-hua-ti-tong-xin/"/>
      <url>/2023/03/09/ros-hua-ti-tong-xin/</url>
      
        <content type="html"><![CDATA[<h3 id="1-话题通信基本操作"><a href="#1-话题通信基本操作" class="headerlink" title="1. 话题通信基本操作"></a>1. 话题通信基本操作</h3><p><strong>需求:</strong> 编写发布订阅实现，要求发布方以10HZ(每秒10次)的频率发布文本消息，订阅方订阅消息并将消息内容打印输出。</p><p><strong>流程:</strong></p><blockquote><ol><li>编写发布方实现；</li><li>编写订阅方实现；</li><li>为python文件添加可执行权限；</li><li>编辑配置文件；</li><li>编译并执行。</li></ol></blockquote><h4 id="1-1-发布方"><a href="#1-1-发布方" class="headerlink" title="1.1 发布方"></a>1.1 发布方</h4><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#! /usr/bin/env python</span><span class="token triple-quoted-string string">"""    需求: 实现基本的话题通信，一方发布数据，一方接收数据，         实现的关键点:         1.发送方         2.接收方         3.数据(此处为普通文本)         PS: 二者需要设置相同的话题    消息发布方:        循环发布信息:HelloWorld 后缀数字编号    实现流程:        1.导包         2.初始化 ROS 节点:命名(唯一)        3.实例化 发布者 对象        4.组织被发布的数据，并编写逻辑发布数据"""</span><span class="token comment">#1.导包 </span><span class="token keyword">import</span> rospy<span class="token keyword">from</span> std_msgs<span class="token punctuation">.</span>msg <span class="token keyword">import</span> String<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">"__main__"</span><span class="token punctuation">:</span>    <span class="token comment">#2.初始化 ROS 节点:命名(唯一)</span>    rospy<span class="token punctuation">.</span>init_node<span class="token punctuation">(</span><span class="token string">"talker_p"</span><span class="token punctuation">)</span>    <span class="token comment">#3.实例化 发布者 对象</span>    pub <span class="token operator">=</span> rospy<span class="token punctuation">.</span>Publisher<span class="token punctuation">(</span><span class="token string">"chatter"</span><span class="token punctuation">,</span>String<span class="token punctuation">,</span>queue_size<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span>    <span class="token comment">#4.组织被发布的数据，并编写逻辑发布数据</span>    msg <span class="token operator">=</span> String<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment">#创建 msg 对象</span>    msg_front <span class="token operator">=</span> <span class="token string">"hello 你好"</span>    count <span class="token operator">=</span> <span class="token number">0</span>  <span class="token comment">#计数器 </span>    <span class="token comment"># 设置循环频率</span>    rate <span class="token operator">=</span> rospy<span class="token punctuation">.</span>Rate<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>    <span class="token keyword">while</span> <span class="token keyword">not</span> rospy<span class="token punctuation">.</span>is_shutdown<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment">#拼接字符串</span>        msg<span class="token punctuation">.</span>data <span class="token operator">=</span> msg_front <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>count<span class="token punctuation">)</span>        pub<span class="token punctuation">.</span>publish<span class="token punctuation">(</span>msg<span class="token punctuation">)</span>        rate<span class="token punctuation">.</span>sleep<span class="token punctuation">(</span><span class="token punctuation">)</span>        rospy<span class="token punctuation">.</span>loginfo<span class="token punctuation">(</span><span class="token string">"写出的数据:%s"</span><span class="token punctuation">,</span>msg<span class="token punctuation">.</span>data<span class="token punctuation">)</span>        count <span class="token operator">+=</span> <span class="token number">1</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="1-2-订阅方"><a href="#1-2-订阅方" class="headerlink" title="1.2 订阅方"></a>1.2 订阅方</h4><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#! /usr/bin/env python</span><span class="token triple-quoted-string string">"""    需求: 实现基本的话题通信，一方发布数据，一方接收数据，         实现的关键点:         1.发送方         2.接收方         3.数据(此处为普通文本)    消息订阅方:        订阅话题并打印接收到的消息    实现流程:        1.导包         2.初始化 ROS 节点:命名(唯一)        3.实例化 订阅者 对象        4.处理订阅的消息(回调函数)        5.设置循环调用回调函数"""</span><span class="token comment">#1.导包 </span><span class="token keyword">import</span> rospy<span class="token keyword">from</span> std_msgs<span class="token punctuation">.</span>msg <span class="token keyword">import</span> String<span class="token keyword">def</span> <span class="token function">doMsg</span><span class="token punctuation">(</span>msg<span class="token punctuation">)</span><span class="token punctuation">:</span>    rospy<span class="token punctuation">.</span>loginfo<span class="token punctuation">(</span><span class="token string">"I heard:%s"</span><span class="token punctuation">,</span>msg<span class="token punctuation">.</span>data<span class="token punctuation">)</span><span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">"__main__"</span><span class="token punctuation">:</span>    <span class="token comment">#2.初始化 ROS 节点:命名(唯一)</span>    rospy<span class="token punctuation">.</span>init_node<span class="token punctuation">(</span><span class="token string">"listener_p"</span><span class="token punctuation">)</span>    <span class="token comment">#3.实例化 订阅者 对象</span>    sub <span class="token operator">=</span> rospy<span class="token punctuation">.</span>Subscriber<span class="token punctuation">(</span><span class="token string">"chatter"</span><span class="token punctuation">,</span>String<span class="token punctuation">,</span>doMsg<span class="token punctuation">,</span>queue_size<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span>    <span class="token comment">#4.处理订阅的消息(回调函数)</span>    <span class="token comment">#5.设置循环调用回调函数</span>    rospy<span class="token punctuation">.</span>spin<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="1-3-添加可执行权限"><a href="#1-3-添加可执行权限" class="headerlink" title="1.3 添加可执行权限"></a>1.3 添加可执行权限</h4><p>终端下进入 scripts 执行:<code>chmod +x *.py</code></p><h4 id="1-4-配置CMakeLists-txt"><a href="#1-4-配置CMakeLists-txt" class="headerlink" title="1.4 配置CMakeLists.txt"></a>1.4 配置CMakeLists.txt</h4><pre class="line-numbers language-none"><code class="language-none">catkin_install_python(PROGRAMS  scripts&#x2F;talker_p.py  scripts&#x2F;listener_p.py  DESTINATION $&#123;CATKIN_PACKAGE_BIN_DESTINATION&#125;)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="1-5-执行"><a href="#1-5-执行" class="headerlink" title="1.5 执行"></a>1.5 执行</h4><ol><li>启动roscore</li><li>启动发布节点</li><li>启动订阅节点</li></ol><h3 id="2-话题通信自定义msg"><a href="#2-话题通信自定义msg" class="headerlink" title="2. 话题通信自定义msg"></a>2. 话题通信自定义msg</h3><p>在 ROS 通信协议中，数据载体是一个较为重要组成部分，ROS 中通过 std_msgs 封装了一些原生的数据类型,比如:String、Int32、Int64、Char、Bool、Empty…. 但是，这些数据一般只包含一个 data 字段，结构的单一意味着功能上的局限性，当传输一些复杂的数据，比如: 激光雷达的信息… std_msgs 由于描述性较差而显得力不从心，这种场景下可以使用自定义的消息类型。</p><p>ROS中还有一种特殊类型：<code>Header</code>，标头包含时间戳和ROS中常用的坐标帧信息。会经常看到msg文件的第一行具有<code>Header标头</code>。</p><p><strong>需求:</strong> 创建自定义消息，该消息包含人的信息:姓名、身高、年龄等。</p><p><strong>流程:</strong></p><blockquote><ol><li>按照固定格式创建 msg 文件</li><li>编辑配置文件</li><li>编译生成可以被 Python 或 C++ 调用的中间文件</li></ol></blockquote><h4 id="2-1-定义msg文件"><a href="#2-1-定义msg文件" class="headerlink" title="2.1 定义msg文件"></a>2.1 定义msg文件</h4><p>功能包下新建 msg 目录，添加文件 Person.msg</p><pre class="line-numbers language-none"><code class="language-none">string nameuint16 agefloat64 height<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h4 id="2-2-编辑配置文件"><a href="#2-2-编辑配置文件" class="headerlink" title="2.2 编辑配置文件"></a>2.2 编辑配置文件</h4><p>功能包内的<strong>package.xml</strong>中添加编译依赖与执行依赖</p><pre class="line-numbers language-none"><code class="language-none">&lt;build_depend&gt;message_generation&lt;&#x2F;build_depend&gt;&lt;exec_depend&gt;message_runtime&lt;&#x2F;exec_depend&gt;&lt;!-- exce_depend 以前对应的是 run_depend 现在非法--&gt;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>功能包内的<strong>CMakeLists.txt</strong>编辑 msg 相关配置</p><pre class="line-numbers language-none"><code class="language-none">find_package(catkin REQUIRED COMPONENTS  roscpp  rospy  std_msgs  message_generation)# 需要加入 message_generation,必须有 std_msgs<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-none"><code class="language-none">## 配置 msg 源文件add_message_files(  FILES  Person.msg)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-none"><code class="language-none"># 生成消息时依赖于 std_msgsgenerate_messages(  DEPENDENCIES  std_msgs)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-none"><code class="language-none">#执行时依赖catkin_package(#  INCLUDE_DIRS include#  LIBRARIES demo02_talker_listener  CATKIN_DEPENDS roscpp rospy std_msgs message_runtime#  DEPENDS system_lib)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="2-3-编译"><a href="#2-3-编译" class="headerlink" title="2.3 编译"></a>2.3 编译</h4><p>在工作空间下进行编译，<strong>注意</strong>单纯改动python文件不需要进行编译，其他改动一般都是需要编译的，此外，每次新打开的terminal都需要通过<strong>source配置环境</strong>。</p><pre class="line-numbers language-none"><code class="language-none">#  编译---工作空间catkin_make#  配置环境变量---新建terminal时source devel&#x2F;setup.bash<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>编译后产生中间文件供C++或Python调用，后续调用相关 msg 时，是从这些中间文件调用的：</strong></p><p>C++ 需要调用的中间文件(…&#x2F;工作空间&#x2F;devel&#x2F;include&#x2F;包名&#x2F;xxx.h)</p><p><img src="/./images/ROS%E6%9E%B6%E6%9E%84/1.png"></p><p>Python 需要调用的中间文件(…&#x2F;工作空间&#x2F;devel&#x2F;lib&#x2F;python3&#x2F;dist-packages&#x2F;包名&#x2F;msg)</p><p><img src="/./images/ROS%E6%9E%B6%E6%9E%84/2.png"></p><h4 id="2-4-发布方"><a href="#2-4-发布方" class="headerlink" title="2.4 发布方"></a>2.4 发布方</h4><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#! /usr/bin/env python</span><span class="token triple-quoted-string string">"""    发布方:        循环发送消息"""</span><span class="token keyword">import</span> rospy<span class="token keyword">from</span> demo02_talker_listener<span class="token punctuation">.</span>msg <span class="token keyword">import</span> Person<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">"__main__"</span><span class="token punctuation">:</span>    <span class="token comment">#1.初始化 ROS 节点</span>    rospy<span class="token punctuation">.</span>init_node<span class="token punctuation">(</span><span class="token string">"talker_person_p"</span><span class="token punctuation">)</span>    <span class="token comment">#2.创建发布者对象</span>    pub <span class="token operator">=</span> rospy<span class="token punctuation">.</span>Publisher<span class="token punctuation">(</span><span class="token string">"chatter_person"</span><span class="token punctuation">,</span>Person<span class="token punctuation">,</span>queue_size<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span>    <span class="token comment">#3.组织消息</span>    p <span class="token operator">=</span> Person<span class="token punctuation">(</span><span class="token punctuation">)</span>    p<span class="token punctuation">.</span>name <span class="token operator">=</span> <span class="token string">"葫芦瓦"</span>    p<span class="token punctuation">.</span>age <span class="token operator">=</span> <span class="token number">18</span>    p<span class="token punctuation">.</span>height <span class="token operator">=</span> <span class="token number">0.75</span>    <span class="token comment">#4.编写消息发布逻辑</span>    rate <span class="token operator">=</span> rospy<span class="token punctuation">.</span>Rate<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>    <span class="token keyword">while</span> <span class="token keyword">not</span> rospy<span class="token punctuation">.</span>is_shutdown<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        pub<span class="token punctuation">.</span>publish<span class="token punctuation">(</span>p<span class="token punctuation">)</span>  <span class="token comment">#发布消息</span>        rate<span class="token punctuation">.</span>sleep<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment">#休眠</span>        rospy<span class="token punctuation">.</span>loginfo<span class="token punctuation">(</span><span class="token string">"姓名:%s, 年龄:%d, 身高:%.2f"</span><span class="token punctuation">,</span>p<span class="token punctuation">.</span>name<span class="token punctuation">,</span> p<span class="token punctuation">.</span>age<span class="token punctuation">,</span> p<span class="token punctuation">.</span>height<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="2-5-订阅方"><a href="#2-5-订阅方" class="headerlink" title="2.5 订阅方"></a>2.5 订阅方</h4><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#! /usr/bin/env python</span><span class="token triple-quoted-string string">"""    订阅方:        订阅消息"""</span><span class="token keyword">import</span> rospy<span class="token keyword">from</span> demo02_talker_listener<span class="token punctuation">.</span>msg <span class="token keyword">import</span> Person<span class="token keyword">def</span> <span class="token function">doPerson</span><span class="token punctuation">(</span>p<span class="token punctuation">)</span><span class="token punctuation">:</span>    rospy<span class="token punctuation">.</span>loginfo<span class="token punctuation">(</span><span class="token string">"接收到的人的信息:%s, %d, %.2f"</span><span class="token punctuation">,</span>p<span class="token punctuation">.</span>name<span class="token punctuation">,</span> p<span class="token punctuation">.</span>age<span class="token punctuation">,</span> p<span class="token punctuation">.</span>height<span class="token punctuation">)</span><span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">"__main__"</span><span class="token punctuation">:</span>    <span class="token comment">#1.初始化节点</span>    rospy<span class="token punctuation">.</span>init_node<span class="token punctuation">(</span><span class="token string">"listener_person_p"</span><span class="token punctuation">)</span>    <span class="token comment">#2.创建订阅者对象</span>    sub <span class="token operator">=</span> rospy<span class="token punctuation">.</span>Subscriber<span class="token punctuation">(</span><span class="token string">"chatter_person"</span><span class="token punctuation">,</span>Person<span class="token punctuation">,</span>doPerson<span class="token punctuation">,</span>queue_size<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span>    rospy<span class="token punctuation">.</span>spin<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment">#4.循环</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="2-6-权限设置"><a href="#2-6-权限设置" class="headerlink" title="2.6 权限设置"></a>2.6 权限设置</h4><p>终端下进入 scripts 执行:<code>chmod +x *.py</code></p><h4 id="2-7-配置CMakeLists-txt"><a href="#2-7-配置CMakeLists-txt" class="headerlink" title="2.7 配置CMakeLists.txt"></a>2.7 配置CMakeLists.txt</h4><pre class="line-numbers language-none"><code class="language-none">catkin_install_python(PROGRAMS  scripts&#x2F;talker_p.py  scripts&#x2F;listener_p.py  scripts&#x2F;person_talker.py  scripts&#x2F;person_listener.py  DESTINATION $&#123;CATKIN_PACKAGE_BIN_DESTINATION&#125;)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="2-8-执行"><a href="#2-8-执行" class="headerlink" title="2.8 执行"></a>2.8 执行</h4><p>1.启动 roscore;</p><p>2.启动发布节点;</p><p>3.启动订阅节点。</p><h3 id="3-ROS话题通信注意事项"><a href="#3-ROS话题通信注意事项" class="headerlink" title="3. ROS话题通信注意事项"></a>3. ROS话题通信注意事项</h3><ul><li>roscore的运行位置可以<strong>任意</strong>，只需启动ros master即可；</li><li>除改动python文件外，其他改动一般都需要在工作空间进行<strong>catkin_make</strong>的编译；</li><li>每次新建的terminal都需要在工作空间进行环境配置，即<strong>source devel&#x2F;setup.bash</strong>；</li><li>python文件的第一行一定不能忘记指定python解释器，即**#! &#x2F;usr&#x2F;bin&#x2F;env python**；</li><li>rosrun 功能包名 自定义文件名.py 与python 自定义文件名.py 启动程序效果相同；</li><li>自定义msg是在<strong>功能包内</strong>新建msg目录，并创建自定义msg名.msg；</li><li>编译生成msg中间文件后，在python文件导入msg内容，采用的是<strong>from 功能包.msg import 自定义msg名</strong>；</li></ul>]]></content>
      
      
      <categories>
          
          <category> Tutorial </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ROS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ROS创建项目流程</title>
      <link href="/2023/03/09/ros-chuang-jian-xiang-mu-liu-cheng/"/>
      <url>/2023/03/09/ros-chuang-jian-xiang-mu-liu-cheng/</url>
      
        <content type="html"><![CDATA[<p><img src="/./images/ROS%E6%9E%B6%E6%9E%84/0.png"></p><p>​ROS中涉及的编程语言以C++和Python为主，ROS中的大多数程序两者都可以实现，同时，ROS中的程序即便使用不同的编程语言，实现流程也大致类似，以当前HelloWorld程序为例，实现流程大致如下：</p><blockquote><ol><li>先创建一个工作空间；</li><li>再创建一个功能包；</li><li>编辑源文件；</li><li>编辑配置文件；</li><li>编译并执行。</li></ol></blockquote><p>​上述流程中，C++和Python只是在步骤3和步骤4的实现细节上存在差异，其他流程基本一致。</p><h3 id="1-创建工作空间并初始化"><a href="#1-创建工作空间并初始化" class="headerlink" title="1. 创建工作空间并初始化"></a>1. 创建工作空间并初始化</h3><pre class="line-numbers language-none"><code class="language-none">mkdir -p 自定义空间名称&#x2F;srccd 自定义空间名称catkin_make<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>​上述命令，首先会创建一个工作空间以及一个 src 子目录，然后再进入工作空间调用 catkin_make命令编译。</p><h3 id="2-进入src创建ros包并添加依赖"><a href="#2-进入src创建ros包并添加依赖" class="headerlink" title="2. 进入src创建ros包并添加依赖"></a>2. 进入src创建ros包并添加依赖</h3><pre class="line-numbers language-none"><code class="language-none">cd srccatkin_create_pkg 自定义ROS包名 roscpp rospy std_msgs<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>​上述命令，会在工作空间下生成一个功能包，该功能包依赖于 roscpp、rospy 与 std_msgs，其中roscpp是使用C++实现的库，而rospy则是使用python实现的库，std_msgs是标准消息库，创建ROS功能包时，一般都会依赖这三个库实现。</p><h3 id="3-进入ros包添加scripts目录并编辑python文件"><a href="#3-进入ros包添加scripts目录并编辑python文件" class="headerlink" title="3. 进入ros包添加scripts目录并编辑python文件"></a>3. 进入ros包添加scripts目录并编辑python文件</h3><pre class="line-numbers language-none"><code class="language-none">cd ros包mkdir scripts<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#! /usr/bin/env python</span><span class="token triple-quoted-string string">"""    Python 版 HelloWorld"""</span><span class="token keyword">import</span> rospy<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">"__main__"</span><span class="token punctuation">:</span>    rospy<span class="token punctuation">.</span>init_node<span class="token punctuation">(</span><span class="token string">"Hello"</span><span class="token punctuation">)</span>    rospy<span class="token punctuation">.</span>loginfo<span class="token punctuation">(</span><span class="token string">"Hello World!!!!"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="4-为python文件添加可执行权限"><a href="#4-为python文件添加可执行权限" class="headerlink" title="4. 为python文件添加可执行权限"></a>4. 为python文件添加可执行权限</h3><pre class="line-numbers language-none"><code class="language-none">chmod +x 自定义文件名.py<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="5-编辑ros包下的CmakeLists-txt文件"><a href="#5-编辑ros包下的CmakeLists-txt文件" class="headerlink" title="5. 编辑ros包下的CmakeLists.txt文件"></a>5. 编辑ros包下的CmakeLists.txt文件</h3><pre class="line-numbers language-none"><code class="language-none">catkin_install_python(PROGRAMS scripts&#x2F;自定义文件名.py  DESTINATION $&#123;CATKIN_PACKAGE_BIN_DESTINATION&#125;)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h3 id="6-进入工作空间目录并编译"><a href="#6-进入工作空间目录并编译" class="headerlink" title="6. 进入工作空间目录并编译"></a>6. 进入工作空间目录并编译</h3><pre class="line-numbers language-none"><code class="language-none">cd 自定义空间名称catkin_make<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h3 id="7-启动并执行程序"><a href="#7-启动并执行程序" class="headerlink" title="7. 启动并执行程序"></a>7. 启动并执行程序</h3><p>​先启动roscore，这个是启动ros工作环境必须要执行的，值得注意的是该命令可以在任何路径执行，不会对后续命令产生负面影响。</p><pre class="line-numbers language-none"><code class="language-none">roscore<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>​再启动python文件，python文件的启动方式有两种，第一种是按照常规的python文件启动方式进行，当前理解是此种方式只是针对ros工作空间只有python文件进行通信等场景中，当同时涉及cpp文件与python文件时，不能采用第一种方式启动。</p><p>​<strong>第一种启动方式</strong></p><pre class="line-numbers language-none"><code class="language-none">python 文件路径&#x2F;自定义文件名.py<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>​<strong>第二种启动方式</strong></p><pre class="line-numbers language-none"><code class="language-none">cd 工作空间source .&#x2F;devel&#x2F;setup.bashrosrun 包名 自定义文件名.py<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>​如上所诉，第二种启动方式可以应对同时含有cpp文件与python文件的工作场景，命令行中的source的目的是配置环境变量，缺少该命令将导致程序找不到对应需要的配置。</p>]]></content>
      
      
      <categories>
          
          <category> Tutorial </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ROS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ROS文件系统相关命令</title>
      <link href="/2023/03/09/ros-wen-jian-xi-tong-xiang-guan-ming-ling/"/>
      <url>/2023/03/09/ros-wen-jian-xi-tong-xiang-guan-ming-ling/</url>
      
        <content type="html"><![CDATA[<h3 id="1-ROS文件系统相关命令"><a href="#1-ROS文件系统相关命令" class="headerlink" title="1. ROS文件系统相关命令"></a>1. ROS文件系统相关命令</h3><p>​ROS 的文件系统本质上都还是操作系统文件，我们可以使用Linux命令来操作这些文件，不过，在ROS中为了更好的用户体验，ROS专门提供了一些类似于Linux的命令，这些命令较之于Linux原生命令，更为简介、高效。文件操作，无外乎就是增删改查与执行等操作，接下来，我们就从这五个维度，来介绍ROS文件系统的一些常用命令。</p><h4 id="1-1-增"><a href="#1-1-增" class="headerlink" title="1.1 增"></a>1.1 增</h4><p>​catkin_create_pkg 自定义包名 依赖包 &#x3D;&#x3D;&#x3D; 创建新的ROS功能包</p><p>​sudo apt install xxx &#x3D;&#x3D;&#x3D; 安装 ROS功能包</p><h4 id="1-2-删"><a href="#1-2-删" class="headerlink" title="1.2 删"></a>1.2 删</h4><p>​sudo apt purge xxx &#x3D;&#x3D;&#x3D;&#x3D; 删除某个功能包</p><h4 id="1-3-查"><a href="#1-3-查" class="headerlink" title="1.3 查"></a>1.3 查</h4><p>​rospack list &#x3D;&#x3D;&#x3D; 列出所有功能包</p><p>​rospack find 包名 &#x3D;&#x3D;&#x3D; 查找某个功能包是否存在，如果存在返回安装路径</p><p>​roscd 包名 &#x3D;&#x3D;&#x3D; 进入某个功能包</p><p>​rosls 包名 &#x3D;&#x3D;&#x3D; 列出某个包下的文件</p><p>​apt search xxx &#x3D;&#x3D;&#x3D; 搜索某个功能包</p><h4 id="1-4-改"><a href="#1-4-改" class="headerlink" title="1.4 改"></a>1.4 改</h4><p>​rosed 包名 文件名 &#x3D;&#x3D;&#x3D; 修改功能包文件</p><p>​需要安装 vim</p><p>​**比如:**rosed turtlesim Color.msg</p><h4 id="1-5-执行"><a href="#1-5-执行" class="headerlink" title="1.5 执行"></a>1.5 执行</h4><h5 id="1-5-1-roscore"><a href="#1-5-1-roscore" class="headerlink" title="1.5.1 roscore"></a>1.5.1 roscore</h5><p>​<strong>roscore &#x3D;&#x3D;&#x3D;</strong> 是 ROS 的系统先决条件节点和程序的集合， 必须运行 roscore 才能使 ROS 节点进行通信。</p><p>​roscore 将启动:</p><ul><li><p>ros master</p></li><li><p>ros 参数服务器</p></li><li><p>rosout日志节点</p></li></ul><p>​用法：</p><pre class="line-numbers language-none"><code class="language-none">roscore<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>​或(指定端口号)</p><pre class="line-numbers language-none"><code class="language-none">roscore -p xxxx<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h5 id="1-5-2-rosrun"><a href="#1-5-2-rosrun" class="headerlink" title="1.5.2 rosrun"></a>1.5.2 rosrun</h5><p>​<strong>rosrun 包名 可执行文件名</strong> &#x3D;&#x3D;&#x3D; 运行指定的ROS节点</p><p>​<strong>比如:</strong><code>rosrun turtlesim turtlesim_node</code></p><h5 id="1-5-3-roslaunch"><a href="#1-5-3-roslaunch" class="headerlink" title="1.5.3 roslaunch"></a>1.5.3 roslaunch</h5><p>​<strong>roslaunch 包名 launch文件名</strong> &#x3D;&#x3D;&#x3D; 执行某个包下的 launch 文件</p>]]></content>
      
      
      <categories>
          
          <category> Tutorial </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ROS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ROS文件系统</title>
      <link href="/2023/03/09/ros-wen-jian-xi-tong/"/>
      <url>/2023/03/09/ros-wen-jian-xi-tong/</url>
      
        <content type="html"><![CDATA[<h3 id="1-ROS文件系统"><a href="#1-ROS文件系统" class="headerlink" title="1.ROS文件系统"></a>1.ROS文件系统</h3><p>​ROS文件系统级指的是在硬盘上ROS源代码的组织形式，其结构大致可以如下图所示：</p><p><img src="/./images/ROS%E6%9E%B6%E6%9E%84/0.png"></p><pre class="line-numbers language-none"><code class="language-none">WorkSpace --- 自定义的工作空间    |--- build:编译空间，用于存放CMake和catkin的缓存信息、配置信息和其他中间文件。    |--- devel:开发空间，用于存放编译后生成的目标文件，包括头文件、动态&amp;静态链接库、可执行文件等。    |--- src: 源码        |-- package：功能包(ROS基本单元)包含多个节点、库与配置文件，包名所有字母小写，只能由字母、数字与下划线组成            |-- CMakeLists.txt 配置编译规则，比如源文件、依赖项、目标文件            |-- package.xml 包信息，比如:包名、版本、作者、依赖项...(以前版本是 manifest.xml)            |-- scripts 存储python文件            |-- src 存储C++源文件            |-- include 头文件            |-- msg 消息通信格式文件            |-- srv 服务通信格式文件            |-- action 动作格式文件            |-- launch 可一次性运行多个节点             |-- config 配置信息        |-- CMakeLists.txt: 编译的基本配置<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>​ROS 文件系统中部分目录和文件前面编程中已经有所涉及，比如功能包的创建、src目录下cpp文件的编写、scripts目录下python文件的编写、launch目录下launch文件的编写，并且也配置了 package.xml 与 CMakeLists.txt 文件。其他目录下的内容后面教程将会再行介绍，当前我们主要介绍: package.xml 与 CMakeLists.txt 这两个配置文件。</p><h4 id="1-1package-xml"><a href="#1-1package-xml" class="headerlink" title="1.1package.xml"></a>1.1package.xml</h4><p>​该文件定义有关软件包的属性，例如软件包名称，版本号，作者，维护者以及对其他catkin软件包的依赖性。请注意，该概念类似于旧版 rosbuild 构建系统中使用的<em>manifest.xml</em>文件。</p><pre class="line-numbers language-none"><code class="language-none">&lt;?xml version&#x3D;&quot;1.0&quot;?&gt;&lt;!-- 格式: 以前是 1，推荐使用格式 2 --&gt;&lt;package format&#x3D;&quot;2&quot;&gt;  &lt;!-- 包名 --&gt;  &lt;name&gt;demo01_hello_vscode&lt;&#x2F;name&gt;  &lt;!-- 版本 --&gt;  &lt;version&gt;0.0.0&lt;&#x2F;version&gt;  &lt;!-- 描述信息 --&gt;  &lt;description&gt;The demo01_hello_vscode package&lt;&#x2F;description&gt;  &lt;!-- One maintainer tag required, multiple allowed, one person per tag --&gt;  &lt;!-- Example:  --&gt;  &lt;!-- &lt;maintainer email&#x3D;&quot;jane.doe@example.com&quot;&gt;Jane Doe&lt;&#x2F;maintainer&gt; --&gt;  &lt;!-- 维护人员 --&gt;  &lt;maintainer email&#x3D;&quot;xuzuo@todo.todo&quot;&gt;xuzuo&lt;&#x2F;maintainer&gt;  &lt;!-- One license tag required, multiple allowed, one license per tag --&gt;  &lt;!-- Commonly used license strings: --&gt;  &lt;!--   BSD, MIT, Boost Software License, GPLv2, GPLv3, LGPLv2.1, LGPLv3 --&gt;  &lt;!-- 许可证信息，ROS核心组件默认 BSD --&gt;  &lt;license&gt;TODO&lt;&#x2F;license&gt;  &lt;!-- Url tags are optional, but multiple are allowed, one per tag --&gt;  &lt;!-- Optional attribute type can be: website, bugtracker, or repository --&gt;  &lt;!-- Example: --&gt;  &lt;!-- &lt;url type&#x3D;&quot;website&quot;&gt;http:&#x2F;&#x2F;wiki.ros.org&#x2F;demo01_hello_vscode&lt;&#x2F;url&gt; --&gt;  &lt;!-- Author tags are optional, multiple are allowed, one per tag --&gt;  &lt;!-- Authors do not have to be maintainers, but could be --&gt;  &lt;!-- Example: --&gt;  &lt;!-- &lt;author email&#x3D;&quot;jane.doe@example.com&quot;&gt;Jane Doe&lt;&#x2F;author&gt; --&gt;  &lt;!-- The *depend tags are used to specify dependencies --&gt;  &lt;!-- Dependencies can be catkin packages or system dependencies --&gt;  &lt;!-- Examples: --&gt;  &lt;!-- Use depend as a shortcut for packages that are both build and exec dependencies --&gt;  &lt;!--   &lt;depend&gt;roscpp&lt;&#x2F;depend&gt; --&gt;  &lt;!--   Note that this is equivalent to the following: --&gt;  &lt;!--   &lt;build_depend&gt;roscpp&lt;&#x2F;build_depend&gt; --&gt;  &lt;!--   &lt;exec_depend&gt;roscpp&lt;&#x2F;exec_depend&gt; --&gt;  &lt;!-- Use build_depend for packages you need at compile time: --&gt;  &lt;!--   &lt;build_depend&gt;message_generation&lt;&#x2F;build_depend&gt; --&gt;  &lt;!-- Use build_export_depend for packages you need in order to build against this package: --&gt;  &lt;!--   &lt;build_export_depend&gt;message_generation&lt;&#x2F;build_export_depend&gt; --&gt;  &lt;!-- Use buildtool_depend for build tool packages: --&gt;  &lt;!--   &lt;buildtool_depend&gt;catkin&lt;&#x2F;buildtool_depend&gt; --&gt;  &lt;!-- Use exec_depend for packages you need at runtime: --&gt;  &lt;!--   &lt;exec_depend&gt;message_runtime&lt;&#x2F;exec_depend&gt; --&gt;  &lt;!-- Use test_depend for packages you need only for testing: --&gt;  &lt;!--   &lt;test_depend&gt;gtest&lt;&#x2F;test_depend&gt; --&gt;  &lt;!-- Use doc_depend for packages you need only for building documentation: --&gt;  &lt;!--   &lt;doc_depend&gt;doxygen&lt;&#x2F;doc_depend&gt; --&gt;  &lt;!-- 依赖的构建工具，这是必须的 --&gt;  &lt;buildtool_depend&gt;catkin&lt;&#x2F;buildtool_depend&gt;  &lt;!-- 指定构建此软件包所需的软件包 --&gt;  &lt;build_depend&gt;roscpp&lt;&#x2F;build_depend&gt;  &lt;build_depend&gt;rospy&lt;&#x2F;build_depend&gt;  &lt;build_depend&gt;std_msgs&lt;&#x2F;build_depend&gt;  &lt;!-- 指定根据这个包构建库所需要的包 --&gt;  &lt;build_export_depend&gt;roscpp&lt;&#x2F;build_export_depend&gt;  &lt;build_export_depend&gt;rospy&lt;&#x2F;build_export_depend&gt;  &lt;build_export_depend&gt;std_msgs&lt;&#x2F;build_export_depend&gt;  &lt;!-- 运行该程序包中的代码所需的程序包 --&gt;    &lt;exec_depend&gt;roscpp&lt;&#x2F;exec_depend&gt;  &lt;exec_depend&gt;rospy&lt;&#x2F;exec_depend&gt;  &lt;exec_depend&gt;std_msgs&lt;&#x2F;exec_depend&gt;  &lt;!-- The export tag contains other, unspecified, tags --&gt;  &lt;export&gt;    &lt;!-- Other tools can request additional information be placed here --&gt;  &lt;&#x2F;export&gt;&lt;&#x2F;package&gt;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="1-2CMakelists-txt"><a href="#1-2CMakelists-txt" class="headerlink" title="1.2CMakelists.txt"></a>1.2CMakelists.txt</h4><p>​文件<strong>CMakeLists.txt</strong>是CMake构建系统的输入，用于构建软件包。任何兼容CMake的软件包都包含一个或多个CMakeLists.txt文件，这些文件描述了如何构建代码以及将代码安装到何处。</p><pre class="line-numbers language-none"><code class="language-none">cmake_minimum_required(VERSION 3.0.2) #所需 cmake 版本project(demo01_hello_vscode) #包名称，会被 $&#123;PROJECT_NAME&#125; 的方式调用## Compile as C++11, supported in ROS Kinetic and newer# add_compile_options(-std&#x3D;c++11)## Find catkin macros and libraries## if COMPONENTS list like find_package(catkin REQUIRED COMPONENTS xyz)## is used, also find other catkin packages#设置构建所需要的软件包find_package(catkin REQUIRED COMPONENTS  roscpp  rospy  std_msgs)## System dependencies are found with CMake&#39;s conventions#默认添加系统依赖# find_package(Boost REQUIRED COMPONENTS system)## Uncomment this if the package has a setup.py. This macro ensures## modules and global scripts declared therein get installed## See http:&#x2F;&#x2F;ros.org&#x2F;doc&#x2F;api&#x2F;catkin&#x2F;html&#x2F;user_guide&#x2F;setup_dot_py.html# 启动 python 模块支持# catkin_python_setup()################################################## Declare ROS messages, services and actions #### 声明 ROS 消息、服务、动作... #################################################### To declare and build messages, services or actions from within this## package, follow these steps:## * Let MSG_DEP_SET be the set of packages whose message types you use in##   your messages&#x2F;services&#x2F;actions (e.g. std_msgs, actionlib_msgs, ...).## * In the file package.xml:##   * add a build_depend tag for &quot;message_generation&quot;##   * add a build_depend and a exec_depend tag for each package in MSG_DEP_SET##   * If MSG_DEP_SET isn&#39;t empty the following dependency has been pulled in##     but can be declared for certainty nonetheless:##     * add a exec_depend tag for &quot;message_runtime&quot;## * In this file (CMakeLists.txt):##   * add &quot;message_generation&quot; and every package in MSG_DEP_SET to##     find_package(catkin REQUIRED COMPONENTS ...)##   * add &quot;message_runtime&quot; and every package in MSG_DEP_SET to##     catkin_package(CATKIN_DEPENDS ...)##   * uncomment the add_*_files sections below as needed##     and list every .msg&#x2F;.srv&#x2F;.action file to be processed##   * uncomment the generate_messages entry below##   * add every package in MSG_DEP_SET to generate_messages(DEPENDENCIES ...)## Generate messages in the &#39;msg&#39; folder# add_message_files(#   FILES#   Message1.msg#   Message2.msg# )## Generate services in the &#39;srv&#39; folder# add_service_files(#   FILES#   Service1.srv#   Service2.srv# )## Generate actions in the &#39;action&#39; folder# add_action_files(#   FILES#   Action1.action#   Action2.action# )## Generate added messages and services with any dependencies listed here# 生成消息、服务时的依赖包# generate_messages(#   DEPENDENCIES#   std_msgs# )################################################## Declare ROS dynamic reconfigure parameters #### 声明 ROS 动态参数配置 #################################################### To declare and build dynamic reconfigure parameters within this## package, follow these steps:## * In the file package.xml:##   * add a build_depend and a exec_depend tag for &quot;dynamic_reconfigure&quot;## * In this file (CMakeLists.txt):##   * add &quot;dynamic_reconfigure&quot; to##     find_package(catkin REQUIRED COMPONENTS ...)##   * uncomment the &quot;generate_dynamic_reconfigure_options&quot; section below##     and list every .cfg file to be processed## Generate dynamic reconfigure parameters in the &#39;cfg&#39; folder# generate_dynamic_reconfigure_options(#   cfg&#x2F;DynReconf1.cfg#   cfg&#x2F;DynReconf2.cfg# )##################################### catkin specific configuration #### catkin 特定配置####################################### The catkin_package macro generates cmake config files for your package## Declare things to be passed to dependent projects## INCLUDE_DIRS: uncomment this if your package contains header files## LIBRARIES: libraries you create in this project that dependent projects also need## CATKIN_DEPENDS: catkin_packages dependent projects also need## DEPENDS: system dependencies of this project that dependent projects also need# 运行时依赖catkin_package(#  INCLUDE_DIRS include#  LIBRARIES demo01_hello_vscode#  CATKIN_DEPENDS roscpp rospy std_msgs#  DEPENDS system_lib)############# Build ############### Specify additional locations of header files## Your package locations should be listed before other locations# 添加头文件路径，当前程序包的头文件路径位于其他文件路径之前include_directories(# include  $&#123;catkin_INCLUDE_DIRS&#125;)## Declare a C++ library# 声明 C++ 库# add_library($&#123;PROJECT_NAME&#125;#   src&#x2F;$&#123;PROJECT_NAME&#125;&#x2F;demo01_hello_vscode.cpp# )## Add cmake target dependencies of the library## as an example, code may need to be generated before libraries## either from message generation or dynamic reconfigure# 添加库的 cmake 目标依赖# add_dependencies($&#123;PROJECT_NAME&#125; $&#123;$&#123;PROJECT_NAME&#125;_EXPORTED_TARGETS&#125; $&#123;catkin_EXPORTED_TARGETS&#125;)## Declare a C++ executable## With catkin_make all packages are built within a single CMake context## The recommended prefix ensures that target names across packages don&#39;t collide# 声明 C++ 可执行文件add_executable(Hello_VSCode src&#x2F;Hello_VSCode.cpp)## Rename C++ executable without prefix## The above recommended prefix causes long target names, the following renames the## target back to the shorter version for ease of user use## e.g. &quot;rosrun someones_pkg node&quot; instead of &quot;rosrun someones_pkg someones_pkg_node&quot;#重命名c++可执行文件# set_target_properties($&#123;PROJECT_NAME&#125;_node PROPERTIES OUTPUT_NAME node PREFIX &quot;&quot;)## Add cmake target dependencies of the executable## same as for the library above#添加可执行文件的 cmake 目标依赖add_dependencies(Hello_VSCode $&#123;$&#123;PROJECT_NAME&#125;_EXPORTED_TARGETS&#125; $&#123;catkin_EXPORTED_TARGETS&#125;)## Specify libraries to link a library or executable target against#指定库、可执行文件的链接库target_link_libraries(Hello_VSCode  $&#123;catkin_LIBRARIES&#125;)############### Install #### 安装 ################ all install targets should use catkin DESTINATION variables# See http:&#x2F;&#x2F;ros.org&#x2F;doc&#x2F;api&#x2F;catkin&#x2F;html&#x2F;adv_user_guide&#x2F;variables.html## Mark executable scripts (Python etc.) for installation## in contrast to setup.py, you can choose the destination#设置用于安装的可执行脚本catkin_install_python(PROGRAMS  scripts&#x2F;Hi.py  DESTINATION $&#123;CATKIN_PACKAGE_BIN_DESTINATION&#125;)## Mark executables for installation## See http:&#x2F;&#x2F;docs.ros.org&#x2F;melodic&#x2F;api&#x2F;catkin&#x2F;html&#x2F;howto&#x2F;format1&#x2F;building_executables.html# install(TARGETS $&#123;PROJECT_NAME&#125;_node#   RUNTIME DESTINATION $&#123;CATKIN_PACKAGE_BIN_DESTINATION&#125;# )## Mark libraries for installation## See http:&#x2F;&#x2F;docs.ros.org&#x2F;melodic&#x2F;api&#x2F;catkin&#x2F;html&#x2F;howto&#x2F;format1&#x2F;building_libraries.html# install(TARGETS $&#123;PROJECT_NAME&#125;#   ARCHIVE DESTINATION $&#123;CATKIN_PACKAGE_LIB_DESTINATION&#125;#   LIBRARY DESTINATION $&#123;CATKIN_PACKAGE_LIB_DESTINATION&#125;#   RUNTIME DESTINATION $&#123;CATKIN_GLOBAL_BIN_DESTINATION&#125;# )## Mark cpp header files for installation# install(DIRECTORY include&#x2F;$&#123;PROJECT_NAME&#125;&#x2F;#   DESTINATION $&#123;CATKIN_PACKAGE_INCLUDE_DESTINATION&#125;#   FILES_MATCHING PATTERN &quot;*.h&quot;#   PATTERN &quot;.svn&quot; EXCLUDE# )## Mark other files for installation (e.g. launch and bag files, etc.)# install(FILES#   # myfile1#   # myfile2#   DESTINATION $&#123;CATKIN_PACKAGE_SHARE_DESTINATION&#125;# )############### Testing ################# Add gtest based cpp test target and link libraries# catkin_add_gtest($&#123;PROJECT_NAME&#125;-test test&#x2F;test_demo01_hello_vscode.cpp)# if(TARGET $&#123;PROJECT_NAME&#125;-test)#   target_link_libraries($&#123;PROJECT_NAME&#125;-test $&#123;PROJECT_NAME&#125;)# endif()## Add folders to be run by python nosetests# catkin_add_nosetests(test)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> Tutorial </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ROS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MMDetection入门教程</title>
      <link href="/2023/03/08/mmdetection-ru-men-jiao-cheng/"/>
      <url>/2023/03/08/mmdetection-ru-men-jiao-cheng/</url>
      
        <content type="html"><![CDATA[<p><img src="/./images/MMdetection%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/0.png"></p><p>​网上MMDetection教程很多，但是都不成系统，比较杂乱，看完一圈下来都还不知道MMDetection怎么使用。这里总结推荐几个比较有用的学习教程。</p><blockquote><ul><li><strong>官方经验参考</strong></li><li><a href="https://mmcv.readthedocs.io/en/latest/understand_mmcv/config.html">官方教程-MMCV</a></li><li><a href="https://mmdetection.readthedocs.io/en/v2.17.0/tutorials/config.html">官方教程-MMDetection</a></li><li><a href="https://zhuanlan.zhihu.com/p/369826931">官方教程 - 不得不知的 MMDetection 学习路线(个人经验版)</a></li><li><a href="https://www.bilibili.com/video/BV1Jb4y1r7ir?spm_id_from=333.999.0.0">西安交大课件 - mmdetection教程(使用篇)</a></li><li><strong>个人经验参考</strong></li><li><a href="https://blog.csdn.net/qq_16137569/article/details/120924726?spm=1001.2014.3001.5501">MMDetection框架入门教程（一）：Anaconda3下的安装教程（mmdet+mmdet3d）</a></li><li><a href="https://blog.csdn.net/qq_16137569/article/details/120929852?spm=1001.2014.3001.5501">MMDetection框架入门教程（二）：快速上手教程</a></li><li><a href="https://blog.csdn.net/qq_16137569/article/details/121188974?spm=1001.2014.3001.5501">MMDetection框架入门教程（三）：配置文件详细解析</a></li><li><a href="https://blog.csdn.net/qq_16137569/article/details/121216363?spm=1001.2014.3001.5501">MMDetection框架入门教程（四）：注册机制详解</a></li><li><a href="https://blog.csdn.net/qq_16137569/article/details/121195529">MMDetection框架入门教程（五）：Runner和Hook详细解析</a></li></ul></blockquote><h3 id="1-框架概述"><a href="#1-框架概述" class="headerlink" title="1.框架概述"></a>1.框架概述</h3><h4 id="1-1Pytorch"><a href="#1-1Pytorch" class="headerlink" title="1.1Pytorch"></a>1.1Pytorch</h4><p>​如果使用Pytorch框架构建一个算法，通常实现的步骤如下：</p><ul><li><strong>构建数据集</strong>：新建一个类，并继承<code>Dataset</code>类，重写<code>__getitem__()</code>方法实现数据和标签的加载和遍历功能，并以pipeline的方式定义数据预处理流程</li><li><strong>构建数据加载器</strong>：传入相应的参数实例化DataLoader</li><li><strong>构建模型</strong>：新建一个类，并继承<code>Module</code>类，重写<code>forward()</code>函数定义模型的前向过程</li><li><strong>定义损失函数和优化器</strong>：根据算法选择合适和损失函数和优化器</li><li><strong>训练和验证</strong>：循环从DataLoader中获取数据和标签，送入网络模型，计算loss，根据反传的梯度使用优化器进行迭代优化</li><li><strong>其他操作</strong>：在主调函数里可以任意穿插训练Tricks、日志打印、检查点保存等操作</li></ul><h4 id="2-1MMDetection"><a href="#2-1MMDetection" class="headerlink" title="2.1MMDetection"></a>2.1MMDetection</h4><p>​如果使用MMDetection构建一个算法，通常的实现步骤如下：</p><ul><li><strong>注册数据集</strong>：<code>CustomDataset</code>是MMDetection在原始的<code>Dataset</code>基础上的再次封装，其<code>__getitem__()</code>方法会根据训练和测试模式分别重定向到<code>prepare_train_img()</code>和<code>prepare_test_img()</code>函数。用户以继承<code>CustomDataset</code>类的方式构建自己的数据集时，需要重写<code>load_annotations()</code>和<code>get_ann_info()</code>函数，定义数据和标签的加载及遍历方式。完成数据集类的定义后，还需要使用<code>DATASETS.register_module()</code>进行模块注册。</li><li><strong>注册模型</strong>：模型构建的方式和Pytorch类似，都是新建一个<code>Module</code>的子类然后重写<code>forward()</code>函数。唯一的区别在于MMDetection中需要继承<code>BaseModule</code>而不是<code>Module</code>，<code>BaseModule</code>是<code>Module</code>的子类，MMLab中的任何模型都必须继承此类。另外，MMDetection将一个完整的模型拆分为backbone、neck和head三部分进行管理，所以用户需要按照这种方式，将算法模型拆解成3个类，分别使用<code>BACKBONES.register_module()</code>、<code>NECKS.register_module()</code>和<code>HEADS.register_module()</code>完成模块注册。</li><li><strong>构建配置文件</strong>：配置文件用于配置算法各个组件的运行参数，大体上可以包含四个部分：datasets、models、schedules和runtime。完成相应模块的定义和注册后，在配置文件中配置好相应的运行参数，然后MMDetection就会通过<code>Registry</code>类读取并解析配置文件，完成模块的实例化。另外，配置文件可以通过<code>_base_</code>字段实现继承功能，以提高代码复用率。</li><li><strong>训练和验证</strong>：在完成各模块的代码实现、模块的注册、配置文件的编写后，就可以使用<code>./tools/train.py</code>和<code>./tools/test.py</code>对模型进行训练和验证，不需要用户编写额外的代码。</li></ul><h4 id="1-3流程对比"><a href="#1-3流程对比" class="headerlink" title="1.3流程对比"></a>1.3流程对比</h4><p><img src="/./images/MMdetection%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/1.png"></p><h3 id="2-算法的实现流程"><a href="#2-算法的实现流程" class="headerlink" title="2.算法的实现流程"></a>2.算法的实现流程</h3><h4 id="2-1注册数据集"><a href="#2-1注册数据集" class="headerlink" title="2.1注册数据集"></a>2.1注册数据集</h4><p>​定义自己的数据集时，需要新写一个继承<code>CustomDataset</code>的Dataset类，然后重写<code>load_annotations()</code>函数和<code>get_ann_info()</code>函数。官方文档上说，用户如果要使用<code>CustomDataset</code>，要将现有数据集转换成MMDetection兼容的格式(COCO格式或中间格式) 。但是仔细研究发现底层的代码并没有发现有这个限制，只要你的数据格式能和你实现的<code>load_annotations()</code>和<code>get_ann_info()</code>对应上即可。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token triple-quoted-string string">"""中间数据格式：[    &#123;        'filename': 'a.jpg',# 图片路径        'width': 1280,# 图片尺寸        'height': 720,        'ann': &#123;# 标注信息            'bboxes': &lt;np.ndarray, float32> (n, 4),# 标注框坐标(x1, y1, x2, y2)            'labels': &lt;np.ndarray, int64> (n, ),# 标注框类别            'bboxes_ignore': &lt;np.ndarray, float32> (k, 4),# 不关注的标注框坐标(可选)            'labels_ignore': &lt;np.ndarray, int64> (k, ) # 不关注的标注框类别(可选)        &#125;    &#125;,    ...]"""</span><span class="token keyword">class</span> <span class="token class-name">CustomDataset</span><span class="token punctuation">(</span>Dataset<span class="token punctuation">)</span><span class="token punctuation">:</span>    CLASSES <span class="token operator">=</span> <span class="token boolean">None</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>                 ann_file<span class="token punctuation">,</span><span class="token comment"># 文件路径</span>                 pipeline<span class="token punctuation">,</span><span class="token comment"># 数据预处理pipeline</span>                 classes<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span><span class="token comment"># 检测类别</span>                 data_root<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span><span class="token comment"># 文件根路径</span>                 img_prefix<span class="token operator">=</span><span class="token string">''</span><span class="token punctuation">,</span>                 seg_prefix<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span>                 proposal_file<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span>                 test_mode<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span><span class="token comment"># 为True的话将不会加载标注信息</span>                 filter_empty_gt<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token comment"># 为True的话将会过滤没有标注框的图像(只在test_mode=False的条件下有效)</span>        self<span class="token punctuation">.</span>ann_file <span class="token operator">=</span> ann_file        self<span class="token punctuation">.</span>data_root <span class="token operator">=</span> data_root        self<span class="token punctuation">.</span>img_prefix <span class="token operator">=</span> img_prefix        self<span class="token punctuation">.</span>seg_prefix <span class="token operator">=</span> seg_prefix        self<span class="token punctuation">.</span>proposal_file <span class="token operator">=</span> proposal_file        self<span class="token punctuation">.</span>test_mode <span class="token operator">=</span> test_mode        self<span class="token punctuation">.</span>filter_empty_gt <span class="token operator">=</span> filter_empty_gt        self<span class="token punctuation">.</span>CLASSES <span class="token operator">=</span> self<span class="token punctuation">.</span>get_classes<span class="token punctuation">(</span>classes<span class="token punctuation">)</span>                <span class="token comment"># 调用load_annotations函数加载样本和标签</span>        self<span class="token punctuation">.</span>data_infos <span class="token operator">=</span> self<span class="token punctuation">.</span>load_annotations<span class="token punctuation">(</span>self<span class="token punctuation">.</span>ann_file<span class="token punctuation">)</span>        <span class="token comment"># 用户可以通过重写_filter_imgs()函数在训练过程中实现自定义的样本过滤功能</span>        <span class="token keyword">if</span> <span class="token keyword">not</span> test_mode<span class="token punctuation">:</span>            valid_inds <span class="token operator">=</span> self<span class="token punctuation">.</span>_filter_imgs<span class="token punctuation">(</span><span class="token punctuation">)</span>            self<span class="token punctuation">.</span>data_infos <span class="token operator">=</span> <span class="token punctuation">[</span>self<span class="token punctuation">.</span>data_infos<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> valid_inds<span class="token punctuation">]</span>        <span class="token comment"># 根据pipeline对样本进行预处理</span>        self<span class="token punctuation">.</span>pipeline <span class="token operator">=</span> Compose<span class="token punctuation">(</span>pipeline<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>​在Pytorch中<code>Dataset</code>的遍历是通过重写<code>__getitem__()</code>函数实现的，但MMDetection的<code>CustomDataset</code>虽然是<code>Dataset</code>的子类，却没有要求我们重写<code>__getitem__()</code>函数，原因是为了方便训练模式和测试模式下的数据管理，MMDetection已经重写了<code>__getitem__()</code>函数，可以根据当前运行模式调用<code>prepare_train_img()</code>或<code>prepare_test_img()</code>，两者的区别在于是否加载训练标签。所以我们只需要重写<code>load_annotations()</code>和<code>get_ann_info()</code>函数，剩下的部分交给MMDetection就可以了。完成自定义的Dataset类后别忘记加上<code>@DATASETS.register_module()</code>将当前模块注册到DATASETS表中。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">__getitem__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> idx<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">if</span> self<span class="token punctuation">.</span>test_mode<span class="token punctuation">:</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>prepare_test_img<span class="token punctuation">(</span>idx<span class="token punctuation">)</span>    <span class="token keyword">else</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>prepare_train_img<span class="token punctuation">(</span>idx<span class="token punctuation">)</span><span class="token comment"># 返回预处理后的训练样本及标签        </span><span class="token keyword">def</span> <span class="token function">prepare_train_img</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> idx<span class="token punctuation">)</span><span class="token punctuation">:</span>    img_info <span class="token operator">=</span> self<span class="token punctuation">.</span>data_infos<span class="token punctuation">[</span>idx<span class="token punctuation">]</span>    <span class="token comment"># 调用get_ann_info获取训练标签</span>    ann_info <span class="token operator">=</span> self<span class="token punctuation">.</span>get_ann_info<span class="token punctuation">(</span>idx<span class="token punctuation">)</span>    results <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span>img_info<span class="token operator">=</span>img_info<span class="token punctuation">,</span> ann_info<span class="token operator">=</span>ann_info<span class="token punctuation">)</span>    <span class="token keyword">return</span> self<span class="token punctuation">.</span>pipeline<span class="token punctuation">(</span>results<span class="token punctuation">)</span><span class="token comment"># 返回预处理后的测试样本</span><span class="token keyword">def</span> <span class="token function">prepare_test_img</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> idx<span class="token punctuation">)</span><span class="token punctuation">:</span>    img_info <span class="token operator">=</span> self<span class="token punctuation">.</span>data_infos<span class="token punctuation">[</span>idx<span class="token punctuation">]</span>    results <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span>img_info<span class="token operator">=</span>img_info<span class="token punctuation">)</span>    <span class="token keyword">return</span> self<span class="token punctuation">.</span>pipeline<span class="token punctuation">(</span>results<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="2-2注册模型"><a href="#2-2注册模型" class="headerlink" title="2.2注册模型"></a>2.2注册模型</h4><p>​网络模型的定义比较简单，相比Pytorch只有两个区别：①继承的父类从<code>Module</code>变成了<code>BaseModule</code>；②需要按照backbone、neck和head的结构将模型拆解成3个部分，分别定义并注册到<code>BACKBONES</code>、<code>NECKS</code>以及<code>HEADS</code>当中。</p><h4 id="2-3构建配置文件"><a href="#2-3构建配置文件" class="headerlink" title="2.3构建配置文件"></a>2.3构建配置文件</h4><h5 id="2-3-1配置文件的构成"><a href="#2-3-1配置文件的构成" class="headerlink" title="2.3.1配置文件的构成"></a>2.3.1配置文件的构成</h5><p>​配置文件是由一系列变量定义组成的文本文件，其中<code>dict</code>类型的变量表示一个个的模块，<code>dict</code>变量必须包含<code>type</code>字段，表示模块名称，<strong>其它字段则和模块构造函数的参数一一对应</strong>，届时用于该模块的初始化（见第本文3章的<code>build_from_cfg()</code>函数）。该模块必须是已经注册的，否则后续MMDetection无法根据<code>type</code>值找到对应的模块。配置文件除了<code>dict</code>类型的变量以外，还可以是其他任意类型，一般是辅助<code>dict</code>变量定义的中间变量，比如：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">test_pipeline <span class="token operator">=</span> <span class="token punctuation">[</span>    <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'LoadMultiViewImageFromFiles'</span><span class="token punctuation">,</span> to_float32<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'NormalizeMultiviewImage'</span><span class="token punctuation">,</span> <span class="token operator">**</span>img_norm_cfg<span class="token punctuation">)</span><span class="token punctuation">,</span>    <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'PadMultiViewImage'</span><span class="token punctuation">,</span> size_divisor<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">]</span>evaluation <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span>interval<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> pipeline<span class="token operator">=</span>test_pipeline<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>​配置文件也支持继承操作，通过<code>_base_</code>变量来实现。<code>_base_</code>是一个<code>list</code>类型变量，里面存储的是要继承的配置文件的路径。在解析配置文件的时候，文件解析器以递归的方式(其他配置文件也可能包含<code>_base_</code>变量)解析所有配置文件。任何配置文件往上追溯都会继承以下四个文件，分别对应数据集(datasets)、模型(models)、训练策略(schedules)和运行时的默认配置(default_runtime)：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">_base_ <span class="token operator">=</span> <span class="token punctuation">[</span>    <span class="token string">'mmdetection/configs/_base_/models/fast_rcnn_r50_fpn.py'</span><span class="token punctuation">,</span><span class="token comment"># models</span>    <span class="token string">'mmdetection/configs/_base_/datasets/coco_detection.py'</span><span class="token punctuation">,</span><span class="token comment"># datasets</span>    <span class="token string">'mmdetection/configs/_base_/schedules/schedule_1x.py'</span><span class="token punctuation">,</span><span class="token comment"># schedules</span>    <span class="token string">'mmdetection/configs/_base_/default_runtime.py'</span><span class="token punctuation">,</span><span class="token comment"># defualt_runtime</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>​如果你对上面继承这4个基础配置文件的配置文件进行打印，可以看到如下内容，这也是<strong>任何一个完整配置文件都应该包含的配置信息</strong>。当然，你也可以任意增加自定义的配置信息。所以我们平常新建一个配置文件的时候，一般都是继承这4个基础配置文件，然后在此基础上进行针对性调整。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 1. 模型配置(models) =========================================</span>model <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'FastRCNN'</span><span class="token punctuation">,</span><span class="token comment"># 模型名称是FastRCNN</span>backbone<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token comment"># BackBone是ResNet</span>        <span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'ResNet'</span><span class="token punctuation">,</span>        <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span>    <span class="token punctuation">)</span><span class="token punctuation">,</span>    neck<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token comment"># Neck是FPN</span>        <span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'FPN'</span><span class="token punctuation">,</span>        <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span>    <span class="token punctuation">)</span><span class="token punctuation">,</span>    roi_head<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token comment"># Head是StandardRoIHead</span>        <span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'StandardRoIHead'</span><span class="token punctuation">,</span>        <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span>        loss_cls<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token comment"># 分类损失函数</span>        loss_bbox<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token comment"># 回归损失函数</span>    <span class="token punctuation">)</span><span class="token punctuation">,</span>    train_cfg<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token comment"># 训练参数配置</span>    assigner<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token comment"># BBox Assigner</span>    sampler<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token comment"># BBox Sampler</span>    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    test_cfg <span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token comment"># 测试参数配置</span>    nms<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token comment"># NMS后处理</span>    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span>    <span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment"># 2. 数据集配置(datasets) =========================================</span>dataset_type <span class="token operator">=</span> <span class="token string">'...'</span><span class="token comment"># 数据集名称</span>data_root <span class="token operator">=</span> <span class="token string">'...'</span><span class="token comment"># 数据集根目录</span>img_norm_cfg <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token comment"># 图像归一化参数</span>train_pipeline <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token comment"># 训练数据处理Pipeline</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span><span class="token punctuation">]</span>test_pipeline <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token comment"># 测试数据处理Pipeline</span>data <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span>samples_per_gpu<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token comment"># batch_size</span>    workers_per_gpu<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token comment"># GPU数量</span>train<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token comment"># 训练集配置</span><span class="token builtin">type</span><span class="token operator">=</span>dataset_type<span class="token punctuation">,</span>        ann_file<span class="token operator">=</span>data_root <span class="token operator">+</span> <span class="token string">'annotations/instances_train2017.json'</span><span class="token punctuation">,</span><span class="token comment"># 标注问加你</span>        img_prefix<span class="token operator">=</span>data_root <span class="token operator">+</span> <span class="token string">'train2017/'</span><span class="token punctuation">,</span><span class="token comment"># 图像前缀</span>pipline<span class="token operator">=</span>trian_pipline<span class="token punctuation">,</span><span class="token comment"># 数据预处理pipeline</span><span class="token punctuation">)</span><span class="token punctuation">,</span>val<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token comment"># 验证集配置</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span>pipline<span class="token operator">=</span>test_pipline<span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">,</span>test<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token comment"># 测试集配置</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span>pipline<span class="token operator">=</span>test_pipline<span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment"># 3. 训练策略配置(schedules) =========================================</span>evaluation <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span>interval<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> metric<span class="token operator">=</span><span class="token string">'bbox'</span><span class="token punctuation">)</span>optimizer <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'SGD'</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.02</span><span class="token punctuation">,</span> momentum<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">,</span> weight_decay<span class="token operator">=</span><span class="token number">0.0001</span><span class="token punctuation">)</span>optimizer_config <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span>grad_clip<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span>lr_config <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span>    policy<span class="token operator">=</span><span class="token string">'step'</span><span class="token punctuation">,</span>    warmup<span class="token operator">=</span><span class="token string">'linear'</span><span class="token punctuation">,</span>    warmup_iters<span class="token operator">=</span><span class="token number">500</span><span class="token punctuation">,</span>    warmup_ratio<span class="token operator">=</span><span class="token number">0.001</span><span class="token punctuation">,</span>    step<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">11</span><span class="token punctuation">]</span><span class="token punctuation">)</span>runner <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'EpochBasedRunner'</span><span class="token punctuation">,</span> max_epochs<span class="token operator">=</span><span class="token number">12</span><span class="token punctuation">)</span><span class="token comment"># 4. 运行配置(runtime) =========================================</span>checkpoint_config <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span>interval<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>log_config <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span>interval<span class="token operator">=</span><span class="token number">50</span><span class="token punctuation">,</span> hooks<span class="token operator">=</span><span class="token punctuation">[</span><span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'TextLoggerHook'</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>custom_hooks <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'NumClassCheckHook'</span><span class="token punctuation">)</span><span class="token punctuation">]</span>dist_params <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span>backend<span class="token operator">=</span><span class="token string">'nccl'</span><span class="token punctuation">)</span>log_level <span class="token operator">=</span> <span class="token string">'INFO'</span>load_from <span class="token operator">=</span> <span class="token boolean">None</span>resume_from <span class="token operator">=</span> <span class="token boolean">None</span>workflow <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token string">'train'</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>​另外还有一些可选的配置参数，比如<code>custom_imports</code>，用于导入用户自定义的模块，当配置文件解析器解析到该字段时，会调用<code>import_modules_from_strings()</code>函数将字段<code>imports</code>包含的模块导入到程序中。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">custom_imports <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span>imports<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'os.path'</span><span class="token punctuation">,</span> <span class="token string">'numpy'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token comment"># list类型, 需要导入的模块名称</span>  allow_failed_imports<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token comment"># 如果设为True, 导入失败时会返回None而不是报错</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h5 id="2-3-2配置文件的修改"><a href="#2-3-2配置文件的修改" class="headerlink" title="2.3.2配置文件的修改"></a>2.3.2配置文件的修改</h5><p>​修改配置文件时会遇到2种情况：①修改已有dict的某个参数：直接重写对应的参数；②需要删掉原有dict的所有参数，然后用一组全新的参数代替：增加<code>_delete_=True</code>字段以修改学习率和更换优化器为例解释这两种情况下应该怎么修改配置文件：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 从_base_中继承的原始优化器</span>optimizer <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'SGD'</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.02</span><span class="token punctuation">,</span> momentum<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">,</span> weight_decay<span class="token operator">=</span><span class="token number">0.0001</span><span class="token punctuation">)</span><span class="token comment"># 修改学习率</span>optimizer <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span>lr<span class="token operator">=</span><span class="token number">0.001</span><span class="token punctuation">)</span><span class="token comment"># 修改后optimizer变成</span>optimizer <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'SGD'</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.001</span><span class="token punctuation">,</span> momentum<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">,</span> weight_decay<span class="token operator">=</span><span class="token number">0.0001</span><span class="token punctuation">)</span><span class="token comment"># 将原来的SGD替换成AdamW</span>optimizer <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span>_delete_<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'AdamW'</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.0001</span><span class="token punctuation">,</span> weight_decay<span class="token operator">=</span><span class="token number">0.0001</span><span class="token punctuation">)</span>  <span class="token comment"># 替换后optimizer变成</span>optimizer <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'AdamW'</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.0001</span><span class="token punctuation">,</span> weight_decay<span class="token operator">=</span><span class="token number">0.0001</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h5 id="2-3-3配置文件的解析"><a href="#2-3-3配置文件的解析" class="headerlink" title="2.3.3配置文件的解析"></a>2.3.3配置文件的解析</h5><p>​解析配置文件其实是train.py和test.py要做的事，这里放到和构建配置文件一块讲了，逻辑上会更通畅一些。一般使用Config类来管理配置文件。使用<code>Config.fromfile(filename)</code>来读取配置文件（也可以直接传入一个dict），返回一个Config类实例cfg，然后可以通过<code>print(cfg.pretty_text)</code>的方式来打印配置文件信息，或者通过<code>cfg.dump(filepath)</code>来保存配置文件信息。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> mmcv <span class="token keyword">import</span> Configcfg <span class="token operator">=</span> Config<span class="token punctuation">.</span>fromfile<span class="token punctuation">(</span><span class="token string">'../configs/test_config.py'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>​<code>fromfile()</code>函数源码如下，其核心函数是<code>_file2dict()</code>。<code>_file2dict()</code>会根据文本顺序，按照key &#x3D; value的格式解析配置文件，得到一个名为<code>cfg_dict</code>的字典，如果存在<code>_base_</code>字段，还会对<code>_base_</code>包含的每个文件路径再调用一次<code>_file2dict()</code>函数，将文件中包含的配置参数加入到<code>cfg_dict</code>中，实现配置文件的<strong>继承</strong>功能。需要注意的是，<code>_file2dict()</code>内部会对<code>_base_</code>中不同文件包含的键值进行校验，<strong>不同基础配置文件中不允许出现重复的键值</strong>，否则Config不知道以哪个配置文件为准。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">fromfile</span><span class="token punctuation">(</span>filename<span class="token punctuation">,</span>             use_predefined_variables<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>             import_custom_modules<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    cfg_dict<span class="token punctuation">,</span> cfg_text <span class="token operator">=</span> Config<span class="token punctuation">.</span>_file2dict<span class="token punctuation">(</span>filename<span class="token punctuation">,</span>                                           use_predefined_variables<span class="token punctuation">)</span>    <span class="token comment"># import_modules_from_strings()是根据字符串列表导入对应的模块</span>    <span class="token keyword">if</span> import_custom_modules <span class="token keyword">and</span> cfg_dict<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">'custom_imports'</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        import_modules_from_strings<span class="token punctuation">(</span><span class="token operator">**</span>cfg_dict<span class="token punctuation">[</span><span class="token string">'custom_imports'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> Config<span class="token punctuation">(</span>cfg_dict<span class="token punctuation">,</span> cfg_text<span class="token operator">=</span>cfg_text<span class="token punctuation">,</span> filename<span class="token operator">=</span>filename<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>​另外有两点需要补充一下，其一是构造Config对象的时候，会将python的<code>dict</code>数据类型转换为<code>ConfigDict</code>类型进行处理。<code>ConfigDict</code>是第三方库addict中<code>Dict</code>的子类(<code>Dict</code>又是python<code>dict</code>的子类)，因为python原生的<code>dict</code>类型不支持<code>.属性</code>的访问方式，特别是<code>dict</code>内部嵌套了多层dict的时候，如果按照key的访问方式，代码写起来非常低效，而<code>Dict</code>类通过重写<code>__getattr__()</code>的方式实现了<code>.属性</code>的访问方式。所以继承了<code>Dict</code>的<code>ConfigDict</code>也支持使用<code>.属性</code>的方式访问字典中的各个成员值。其二，为了兼容配置文件名中出现小数点的情况，<code>_file2dict()</code>会在C盘下创建一个临时文件夹进行操作，如果C盘有访问权限设置，可能会出现报错，不过这个问题只会出现在Windows系统下。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> mmcv <span class="token keyword">import</span> ConfigDictmodel <span class="token operator">=</span> ConfigDict<span class="token punctuation">(</span><span class="token builtin">dict</span><span class="token punctuation">(</span>backbone<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'ResNet'</span><span class="token punctuation">,</span> depth<span class="token operator">=</span><span class="token number">50</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>model<span class="token punctuation">.</span>backbone<span class="token punctuation">.</span><span class="token builtin">type</span><span class="token punctuation">)</span><span class="token comment"># 输出 'ResNet'</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="2-4训练和测试"><a href="#2-4训练和测试" class="headerlink" title="2.4训练和测试"></a>2.4训练和测试</h4><p>​用MMDetection实现一个算法包含四个步骤，第一第二步注册数据集和模型的目的是构建基础模块（数据流和模型），第三步构建配置文件的目的是指定需要的模块以及模块的输入参数，接下来第四步就是根据配置文件把事先定义好的模块一个个拎出来，传入指定的输入参数，然后按照算法流程依次串起来。</p><h5 id="2-4-1train-py文件"><a href="#2-4-1train-py文件" class="headerlink" title="2.4.1train.py文件"></a>2.4.1train.py文件</h5><p>​我们先过一遍官方提供的<code>train.py</code>代码(我只保留了核心功能代码)，然后再介绍MMDetection是如何使用Runner和Hook来调度整个训练流程的，这样理解起来会更快一些。</p><p>​<code>train.py</code>的主调函数做了4件事情，一个是利用Config类对我们第三步构建好的配置文件进行解析，然后对模型和数据集进行初始化，最后将模型和数据集传入<code>train_detector()</code>函数，准备开始训练流程。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token comment"># Step1: 解析配置文件, args.config是配置文件路径(如何解析配置文件可以参考本文4.3.3节)</span>cfg <span class="token operator">=</span> Config<span class="token punctuation">.</span>fromfile<span class="token punctuation">(</span>args<span class="token punctuation">.</span>config<span class="token punctuation">)</span><span class="token comment"># Step2: 初始化模型, 函数内部调用的是DETECTORS.build(cfg)</span>model <span class="token operator">=</span> build_detector<span class="token punctuation">(</span>cfg<span class="token punctuation">.</span>model<span class="token punctuation">)</span>    <span class="token comment"># 初始化模型权重</span>    model<span class="token punctuation">.</span>init_weights<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># Step3: 初始化训练集和验证集, 函数内部调用build_from_cfg(cfg, DATASETS), 等价于DATASETS.build(cfg)</span>datasets <span class="token operator">=</span> <span class="token punctuation">[</span>build_dataset<span class="token punctuation">(</span>cfg<span class="token punctuation">.</span>data<span class="token punctuation">.</span>train<span class="token punctuation">)</span><span class="token punctuation">]</span>    <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>cfg<span class="token punctuation">.</span>workflow<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">2</span><span class="token punctuation">:</span>        val_dataset <span class="token operator">=</span> copy<span class="token punctuation">.</span>deepcopy<span class="token punctuation">(</span>cfg<span class="token punctuation">.</span>data<span class="token punctuation">.</span>val<span class="token punctuation">)</span>        val_dataset<span class="token punctuation">.</span>pipeline <span class="token operator">=</span> cfg<span class="token punctuation">.</span>data<span class="token punctuation">.</span>train<span class="token punctuation">.</span>pipeline <span class="token comment"># 验证集在训练过程中使用train pipeline而不是test pipeline</span>        datasets<span class="token punctuation">.</span>append<span class="token punctuation">(</span>build_dataset<span class="token punctuation">(</span>val_dataset<span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token comment"># Step4: 传入模型和数据集, 准备开始训练模型</span>    train_detector<span class="token punctuation">(</span>model<span class="token punctuation">,</span> datasets<span class="token punctuation">,</span> cfg<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>​<code>train_detector()</code>函数主要是构建了dataloader，初始化了优化器以及runner和hooks，最后调用runner.run开始正式的迭代训练流程。其中涉及到了Runner的概念，不过这里先不展开，我们只要知道Runner也是一个模块，负责模型的迭代训练。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">train_detector</span><span class="token punctuation">(</span>model<span class="token punctuation">,</span> dataset<span class="token punctuation">,</span> cfg<span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token comment"># 获取Runner类型, EpochBasedRunner或IterBasedRuner</span>runner_type <span class="token operator">=</span> <span class="token string">'EpochBasedRunner'</span> <span class="token keyword">if</span> <span class="token string">'runner'</span> <span class="token keyword">not</span> <span class="token keyword">in</span> cfg <span class="token keyword">else</span> cfg<span class="token punctuation">.</span>runner<span class="token punctuation">[</span><span class="token string">'type'</span><span class="token punctuation">]</span><span class="token comment"># Step1: 获取dataloader, 因为dataset列表里包含了训练集和验证集, 所以使用for循环的方式构建dataloader</span><span class="token comment"># build_dataloader()会用DataLoader类进行dataloader的初始化</span>    data_loaders <span class="token operator">=</span> <span class="token punctuation">[</span>        build_dataloader<span class="token punctuation">(</span>            ds<span class="token punctuation">,</span>            cfg<span class="token punctuation">.</span>data<span class="token punctuation">.</span>samples_per_gpu<span class="token punctuation">,</span><span class="token comment"># batch_size</span>            runner_type<span class="token operator">=</span>runner_type<span class="token punctuation">)</span> <span class="token keyword">for</span> ds <span class="token keyword">in</span> dataset    <span class="token punctuation">]</span><span class="token comment"># Step2: 封装模型, 为了进行分布式训练</span>model <span class="token operator">=</span> MMDataParallel<span class="token punctuation">(</span>model<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span>cfg<span class="token punctuation">.</span>gpu_ids<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> device_ids<span class="token operator">=</span>cfg<span class="token punctuation">.</span>gpu_ids<span class="token punctuation">)</span><span class="token comment"># Step3: 初始化优化器</span>optimizer <span class="token operator">=</span> build_optimizer<span class="token punctuation">(</span>model<span class="token punctuation">,</span> cfg<span class="token punctuation">.</span>optimizer<span class="token punctuation">)</span><span class="token comment"># Step4: 初始化Runner</span>runner <span class="token operator">=</span> build_runner<span class="token punctuation">(</span>        cfg<span class="token punctuation">.</span>runner<span class="token punctuation">,</span>        default_args<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span>model<span class="token operator">=</span>model<span class="token punctuation">,</span> optimizer<span class="token operator">=</span>optimizer<span class="token punctuation">)</span><span class="token comment"># Step5: 注册默认Hook(注册到runner._hooks列表中)</span>runner<span class="token punctuation">.</span>register_training_hooks<span class="token punctuation">(</span>cfg<span class="token punctuation">.</span>lr_config<span class="token punctuation">,</span> optimizer_config<span class="token punctuation">,</span>                                   cfg<span class="token punctuation">.</span>checkpoint_config<span class="token punctuation">,</span> cfg<span class="token punctuation">.</span>log_config<span class="token punctuation">,</span>                                   cfg<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">'momentum_config'</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment"># Step6: 注册自定义Hook(注册到runner._hooks列表中)</span> <span class="token keyword">if</span> cfg<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">'custom_hooks'</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        custom_hooks <span class="token operator">=</span> cfg<span class="token punctuation">.</span>custom_hooks        <span class="token keyword">for</span> hook_cfg <span class="token keyword">in</span> cfg<span class="token punctuation">.</span>custom_hooks<span class="token punctuation">:</span>            hook_cfg <span class="token operator">=</span> hook_cfg<span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span>            priority <span class="token operator">=</span> hook_cfg<span class="token punctuation">.</span>pop<span class="token punctuation">(</span><span class="token string">'priority'</span><span class="token punctuation">,</span> <span class="token string">'NORMAL'</span><span class="token punctuation">)</span>            hook <span class="token operator">=</span> build_from_cfg<span class="token punctuation">(</span>hook_cfg<span class="token punctuation">,</span> HOOKS<span class="token punctuation">)</span>            runner<span class="token punctuation">.</span>register_hook<span class="token punctuation">(</span>hook<span class="token punctuation">,</span> priority<span class="token operator">=</span>priority<span class="token punctuation">)</span><span class="token comment"># Step7: 开始训练流程</span>    <span class="token keyword">if</span> cfg<span class="token punctuation">.</span>resume_from<span class="token punctuation">:</span>    <span class="token comment"># 恢复检查点</span>        runner<span class="token punctuation">.</span>resume<span class="token punctuation">(</span>cfg<span class="token punctuation">.</span>resume_from<span class="token punctuation">)</span>    <span class="token keyword">elif</span> cfg<span class="token punctuation">.</span>load_from<span class="token punctuation">:</span>    <span class="token comment"># 加载预训练模型</span>        runner<span class="token punctuation">.</span>load_checkpoint<span class="token punctuation">(</span>cfg<span class="token punctuation">.</span>load_from<span class="token punctuation">)</span>    <span class="token comment"># 调用run()方法, 开始迭代过程</span>    runner<span class="token punctuation">.</span>run<span class="token punctuation">(</span>data_loaders<span class="token punctuation">,</span> cfg<span class="token punctuation">.</span>workflow<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>​虽然官方<code>train.py</code>文件写的很长，但是把核心代码扒出来一看，其实都是我们在Pytorch中熟悉的操作。整个train.py的流程如下图所示。</p><p><img src="/./images/MMdetection%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/2.png"></p><h5 id="2-4-2Runner类"><a href="#2-4-2Runner类" class="headerlink" title="2.4.2Runner类"></a>2.4.2Runner类</h5><p>​Runner分为<strong>EpochBasedRunner</strong>和<strong>IterBasedRunner</strong>，顾名思义，前者以epoch的方式管理流程，后者以iter的方式管理流程，它们都是BaseRunner的子类。EpochBasedRunner和IterBasedRunner本身没有重写构造函数，直接继承了BaseRunner的构造函数：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">BaseRunner</span><span class="token punctuation">(</span>metaclass<span class="token operator">=</span>ABCMeta<span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>                 model<span class="token punctuation">,</span><span class="token comment"># [torch.nn.Module] 要运行的模型</span>                 batch_processor<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span><span class="token comment"># 该参数一般不使用</span>                 optimizer<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span><span class="token comment"># [torch.optim.Optimizer] 优化器, 可以是一个也可以是一组通过dict配置的优化器</span>                 work_dir<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span><span class="token comment"># [str] 保存检查点和Log的目录</span>                 logger<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span><span class="token comment"># [logging.Logger] 训练中使用的日志记录器</span>                 meta<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span><span class="token comment"># [dict] 一些信息, 这些信息会在logger hook中记录</span>                 max_iters<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span><span class="token comment"># [int] 训练epoch数</span>                 max_epochs<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token comment"># [int] 训练迭代次数</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>​BaseRunner的任何子类都需要实现<code>run()</code>、<code>train()</code>、<code>val()</code>和<code>save_checkpoint()</code>四个方法，这也是Runner的核心方法，接下来就以EpochBasedRunner类为例对这四个函数进行详细分析。</p><p>​<strong>run()函数</strong>是Runner类的主调函数，会根据workflow指定的工作流，对data_loaders中的数据进行处理。目前MMCV支持训练和验证两种工作流，对于EpochBasedRunner而言，workflow配置为<code>[(&#39;train&#39;, 2)，(&#39;val&#39;, 1)]</code>表示先训练2个epoch，然后验证一个epoch；<code>[(&#39;train&#39;, 1)]</code>表示只进行训练，不进行验证。如果是IterBasedRunner，<code>[(&#39;train&#39;, 2)，(&#39;val&#39;, 1)]</code>则表示先训练2个iter，然后验证一个iter。然后<code>getattr(self, mode)</code>会根据不同mode调用self.train()函数和self.val()函数。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">run</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> data_loaders<span class="token punctuation">,</span> workflow<span class="token punctuation">,</span> max_epochs<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">while</span> self<span class="token punctuation">.</span>epoch <span class="token operator">&lt;</span> self<span class="token punctuation">.</span>_max_epochs<span class="token punctuation">:</span>        <span class="token keyword">for</span> i<span class="token punctuation">,</span> flow <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>workflow<span class="token punctuation">)</span><span class="token punctuation">:</span>            mode<span class="token punctuation">,</span> epochs <span class="token operator">=</span> flow                        <span class="token comment"># 如果mode='train', 则调用self.train()函数</span>            <span class="token comment"># 如果mode='val', 则调用self.val()函数</span>            epoch_runner <span class="token operator">=</span> <span class="token builtin">getattr</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> mode<span class="token punctuation">)</span>            <span class="token keyword">for</span> _ <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>                <span class="token keyword">if</span> mode <span class="token operator">==</span> <span class="token string">'train'</span> <span class="token keyword">and</span> self<span class="token punctuation">.</span>epoch <span class="token operator">>=</span> self<span class="token punctuation">.</span>_max_epochs<span class="token punctuation">:</span>                    <span class="token keyword">break</span>                <span class="token comment"># 运行train()或val()</span>                epoch_runner<span class="token punctuation">(</span>data_loaders<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>​<code>train()</code>和<code>val()</code>函数循环调用<code>run_iter()</code>完成一个epoch流程。函数开头的self.model.train()和self.model.eval()实际上调用的是torch.nn.module.Module的成员函数，将当前模块设置为训练模式或验证模式，两种不同模式下batchnorm、dropout等层的操作会有区别。然后由于测试过程不需要梯度回传，所以val函数加了一个装饰器<code>@torch.no_grad()</code>。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> data_loader<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token comment"># 将模块设置为训练模式</span>    self<span class="token punctuation">.</span>model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>    self<span class="token punctuation">.</span>mode <span class="token operator">=</span> <span class="token string">'train'</span>    self<span class="token punctuation">.</span>data_loader <span class="token operator">=</span> data_loader    self<span class="token punctuation">.</span>_max_iters <span class="token operator">=</span> self<span class="token punctuation">.</span>_max_epochs <span class="token operator">*</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>data_loader<span class="token punctuation">)</span>    <span class="token keyword">for</span> i<span class="token punctuation">,</span> data_batch <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>data_loader<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>run_iter<span class="token punctuation">(</span>data_batch<span class="token punctuation">,</span> train_mode<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>_iter <span class="token operator">+=</span> <span class="token number">1</span>    self<span class="token punctuation">.</span>_epoch <span class="token operator">+=</span> <span class="token number">1</span><span class="token decorator annotation punctuation">@torch<span class="token punctuation">.</span>no_grad</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">val</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> data_loader<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token comment"># 将模块设置为验证模式</span>    self<span class="token punctuation">.</span>model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    self<span class="token punctuation">.</span>mode <span class="token operator">=</span> <span class="token string">'val'</span>    self<span class="token punctuation">.</span>data_loader <span class="token operator">=</span> data_loader    <span class="token keyword">for</span> i<span class="token punctuation">,</span> data_batch <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>data_loader<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>run_iter<span class="token punctuation">(</span>data_batch<span class="token punctuation">,</span> train_mode<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">run_iter</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> data_batch<span class="token punctuation">,</span> train_mode<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">if</span> self<span class="token punctuation">.</span>batch_processor <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>        outputs <span class="token operator">=</span> self<span class="token punctuation">.</span>batch_processor<span class="token punctuation">(</span>self<span class="token punctuation">.</span>model<span class="token punctuation">,</span> data_batch<span class="token punctuation">,</span> train_mode<span class="token operator">=</span>train_mode<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span>    <span class="token keyword">elif</span> train_mode<span class="token punctuation">:</span>        outputs <span class="token operator">=</span> self<span class="token punctuation">.</span>model<span class="token punctuation">.</span>train_step<span class="token punctuation">(</span>data_batch<span class="token punctuation">,</span> self<span class="token punctuation">.</span>optimizer<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span>    <span class="token keyword">else</span><span class="token punctuation">:</span>        outputs <span class="token operator">=</span> self<span class="token punctuation">.</span>model<span class="token punctuation">.</span>val_step<span class="token punctuation">(</span>data_batch<span class="token punctuation">,</span> self<span class="token punctuation">.</span>optimizer<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>outputs <span class="token operator">=</span> outputs<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>​<code>train()</code>和<code>val()</code>的核心函数是<code>run_iter()</code>，根据train_mode参数调用<code>model.train_step()</code>或<code>model.val_step()</code>，这两个函数最终都会指向我们自己模型的<code>forward()</code>函数，返回模型的前向推理结果（一般是Loss值）。Runner到我们自己的模型中间还会经过MMDataParallel、BaseDetector、SingleStageDetector(或TwoStageDetector)四个类，最终调用我们自己模型的<code>forward()</code>函数，执行推理过程。</p><p><img src="/./images/MMdetection%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/3.png"></p><p>​细心的同学可能会问，怎么从头到尾没看到梯度反传优化这一步骤？MMDetection的梯度优化是通过一个实现了<code>after_train_iter()</code>的Hook实现的，其优先级为ABOVE_NORMAL。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token decorator annotation punctuation">@HOOKS<span class="token punctuation">.</span>register_module</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">class</span> <span class="token class-name">OptimizerHook</span><span class="token punctuation">(</span>Hook<span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token keyword">def</span> <span class="token function">after_train_iter</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> runner<span class="token punctuation">)</span><span class="token punctuation">:</span>    runner<span class="token punctuation">.</span>optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>    runner<span class="token punctuation">.</span>outputs<span class="token punctuation">[</span><span class="token string">'loss'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">if</span> self<span class="token punctuation">.</span>grad_clip <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>        grad_norm <span class="token operator">=</span> self<span class="token punctuation">.</span>clip_grads<span class="token punctuation">(</span>runner<span class="token punctuation">.</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">if</span> grad_norm <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>            <span class="token comment"># Add grad norm to the logger</span>            runner<span class="token punctuation">.</span>log_buffer<span class="token punctuation">.</span>update<span class="token punctuation">(</span><span class="token punctuation">&#123;</span><span class="token string">'grad_norm'</span><span class="token punctuation">:</span> <span class="token builtin">float</span><span class="token punctuation">(</span>grad_norm<span class="token punctuation">)</span><span class="token punctuation">&#125;</span><span class="token punctuation">,</span>                                     runner<span class="token punctuation">.</span>outputs<span class="token punctuation">[</span><span class="token string">'num_samples'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    runner<span class="token punctuation">.</span>optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>​ <strong>save_checkpoint()函数</strong>比较简单，就不过多说明了，最终是调用torch.save将检查点按下列格式保存成文件。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">checkpoint <span class="token operator">=</span> <span class="token punctuation">&#123;</span>  <span class="token string">'meta'</span><span class="token punctuation">:</span> <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token comment"># 环境信息(比如epoch_num, iter_num)</span>  <span class="token string">'state_dict'</span><span class="token punctuation">:</span> <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token comment"># 模型的state_dict()</span>  <span class="token string">'optimizer'</span><span class="token punctuation">:</span> <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment"># 优化器的state_dict()</span><span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="3-注册机制"><a href="#3-注册机制" class="headerlink" title="3.注册机制"></a>3.注册机制</h3><h4 id="3-1Registry类"><a href="#3-1Registry类" class="headerlink" title="3.1Registry类"></a>3.1Registry类</h4><p>​MMDetection作为MMCV的下游项目，继承了MMCV的模块管理方式——注册机制。简单来说，注册机制就是维护几张查询表，key是模块的名称，value是模块的句柄，每张查询表都管理一批功能相似的不同模块。我们每新建一个模块，都要根据模块实现的功能将对应的<code>key-value</code>查询对保存到对应的查询表中，这个保存的过程就称为“<strong>注册</strong>”。当我们想要调用某个模块时，只需要根据模块名称从查询表中找到对应的模块句柄，然后就能完成模块初始化或方法调用等操作。MMCV通过<code>Registry</code>类来实现字符串(key)到类(value)的映射。</p><p>​Registry的构造函数如下所示，变量<code>self._module_dict</code>就是上面提到的“查询表”，注册的模块都会存到这个字典类型的变量里，新建一个Registry实例就是新建一张查询表。另外，Registry还支持继承机制。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> mmcv<span class="token punctuation">.</span>utils <span class="token keyword">import</span> Registry<span class="token keyword">class</span> <span class="token class-name">Registry</span><span class="token punctuation">:</span><span class="token comment"># 构造函数</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> name<span class="token punctuation">,</span> build_func<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> parent<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> scope<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment"># 注册器的名称</span>        self<span class="token punctuation">.</span>_name <span class="token operator">=</span> name        <span class="token comment"># 使用module_dict管理字符串到类的映射</span>        self<span class="token punctuation">.</span>_module_dict <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment"># 使用children管理注册器的子类</span>        self<span class="token punctuation">.</span>_children <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment"># build_func按照如下优先级初始化:</span>        <span class="token comment"># 1. build_func: 优先使用指定的函数</span>        <span class="token comment"># 2. parent.build_func: 其次使用父类的build_func</span>        <span class="token comment"># 3. build_from_cfg: 默认从config dict中实例化对象</span>        <span class="token keyword">if</span> build_func <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span>            <span class="token keyword">if</span> parent <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>                self<span class="token punctuation">.</span>build_func <span class="token operator">=</span> parent<span class="token punctuation">.</span>build_func            <span class="token keyword">else</span><span class="token punctuation">:</span>                self<span class="token punctuation">.</span>build_func <span class="token operator">=</span> build_from_cfg        <span class="token keyword">else</span><span class="token punctuation">:</span>            self<span class="token punctuation">.</span>build_func <span class="token operator">=</span> build_func                    <span class="token comment"># 设置父类-子类的从属关系</span>        <span class="token keyword">if</span> parent <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>            <span class="token keyword">assert</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>parent<span class="token punctuation">,</span> Registry<span class="token punctuation">)</span>            parent<span class="token punctuation">.</span>_add_children<span class="token punctuation">(</span>self<span class="token punctuation">)</span>            self<span class="token punctuation">.</span>parent <span class="token operator">=</span> parent        <span class="token keyword">else</span><span class="token punctuation">:</span>            self<span class="token punctuation">.</span>parent <span class="token operator">=</span> <span class="token boolean">None</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>​模块的注册通过Registry的成员函数<code>register_module()</code>来实现，<code>register_module()</code>内部又会调用另一个私有函数<code>_register_module()</code>，模块注册的核心功能其实是在<code>_register_module()</code>中实现的。核心代码也很简单，就是将传入的<code>module_name</code>和<code>module_class</code>保存到字典<code>self._module_dict</code>中。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">_register_module</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> module_class<span class="token punctuation">,</span> module_name<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> force<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token comment"># 如果未指定模块名称则使用默认名称</span>    <span class="token keyword">if</span> module_name <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span>        module_name <span class="token operator">=</span> module_class<span class="token punctuation">.</span>__name__            <span class="token comment"># 为了支持在nn.Sequentail中构建pytorch模块, module_name为list形式</span>    <span class="token keyword">if</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>module_name<span class="token punctuation">,</span> <span class="token builtin">str</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        module_name <span class="token operator">=</span> <span class="token punctuation">[</span>module_name<span class="token punctuation">]</span>            <span class="token keyword">for</span> name <span class="token keyword">in</span> module_name<span class="token punctuation">:</span>    <span class="token comment"># 如果force=False, 则不允许注册相同名称的模块</span>    <span class="token comment"># 如果force=True, 则用后一次的注册覆盖前一次</span>        <span class="token keyword">if</span> <span class="token keyword">not</span> force <span class="token keyword">and</span> name <span class="token keyword">in</span> self<span class="token punctuation">.</span>_module_dict<span class="token punctuation">:</span>            <span class="token keyword">raise</span> KeyError<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'</span><span class="token interpolation"><span class="token punctuation">&#123;</span>name<span class="token punctuation">&#125;</span></span><span class="token string"> is already registered in </span><span class="token interpolation"><span class="token punctuation">&#123;</span>self<span class="token punctuation">.</span>name<span class="token punctuation">&#125;</span></span><span class="token string">'</span></span><span class="token punctuation">)</span>        <span class="token comment"># 将当前注册的模块加入到查询表中</span>        self<span class="token punctuation">.</span>_module_dict<span class="token punctuation">[</span>name<span class="token punctuation">]</span> <span class="token operator">=</span> module_class<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>​在我们通过字符串获取到一个模块的句柄后，可以通过<code>self.build_func</code>函数句柄来实例化这个模块。<code>build_func</code>可以人为指定，也可以从父类继承，一般来说都是默认使用<code>build_from_cfg()</code>函数，即使用配置参数<code>cfg</code>来初始化该模块。配置参数<code>cfg</code>是一个字典，里面的<code>type</code>字段是模块名称的字符串，其他字段则对应模块构造函数的输入参数。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">build_from_cfg</span><span class="token punctuation">(</span>cfg<span class="token punctuation">,</span> registry<span class="token punctuation">,</span> default_args<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    args <span class="token operator">=</span> cfg<span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># 将cfg以外的外部传入参数也合并到args中</span>    <span class="token keyword">if</span> default_args <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>        <span class="token keyword">for</span> name<span class="token punctuation">,</span> value <span class="token keyword">in</span> default_args<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            args<span class="token punctuation">.</span>setdefault<span class="token punctuation">(</span>name<span class="token punctuation">,</span> value<span class="token punctuation">)</span>            <span class="token comment"># 获取模块名称</span>    obj_type <span class="token operator">=</span> args<span class="token punctuation">.</span>pop<span class="token punctuation">(</span><span class="token string">'type'</span><span class="token punctuation">)</span>    <span class="token keyword">if</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>obj_type<span class="token punctuation">,</span> <span class="token builtin">str</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment"># get函数返回registry._module_dict中obj_type对应的模块句柄</span>        obj_cls <span class="token operator">=</span> registry<span class="token punctuation">.</span>get<span class="token punctuation">(</span>obj_type<span class="token punctuation">)</span>        <span class="token keyword">if</span> obj_cls <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span>            <span class="token keyword">raise</span> KeyError<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'</span><span class="token interpolation"><span class="token punctuation">&#123;</span>obj_type<span class="token punctuation">&#125;</span></span><span class="token string"> is not in the </span><span class="token interpolation"><span class="token punctuation">&#123;</span>registry<span class="token punctuation">.</span>name<span class="token punctuation">&#125;</span></span><span class="token string"> registry'</span></span><span class="token punctuation">)</span>    <span class="token keyword">elif</span> inspect<span class="token punctuation">.</span>isclass<span class="token punctuation">(</span>obj_type<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment"># type值是模块本身</span>        obj_cls <span class="token operator">=</span> obj_type    <span class="token keyword">else</span><span class="token punctuation">:</span>        <span class="token keyword">raise</span> TypeError<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'type must be a str or valid type, but got </span><span class="token interpolation"><span class="token punctuation">&#123;</span><span class="token builtin">type</span><span class="token punctuation">(</span>obj_type<span class="token punctuation">)</span><span class="token punctuation">&#125;</span></span><span class="token string">'</span></span><span class="token punctuation">)</span>        <span class="token comment"># 模块初始化, 返回模块实例</span>    <span class="token keyword">try</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> obj_cls<span class="token punctuation">(</span><span class="token operator">**</span>args<span class="token punctuation">)</span>    <span class="token keyword">except</span> Exception <span class="token keyword">as</span> e<span class="token punctuation">:</span>        <span class="token keyword">raise</span> <span class="token builtin">type</span><span class="token punctuation">(</span>e<span class="token punctuation">)</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'</span><span class="token interpolation"><span class="token punctuation">&#123;</span>obj_cls<span class="token punctuation">.</span>__name__<span class="token punctuation">&#125;</span></span><span class="token string">: </span><span class="token interpolation"><span class="token punctuation">&#123;</span>e<span class="token punctuation">&#125;</span></span><span class="token string">'</span></span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>​考虑到<code>registry</code>参数需要指向当前注册器本身，我们一般是调用Registry类的<code>build()</code>方法而不是<code>self.build_func</code>。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">build</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">return</span> self<span class="token punctuation">.</span>build_func<span class="token punctuation">(</span><span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">,</span> registry<span class="token operator">=</span>self<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>​下面是一个小例子，模拟了网络模型的注册和调用过程。注意一下，我们打印Registry对象时，实际上打印的是<code>self._module_dict</code>中的values。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 实例化一个注册器用来管理模型</span>MODELS <span class="token operator">=</span> Registry<span class="token punctuation">(</span><span class="token string">'myModels'</span><span class="token punctuation">)</span><span class="token comment"># 方式1: 在类的创建过程中, 使用函数装饰器进行注册(推荐)</span><span class="token decorator annotation punctuation">@MODELS<span class="token punctuation">.</span>register_module</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">class</span> <span class="token class-name">ResNet</span><span class="token punctuation">(</span><span class="token builtin">object</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> depth<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>depth <span class="token operator">=</span> depth        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Initialize ResNet&#123;&#125;'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>depth<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment"># 方式2: 完成类的创建后, 再显式调用register_module进行注册(不推荐)   </span><span class="token keyword">class</span> <span class="token class-name">FPN</span><span class="token punctuation">(</span><span class="token builtin">object</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_channel<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>in_channel<span class="token operator">=</span> in_channel        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Initialize FPN&#123;&#125;'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>in_channel<span class="token punctuation">)</span><span class="token punctuation">)</span>MODELS<span class="token punctuation">.</span>register_module<span class="token punctuation">(</span>name<span class="token operator">=</span><span class="token string">'FPN'</span><span class="token punctuation">,</span> module<span class="token operator">=</span>FPN<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>MODELS<span class="token punctuation">)</span><span class="token triple-quoted-string string">""" 打印结果为:Registry(name=myModels, items=&#123;'ResNet': &lt;class '__main__.ResNet'>, 'FPN': &lt;class '__main__.FPN'>&#125;)"""</span><span class="token comment"># 配置参数, 一般cfg从配置文件中获取</span>backbone_cfg <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'ResNet'</span><span class="token punctuation">,</span> depth<span class="token operator">=</span><span class="token number">101</span><span class="token punctuation">)</span>neck_cfg <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'FPN'</span><span class="token punctuation">,</span> in_channel<span class="token operator">=</span><span class="token number">256</span><span class="token punctuation">)</span><span class="token comment"># 实例化模型(将配置参数传给模型的构造函数), 得到实例化对象</span>my_backbone <span class="token operator">=</span> MODELS<span class="token punctuation">.</span>build<span class="token punctuation">(</span>backbone_cfg<span class="token punctuation">)</span>my_neck <span class="token operator">=</span> MODELS<span class="token punctuation">.</span>build<span class="token punctuation">(</span>neck_cfg<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>my_backbone<span class="token punctuation">,</span> my_neck<span class="token punctuation">)</span><span class="token triple-quoted-string string">""" 打印结果为:Initialize ResNet101Initialize FPN256&lt;__main__.ResNet object at 0x000001E68E99E198> &lt;__main__.FPN object at 0x000001E695044B38>"""</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="3-2注册机制步骤"><a href="#3-2注册机制步骤" class="headerlink" title="3.2注册机制步骤"></a>3.2注册机制步骤</h4><ol><li>新建一个类，实现自定义功能</li><li>将该类注册到对应的查询表中（<code>register_module</code>）</li><li>在配置文件中指定该模块的初始化参数</li><li>通过build函数对模块进行实例化（<code>build_from_cfg</code>）</li><li>使用该实例对象执行功能函数</li></ol><h3 id="4-Hook机制"><a href="#4-Hook机制" class="headerlink" title="4.Hook机制"></a>4.Hook机制</h3><h4 id="4-1Hook类"><a href="#4-1Hook类" class="headerlink" title="4.1Hook类"></a>4.1Hook类</h4><p>​MMDetection的整个算法过程就像一个黑盒子：给定输入后（配置文件），黑盒子就会吐出算法结果。整个过程封装度非常高，几乎不需要手写什么代码，但是我们如何在算法执行过程中加入自定义操作呢？这就是Hook机制的作用。</p><p>​简单来说，<strong>Hook可以理解为一种触发器，可以在程序预定义的位置执行预定义的函数</strong>。MMCV根据算法的生命周期预定义了6个可以插入自定义函数的位点，用户可以在每个位点自由地插入任意数量的函数操作，如下图所示：</p><p><img src="/./images/MMdetection%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/4.png"></p><p>​这6个位置基本涵盖了自定义操作可能出现的位置，MMCV已经实现了部分常用Hook，其中默认Hook不需要用户自行注册，通过配置文件配置对应的参数即可；定制Hook则需要用户在配置文件中手动配置<code>custom_hooks</code>字段进行注册。</p><p><img src="/./images/MMdetection%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/5.png"></p><p>​<code>Hook</code>类本身代码很少，只提供了预定义位置的接口函数，任何自定义的Hook都需要继承<code>Hook</code>类，然后根据需要重写对应的接口函数。比如检查点保存操作通常发生在每次迭代或epoch后，所以我们需要重写<code>after_train_iter</code>和<code>after_train_epoch</code>。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Hook</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">before_run</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> runner<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">pass</span>    <span class="token keyword">def</span> <span class="token function">after_run</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> runner<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">pass</span>    <span class="token keyword">def</span> <span class="token function">before_epoch</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> runner<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">pass</span>    <span class="token keyword">def</span> <span class="token function">after_epoch</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> runner<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">pass</span>    <span class="token keyword">def</span> <span class="token function">before_iter</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> runner<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">pass</span>    <span class="token keyword">def</span> <span class="token function">after_iter</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> runner<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">pass</span><span class="token decorator annotation punctuation">@HOOKS<span class="token punctuation">.</span>register_module</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">class</span> <span class="token class-name">CheckpointHook</span><span class="token punctuation">(</span>Hook<span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>                 interval<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span>                 by_epoch<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>                 save_optimizer<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>                 out_dir<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span>                 max_keep_ckpts<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span>                 <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token keyword">def</span> <span class="token function">after_train_iter</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> runner<span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token keyword">def</span> <span class="token function">after_train_epoch</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> runner<span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>​和其他模块不同，当我们定义好一个Hook(并注册到<code>HOOKS</code>注册器中)之后，还需要注册到Runner中才能使用，<strong>前后一共进行两次注册</strong>。第一次注册到<code>HOOKS</code>是为了程序能够根据Hook名称找到对应的模块，第二次注册到Runner中是为了程序执行到预定义位置时能够调用对应的函数。</p><p>​ Runner是MMCV用来管理训练过程的一个类，它内部会维护一个list类型变量<code>self._hooks</code>，我们需要把训练过程会调用的Hook<strong>实例对象</strong>按照优先级顺序全部添加到<code>self._hooks</code>中，这个过程通过<code>Runner.register_hook()</code>函数实现。MMCV预定义了几种优先级, 数字越小表示优先级越高, 如果觉得默认的分级方式颗粒度过大, 也<strong>可以直接传入0~100的整数</strong>进行精细划分。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">register_hook</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> hook<span class="token punctuation">,</span> priority<span class="token operator">=</span><span class="token string">'NORMAL'</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token triple-quoted-string string">"""预定义优先级    +--------------+------------+    | Level        | Value      |    +==============+============+    | HIGHEST      | 0          |    +--------------+------------+    | VERY_HIGH    | 10         |    +--------------+------------+    | HIGH         | 30         |    +--------------+------------+    | ABOVE_NORMAL | 40         |    +--------------+------------+    | NORMAL       | 50         |    +--------------+------------+    | BELOW_NORMAL | 60         |    +--------------+------------+    | LOW          | 70         |    +--------------+------------+    | VERY_LOW     | 90         |    +--------------+------------+    | LOWEST       | 100        |    +--------------+------------+    """</span>    hook<span class="token punctuation">.</span>priority <span class="token operator">=</span> priority    <span class="token comment"># 插入法排序将Hooks按照priority大小升序排列</span>    inserted <span class="token operator">=</span> <span class="token boolean">False</span>    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>_hooks<span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">if</span> priority <span class="token operator">>=</span> self<span class="token punctuation">.</span>_hooks<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">.</span>priority<span class="token punctuation">:</span>            self<span class="token punctuation">.</span>_hooks<span class="token punctuation">.</span>insert<span class="token punctuation">(</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> hook<span class="token punctuation">)</span>            inserted <span class="token operator">=</span> <span class="token boolean">True</span>            <span class="token keyword">break</span>    <span class="token keyword">if</span> <span class="token keyword">not</span> inserted<span class="token punctuation">:</span>        self<span class="token punctuation">.</span>_hooks<span class="token punctuation">.</span>insert<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> hook<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>​将Hook实例加入到<code>self._hooks</code>中之后，然后就可以在预定义位置调用<code>call_hook()</code>来调用各个Hook实例中的对应方法。<code>call_hook()</code>称为回调函数。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 开始运行时调用</span>self<span class="token punctuation">.</span>call_hook<span class="token punctuation">(</span><span class="token string">'after_train_epoch'</span><span class="token punctuation">)</span><span class="token keyword">while</span> self<span class="token punctuation">.</span>epoch <span class="token operator">&lt;</span> self<span class="token punctuation">.</span>_max_epochs<span class="token punctuation">:</span>    <span class="token comment"># 开始 epoch 迭代前调用</span>    self<span class="token punctuation">.</span>call_hook<span class="token punctuation">(</span><span class="token string">'before_train_epoch'</span><span class="token punctuation">)</span>    <span class="token keyword">for</span> i<span class="token punctuation">,</span> data_batch <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>data_loader<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment"># 开始 iter 迭代前调用</span>        self<span class="token punctuation">.</span>call_hook<span class="token punctuation">(</span><span class="token string">'before_train_iter'</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>model<span class="token punctuation">.</span>train_step<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment"># 经过一次迭代后调用</span>        self<span class="token punctuation">.</span>call_hook<span class="token punctuation">(</span><span class="token string">'after_train_iter'</span><span class="token punctuation">)</span>    <span class="token comment"># 经过一个 epoch 迭代后调用</span>    self<span class="token punctuation">.</span>call_hook<span class="token punctuation">(</span><span class="token string">'after_train_epoch'</span><span class="token punctuation">)</span><span class="token comment"># 运行完成前调用</span>self<span class="token punctuation">.</span>call_hook<span class="token punctuation">(</span><span class="token string">'after_train_epoch'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>​调用<code>call_hook()</code>时会遍历<code>self._hooks</code>中所有Hook实例，并根据<code>fn_name</code>调用Hook实例的指定成员函数。比如<code>fn_name=&#39;before_train_epoch&#39;</code>时，<code>call_hook()</code>会挨个调用所有Hook的<code>before_train_epoch()</code>函数。而且由于<code>self._hooks</code>已经按照优先级进行过排序，<code>call_hook()</code>会先调用优先级高的Hook方法。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">call_hook</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> fn_name<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">for</span> hook <span class="token keyword">in</span> self<span class="token punctuation">.</span>_hooks<span class="token punctuation">:</span>        <span class="token builtin">getattr</span><span class="token punctuation">(</span>hook<span class="token punctuation">,</span> fn_name<span class="token punctuation">)</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h4 id="4-2-Hool机制步骤"><a href="#4-2-Hool机制步骤" class="headerlink" title="4.2 Hool机制步骤"></a>4.2 Hool机制步骤</h4><ol><li>定义一个类，继承Hook基类</li><li>根据自定义Hook的功能有选择地重写Hook基类中对应的函数</li><li>注册自定义Hook模块到HOOKS查询表中（<code>register_module</code>）</li><li>实例化Hook模块并注册到Runner中（<code>register_hook</code>）</li><li>使用回调函数调用重写的Hook函数（<code>call_hook</code>）</li></ol>]]></content>
      
      
      <categories>
          
          <category> Tutorial </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MMDetection </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
